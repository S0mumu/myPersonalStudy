







#  JAVA基础

### 1. Static 修饰类，方法，变量有什么作用，final呢？

```
static修饰类、方法、变量表示该类、方法、变量是静态的。
首先static只能用于修饰内部类，不能用于修饰普通类，静态内部类的相当于一个普通的类，访问方式为（new 外部类名.内部类的方法()）。 
静态方法、静态变量表示不通过类对象可以直接访问到，因为他在类加载时生成，他的生命周期是类的生命周期。
当一个方法或者变量需要初始化加载，或者是经常被调用的时候可以加上static。用static修饰的方法可以用类名直接调用，不用的一定要先实例化一个对象然后才可以调用。
坏处：初始化加载，比较占内存，所以不经常用的方法，不建议加此关键字。如果static是写在单例中，高并发访问是会出问题的，这时候就要设置线程等待了，static是在容器加载的时候就已经加载到内存中，所以static方法和变量不宜过度使用，有选择的使用。
```

```
使用final修饰符修饰的类的特点，该类不能有子类；
使用final修饰符修饰的对象的特点：该对象的引用地址不能改变；
使用Final修饰符修饰的方法的特点：该方法不能被重写；
使用final修饰符修饰的变量的特点：该变量会变成常量，值不能被改变。
```

### 2. ==和equals区别 

```
==比较两个对象的内存地址是否相同
equals为重写前比较两个对象内存地址是否相同，可以重写equlas方法，例如String可以直接通过比较equals比较两个String对象的内容是否相等。
但是重写equals方法一定要重写hashcode方法。
1、如果两个对象相同（即用equals比较返回true），那么它们的hashCode值一定要相同；
2、如果两个对象的hashCode相同，它们并不一定相同(即用equals比较返回false) 

```

### 3. Object类的hashcode方法的作用 

```
hashCode():获取哈希码，也称为散列码，返回一个int整数。这个哈希码的作用是通过该对象在哈希表中的索引位置。
由于为了提高程序的效率才实现了hashcode方法，先进行hashcode的比较，如果不同，那没就不必在进行equals的比较了，这样就大大减少了equals比较的次数，这对比需要比较的数量很大的效率提高是很明显的，一个很好的例子就是在集合中的使用；我们都知道java中的List集合是有序的，因此是可以重复的，而set集合是无序的，因此是不能重复的，那么怎么能保证不能被放入重复的元素呢，但靠equals方法一样比较的话，如果原来集合中以后又10000个元素了，那么放入10001个元素，难道要将前面的所有元素都进行比较，看看是否有重复，欧码噶的，这个效率可想而知，因此hashcode就应遇而生了，java就采用了hash表，利用哈希算法（也叫散列算法），就是将对象数据根据该对象的特征使用特定的算法将其定义到一个地址上，那么在后面定义进来的数据只要看对应的hashcode地址上是否有值，那么就用equals比较，如果没有则直接插入，只要就大大减少了equals的使用次数，执行效率就大大提高了。继续上面的话题，为什么必须要重写hashcode方法，其实简单的说就是为了保证同一个对象，保证在equals相同的情况下hashcode值必定相同，如果重写了equals而未重写hashcode方法，可能就会出现两个没有关系的对象equals相同的（因为equal都是根据对象的特征进行重写的），但hashcode确实不相同的。
```

### 4. hashmap的哈希冲突，rehash 

```
Map ，最直观就是理解就是键值对，映射，key-value 形式。一个映射不能包含重复的键，一个键只能有一个值。HashMap 实现了 Map 接口，允许使用 null 值 和 null 键，并且不保证映射顺序。
**HashMap 有两个参数影响性能：**
**初始容量** **加载因子**
当哈希表中的条目超过了容量和加载因子的乘积的时候，就会进行重哈希操作。
hashmap底层数据结构是数组+链表/红黑树
当使用put(key,value)添加元素的时候，会调用putVal（hash(key), key, value, false, true）方法，其中hash(key)表示的是通过key计算出一个值，表示key存放的位置。如果该位置存在元素，则通过链表数据结构，链接到后面。如果数组过短则通过增加数组长度。
此外，通过将链表转为红黑树，来提高查找的效率。
```



### 5. 红黑树

![img](https://images2015.cnblogs.com/blog/758472/201606/758472-20160617172959307-415335808.png)

```
红黑树的要求
1）根节点是黑节点
2）所有Null节点是叶子节点是黑节点
3）所有红节点的子节点是黑节点
2）从任意节点到齐叶子节点的所有路径上包括相同数目的黑节点。
```



### 6. 红黑树与AVL树相比，优缺点

```
二者都是二叉平衡树，两者查询、插入、删除的时间复杂度最坏都是log（n）
但是二叉平衡树的要求严格，需要保证左右子树的高度差<=1,因此在添加删除元素的时候，需要进行大量的旋转操作来达到二叉平衡树的要求。但是红黑树为树上的每个节点设置了红黑两种颜色，它用非严格的平衡来换取增加删除节点时旋转的次数的降低。
```

### 7. wait()和sleep()的区别 

**类的区别**：

```
wait() 是来自java.lang.Object
sleep()是来自java.lang.Thread
```

**用法上的区别**：

```
wait()线程挂起时，其必须在synchronized block中，否则抛出运行时java.lang.IllegalMonitorStateException异常，对象调用java.lang.object.notify()或者java.lang.object.notifyAll()或者时间到期，则从wait()中恢复过来。
sleep()，表示在指定时间线程暂停执行，等待一段时间后，自动醒来进入可运行状态
```

**同步和锁的区别**：

```
wait()期间对象锁释放;如果线程拥有某个或某些对象的同步锁，那么在调用了wait()后，这个线程就会释放它持有的所有同步资源，而不限于这个被调用了wait()方法的对象。wait()方法有可能被其他对象调用interrupt()方法  

sleep() yield()方法锁不释放，但可能会有可能被其他对象调用的interrupt(),产生InterruptedException异常，如果程序不捕获这个异常，线程就会异常终止，进入TERMINATED状态，如果程序捕获了这个异常，那么程序就会继续执行catch语句块(可能还有finally语句块)以及以后的代码。 sleep() yield()方法锁不释放，但可能会有可能被其他对象调用的interrupt(),产生InterruptedException异常，如果程序不捕获这个异常，线程就会异常终止，进入TERMINATED状态，如果程序捕获了这个异常，那么程序就会继续执行catch语句块(可能还有finally语句块)以及以后的代码。   

如果线程A想要结束线程B，则可以对线程B对应的Thread实例调用interrupt方法，若线程B正在wait/sleep/join，则线程B会立刻抛出IterruptedExcpetion，在catch{}中捕获异常就可以安全return结束线程。

一般而言，wait ()用于线程间通信，sleep()用于线程状态控制
```

### 8. yield()和join()

```
yield方法暂停当前正在执行的线程对象。yield()是暂停当前的线程，让同等优先级和更高级的线程有机会执行，如果没有，则yield方法的线程立刻进入可执行状态后立马执行。

join方法在一个线程的执行过程中调用另一个线程，另一个线程结束运行后，再继续执行当前线程。
```

### 9. 死锁的必要条件

```
1. 互斥
2. 占有并等待
3. 非抢占
4. 循环等待
```

### 10. Synchronized

```
 1)CAS 

compare and swap 是不用加锁的一种多线程操作，这可能有ABA问题，就是经过其他线程修改后变成了跟原始值相同，因此可以加版本号解决。

lock cmpxchg 指令，cmpxchg是非原子,因此加了lock

 2) 对象内存布局

markword （8个字节头，包含锁信息，GC，hashcode）

classpointer （默认4个字节）

m

padding 

64位机，需要被8个字节整除

3) 锁升级

用户态，内核态
```

### 11. java的位运算

```
按位与 & 
按位或 |
按位取非 ～
按位异或 ^
按位左移 <<
按位右移 >>
无符号右移 >>>
```

### 12. ArrayList和LinkedList的区别

```
ArrayList在插入和删除元素的时候一定比LinkedList差吗？
https://blog.csdn.net/javageektech/article/details/108162342
```

### 13. ThreadLocal

https://www.jianshu.com/p/3c5d7f09dfbd

```
在Handler源码中会出现ThreadLocal

多线程访问同一个共享变量的时候容易出现并发问题，特别是多个线程对一个变量进行写入的时候，为了保证线程安全，一般使用者在访问共享变量的时候需要进行额外的同步措施才能保证线程安全性。ThreadLocal是除了加锁这种同步方式之外的一种保证一种规避多线程访问出现线程不安全的方法，当我们在创建一个变量后，如果每个线程对其进行访问的时候访问的都是线程自己的变量这样就不会存在线程不安全问题。ThreadLocal是JDK包提供的，它提供线程本地变量，如果创建一乐ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的一个副本，在实际多线程操作的时候，操作的是自己本地内存中的变量，从而规避了线程安全问题，

Threadlocal是一个线程内部的存储类，可以在指定线程内存储数据，数据存储以后，只有指定线程可以得到存储数据。ThreadLocal提供了线程内存储变量的能力，这些变量不同之处在于每一个线程读取的变量是对应的互相独立的。通过get和set方法就可以得到当前线程对应的值。实际上是ThreadLocal的静态内部类ThreadLocalMap为每个Thread都维护了一个数组table，ThreadLocal确定了一个数组下标，而这个下标就是value存储的对应位置。每个线程持有一个ThreadLocalMap对象。每一个新的线程Thread都会实例化一个ThreadLocalMap并赋值给成员变量threadLocals，使用时若已经存在threadLocals则直接使用已经存在的对象

static final ThreadLocal<T> sThreadLocal=new ThreadLocal<T>();
sThreadLocal.set();
sThreadLocal.get();
```



### 14. String s=new String("aa");

```
https://blog.csdn.net/luzhensmart/article/details/105679905?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0.control&spm=1001.2101.3001.4242
```



### 抽象类和抽象方法

```
abstract可以用来修饰抽象类和抽象方法。
抽象类中可以没有抽象方法，但有抽象方法的类一定是抽象类。
抽象类和抽象方法不能被final修饰
```



### 抽象类和接口

```
抽象类和接口都不能被实例化，且都可以包含抽象方法
```



### Seriable

```
Seriable接口实现对象的序列化，主要是方便于对象数据的持久化。
对象传输的流ObjectOutputStream和ObjectInputStream
变量用transient修饰的则该变量并不会被序列化
```



# JVM

### Java的内存空间

<img src="https://snailclimb.gitee.io/javaguide/docs/java/jvm/pictures/java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/Java%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9FJDK1.8.png" alt="img" style="zoom:67%;" />

### Java的堆内存

<img src="https://snailclimb.gitee.io/javaguide/docs/java/jvm/pictures/java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/JVM%E5%A0%86%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84-jdk8.png" alt="JVM堆内存结构-JDK8" style="zoom:67%;" />

```
Java 堆是垃圾收集器管理的主要区域，因此也被称作**GC 堆（Garbage Collected Heap）**

分代垃圾收集算法

**上图所示的 Eden 区、两个 Survivor 区都属于新生代（为了区分，这两个 Survivor 区域按照顺序被命名为 from 和 to），中间一层属于老年代。**

对于直接内存来说，JVM将会在IO操作上具有更高的性能，因为它直接作用于本地系统的IO操作。而非直接内存，也就是堆内存中的数据，如果要作IO操作，会先复制到直接内存，再利用本地IO处理。
```



### GC Roots节点都有啥 



### G1收集器的收集[算法]

**G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.**

# 计算机组成原理

### 虚拟内存的作用

```
 缓存，内存管理， 内存保护，虚拟内存其实是将主存视为一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，其他作用是便于管理
```

### 全加器

```
一个全加器可以实现对两路一位数字信号的加法运算，输入为两路一位信号I1，I2，输出为一路两位信号O（含进位）满足：O = I1 + I2，现在有一路任意的3位数字信号X作为输入，要求输出Y=X*5，最少需要几个全加器？Y=X*5=X*4+X，即X左移两位再加自身，用abc表示X的三位数：abc00+abc，最低两位直接输出，前三位使用三个加法器计算
```

# 操作系统

### 页存储

https://blog.csdn.net/qq_43186095/article/details/103397642

为了知道每个进程中每一页在内存中对应存放位置，使用了也存储。示意图如下所示：

<img src="https://img-blog.csdnimg.cn/20191205080601403.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMTg2MDk1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%;" />

页存储的特点：

```
1.用一张页表来维护页号与具体的内存地址块号的映射关系
2.每个进程有多个页，一个页号由一个页表项来进行维护，页表项包括页号和块号
3. 每个页表项长度相同，页号是隐含的、连续的
```

如何进行页号和块号的转换。得到物理地址呢？

```
物理地址=页面起始地址+页内偏移量
```

计算方式1:

页号=逻辑地址/页面长度；
偏移量=逻辑地址%页面长度；

计算方式2:

<img src="https://img-blog.csdnimg.cn/20191205083156372.png" alt="在这里插入图片描述" style="zoom:50%;" />

因为页面长度一般为2的幂次方，假设32位表示一个逻辑地址，页面大小为2^k(B)，则后k位代表页内偏移量，前面部分表示页号。



局部性原理：

```
时间局部性、空间局部性、顺序局部性
```

产生了新的概念:快表+慢表构建了二级页表，可以在需要访问页面时才把页面调入内存（虚拟存储技术），在页表项中增加一个标志位用于表示该页面是否已被调入内存。若想访问的页面不在内存中，则会产生缺页中断（内中断），然后操作系统会把目标页面从外存调入内存。

### 页面置换算法

```
在地址映射的过程中，会产生页面的缺失，会产生缺页中断。如果操作系统不存在空闲的内存，则需要选择淘汰一页，即进行页面的置换。

**1．最佳置换算法（OPT）**（理想置换算法）：从主存中移出永远不再需要的页面；如无这样的页面存在，则选择最长时间不需要访问的页面。所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。 

**2．先进先出置换算法（FIFO）**：是最简单的页面置换算法。这种算法的基本思想是：当需要淘汰一个页面时，总是选择驻留主存时间最长的页面进行淘汰，即先进入主存的页面先淘汰。其理由是：最早调入主存的页面不再被使用的可能性最大。 

**3．最近最久未使用（LRU）算法**：这种算法的基本思想是：利用局部性原理，根据一个作业在执行过程中过去的页面访问历史来推测未来的行为。它认为过去一段时间里不曾被访问过的页面，在最近的将来可能也不会再被访问。所以，这种算法的实质是：当需要淘汰一个页面时，总是选择在最近一段时间内最久不用的页面予以淘汰。 

**4. 时钟(CLOCK)置换算法**：LRU算法的性能接近于OPT,但是实现起来比较困难，且开销大；FIFO算法实现简单，但性能差。所以操作系统的设计者尝试了很多算法，试图用比较小的开销接近LRU的性能，这类算法都是CLOCK算法的变体。

简单的CLOCK算法是给每一帧关联一个附加位，称为使用位。当某一页首次装入主存时，该帧的使用位设置为1;当该页随后再被访问到时，它的使用位也被置为1。对于页替换算法，用于替换的候选帧集合看做一个循环缓冲区，并且有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。每当遇到一个使用位为1的帧时，操作系统就将该位重新置为0；如果在这个过程开始时，缓冲区中所有帧的使用位均为0，则选择遇到的第一个帧替换；如果所有帧的使用位均为1,则指针在缓冲区中完整地循环一周，把所有使用位都置为0，并且停留在最初的位置上，替换该帧中的页。由于该算法循环地检查各页面的情况，故称为CLOCK算法，又称为最近未用(Not Recently Used, NRU)算法。
```



### 临界资源 && 临界区

1.临界资源
  临界资源是一次仅允许一个进程使用的共享资源。各进程采取互斥的方式，实现共享的资源称作临界资源。属于临界资源的硬件有，打印机，磁带机等；软件有消息队列，变量，数组，缓冲区等。诸进程间采取互斥方式，实现对这种资源的共享。

2.临界区：
  每个进程中访问临界资源的那段代码称为临界区（criticalsection），每次只允许一个进程进入临界区，进入后，不允许其他进程进入。不论是硬件临界资源还是软件临界资源，多个进程必须互斥的对它进行访问。多个进程涉及到同一个临界资源的临界区称为相关临界区。使用临界区时，一般不允许其运行时间过长，只要运行在临界区的线程还没有离开，其他所有进入此临界区的线程都会被挂起而进入等待状态，并在一定程度上影响程序的运行性能。



### 信号量 

1.设有n个进程共享一个互斥段，对于如下两种情况使用信号量，信号量的值应该怎样变化 (1)如果每次只允许一个进程进入互斥段 (2)如果每次最多允许m个进程(m<n)同时进入互斥段 

```
(1)信号量的初值是1，变化量范围是1，0，-1，-2，1-n
(2)信号量的初值是m，变化量范围是m，m-1，m-2，m-n
```

2.桌子上有一个盘子，每次只能放一个水果，爸爸专门向里面放苹果，妈妈专门向里面放橘子，一个儿子专门吃橘子，一个女儿专门吃苹果，用信号量实现他们间的同步机制

```
分析：爸爸和妈妈向里面放水果的时候要判断盘中是否空，是否有人在用盘子。女儿和儿子在吃水果之前要判断盘中是否有水果，以及是否有人在用盘子。判断使用wait

这两类人判断完之后在做自己应该做的事情，做完之后在signal，表示通知别人自己做完了
```

3.某业务要先取数据在向缓冲区存数据，另一业务要先从缓冲区取数据在计算

```
gathering Date
wait(buffer)
put Data to Buffer
signal(Date)

wait(Date)
take Date from Buffer
signal(Buffer)
complete
```



# 算法

### Java 中大根堆和小根堆的实现

```java
import java.util.*;
PriorityQueue<Integer> priorityQueue=new PriorityQueue<>(
		(o1,o1) -> o1-o2);  //小根堆,java8流式

PriorityQueue<Integer> priorityQueue=new PriorityQueue<>(new Comparator<Integer>(){
  	@Override
  	public int compare(Integer o1,Integer o2){
      		return o1-o2;
    }
});

PriorityQueue<Integer> priorityQueue=new PriorityQueue<>(
		(o1,o2) -> o2-o1);  //大根堆
```

### 排序算法

<img src="https://images2018.cnblogs.com/blog/849589/201804/849589-20180402133438219-1946132192.png" alt="img" style="zoom: 33%;" />

初始数据结构对排序没有影响的是堆排序



排序算法可以分为两类：

比较类排序：

​	交换排序（冒泡排序、快速排序）

​	插入排序（简单插入排序、希尔排序）

​	选择排序（简单选择排序，堆排序）

​	归并排序 （二路归并排序，多路归并排序）

非比较类排序：

​	计数排序

​	桶排序

​	基数排序



### 求质数因子

```
只要每次都按2 3 分就会得到
```

### 分桃子

```java
public class GDMU_HYGG {
    public static int sum(int count, int remain, int total) {
        total = total / 4 * 5 + 1;
        if (count == 1) {
            return total;
        }
        if (total % 5 == 1 && total % 4 == 0) {
            count--;
        } else {
            count = 5;
            remain += 4;
            total = remain;
        }
        return sum(count, remain, total);
    }

    public static void main(String[] args) {
        System.out.println("海滩原有" + sum(5, 4, 4) + "个桃子");
    }
}
```



### 动态规划

**基础题目**

​	[509. 斐波那契数](https://leetcode-cn.com/problems/fibonacci-number/)

​	[70. 爬楼梯](https://leetcode-cn.com/problems/climbing-stairs/)

​	[746. 使用最小花费爬楼梯](https://leetcode-cn.com/problems/min-cost-climbing-stairs/)

​	[62. 不同路径](https://leetcode-cn.com/problems/unique-paths/)	

​	[63. 不同路径 II](https://leetcode-cn.com/problems/unique-paths-ii/)

​	[343. 整数拆分](https://leetcode-cn.com/problems/integer-break/)



### 背包问题

**01背包**

​	[416. 分割等和子集](https://leetcode-cn.com/problems/partition-equal-subset-sum/)

​	[1049. 最后一块石头的重量 II](https://leetcode-cn.com/problems/last-stone-weight-ii/)

# 网络



### 第一部分：协议层次以及它们的服务类型

#### 1.	**OSI 7层模型** 面试高频指数：★★★★★

应用层、表示层、会话层、传输层、网络层、数据链路层和物理层。

![图片 1](/Users/rb/Desktop/找工作的资料/我的整理笔记/图片 1.png)

建立七层模型的主要目的是为解决异种网络互连时所遇到的兼容性问题。它的最大优点是将服务、接口和协议这三个概念明确地区分开来：服务说明某一层为上一层提供一些什么功能，接口说明上一层如何使用下层的服务，而协议涉及如何实现本层的服务；这样各层之间具有很强的独立性，互连网络中各实体采用什么样的协议是没有限制的，只要向上提供相同的服务并且不改变相邻层的接口就可以了。网络七层的划分也是为了使网络的不同功能模块（不同层次）分担起不同的职责，从而带来如下好处： 　
 ●   减轻问题的复杂程度，一旦网络发生故障，可迅速定位故障所处层次，便于查找和纠错； 　
 ●   在各层分别定义标准接口，使具备相同对等层的不同网络设备能实现互操作，各层之间则相对独立，一种高层协议可放在多种低层协议上运行； 　
 ●   能有效刺激网络技术革新，因为每次更新都可以在小范围内进行，不需对整个网络动大手术； 　
 ●   便于研究和教学。

#### 2. 各种协议的简单理解：

##### TCP/IP协议是一个协议簇。

TCP/IP协议不仅仅指的是TCP 和IP两个协议，而是指一个由FTP、SMTP、TCP、UDP、IP等协议构成的协议簇， 只是因为在TCP/IP协议中TCP协议和IP协议最具代表性，所以被称为TCP/IP协议。

TCP/IP（Transmission Control Protocol/Internet Protocol，传输控制协议/网际协议）协议集包括：应用层、传输层、网络层和数据链路层都包含其中。TCP/IP协议是Internet最基本的协议,其中应用层的主要协议有Telnet、FTP、SMTP等，是用来接收来自传输层的数据或者按不同应用要求与方式将数据传输至传输层；传输层的主要协议有UDP、TCP，是使用者使用平台和计算机信息网内部数据结合的通道，可以实现数据传输与数据共享；网络层的主要协议有ICMP、IP、IGMP，主要负责网络中数据包的传送等；而网络访问层，也叫网路接口层或数据链路层，主要协议有ARP、RARP，主要功能是提供链路管理错误检测、对不同通信媒介有关信息细节问题进行有效处理等。

应用层：

1. Telnet(远程登录)
2. FTP(文件传输协议)
3. SMTP(简单邮件传输协议)
4. SNMP(简单网络管理协议)
5. POP3(即邮局协议版本3)
6. TFTP简单文件传输协议

传输层：

1. TCP（传输控制协议支持有连接传输协议）
2. UDP（用户数据报协议支持无连接传输协议）

网络层：

1. IP-网际协议
2. ICMP-Internet控制报文协议(用于在主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息，典型应用就是ping)
3. IGMP(用于管理因特网协议多播组成员的一种通信协议)
4. RIP(内部网关协议-动态路由选择协议)
5. OSPF(Open Shortest Path First开放式最短路径优先)


数据链路层：

1. SDLC：软件生命周期
2. HDLC:（High-Level Data Link Control，高级数据链路控制），是链路层协议的一项国际标准，用以实现远程用户间资源共享以及信息交互。
3. STP（Spanning Tree Protocol）生成树协议
4. ARP正向地址解析协议（可放在链路层，也可放在网络层）、RARP反向地址解析协议：（ARP(ip->mac),RARP(mac->ip)）



##### Telnet

Telnet协议是[TCP/IP协议](https://baike.baidu.com/item/TCP%2FIP协议)族中的一员，是Internet远程登录服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程[主机](https://baike.baidu.com/item/主机/455151)工作的能力。在[终端](https://baike.baidu.com/item/终端/1903878)使用者的电脑上使用telnet程序，用它连接到[服务器](https://baike.baidu.com/item/服务器/100571)。[终端](https://baike.baidu.com/item/终端/1903878)使用者可以在telnet程序中输入命令，这些命令会在[服务器](https://baike.baidu.com/item/服务器/100571)上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制[服务器](https://baike.baidu.com/item/服务器/100571)。要开始一个telnet会话，必须输入用户名和密码来登录[服务器](https://baike.baidu.com/item/服务器/100571)。Telnet是常用的[远程控制](https://baike.baidu.com/item/远程控制/934368)Web[服务器](https://baike.baidu.com/item/服务器)的方法。



##### 那么Telnet跟ssh有什么区别呢？

ssh与telnet的相同点：

1.两种协议都可以远程登录另一台主机

2.两种协议都属于基于TCP/IP的协议

ssh与telnet的不同点：

1.telnet是明文传送；ssh是加密传送，并且支持压缩。

2.telnet的默认端口号为23；ssh的默认端口号为22.

3.ssh使用公钥对访问的服务器的用户验证身份，进一步提高的安全性；telnet没有使用公钥。



##### ssh的具体实现过程？

SSH是为远程登录和其他网络服务器提供安全性的协议，是目前使用较广泛且比较可靠的协议。SSH为了确保安全性，在会话建立和整个会话过程中使用了几种数据加密、处理的方式。包括：对称加密、非对称加密和密钥哈希函数。

###### 对称加密

[对称加密](https://en.wikipedia.org/wiki/Symmetric-key_algorithm)是指加密和解密都通过同一个密钥进行；或者是使用一个密钥对，其中一个用于加密而另一个用于解密，但这两个密钥间的关系是比较容易就能推导出来的，即通过其中一个可以推导出另一个（其实本质上还是一个密钥）。 假设A和B使用对称加密进行通信（使用同一个密钥），A给B发送信息：

<img src="https://aczero.github.io//assets/2016-02-20/1.png" alt="Symmetric encryption" style="zoom: 33%;" />

上图对称加密的过程可以这样描述：

1. A给B发送信息前，先使用密钥加密明文
2. A将密文发送给B
3. B收到密文，使用相同的密钥进行解密，获得A中的明文。

反过来B给A发信息也是一样的。



###### 非对称加密

[非对称加密](https://en.wikipedia.org/wiki/Public-key_cryptography)使用一个密钥对进行加密和解密。这个密钥对中一个称作公钥，另一个称作私钥。公钥只负责对信息进行加密，私钥只负责对信息进行解密，最重要的是，私钥是无法从公钥推导出来的。 同样我们假设A和B使用非对称加密进行通信，A给B发送信息： ![Asymmetric encryption](https://aczero.github.io//assets/2016-02-20/2.png)

上图的过程是这样的，B有一个密钥对（公钥和私钥）：

1. 首先，无论通过什么方式，B都要先将他的公钥分享给A。
2. A使用B的公钥对明文进行加密。
3. A将密文发送给B。
4. B收到密文，使用自己的私钥对信息进行解密，得到A的明文。

反过来，若B要给A发送信息，那么B也必须知道A的公钥。



###### 密文哈希算法

要注意的是，[密文哈希算法](https://en.wikipedia.org/wiki/Cryptographic_hash_function)并不是一种加密算法。哈希算法对于数据的处理是单向的，即明文到密文的过程不可逆，无法从哈希算法得到的结果去获得原来的信息。同时，哈希算法可以把任意长度的信息处理成固定长度的结果。此外，相同明文进行哈希算法得到的结果永远是相通的，而不同明文几乎不可能得到相同的结果（理想状态的话是完全不可能得到。）



###### Diffie-Hellman算法

[Diffie-Hellman算法](https://en.wikipedia.org/wiki/Diffie–Hellman_key_exchange)是一种密钥交换算法,用于生成密钥和通信双方交换共享密钥（用于对称加密的密钥），他可以保证通信的双方一起参与到共享密钥的生成过程，而且确保密钥在交换过程中的安全性，即使第三方窃听了通信信息，也无法获得共享密钥。 中间人攻击，对Diffie-Hellman协议的安全性造成威胁。一般Diffie-Hellman算法的步骤如下：

- 双方商定一个较大的素数作为种子值。
- 双方商定一种加密方式（一般为AES），用于处理数据。

<img src="https://aczero.github.io//assets/2016-02-20/3.png" alt="stage1" style="zoom:33%;" />

- 双方独自生成另外一个素数，且不能让另一方知道。这个素数可以说是交互过程中的私钥。

<img src="https://aczero.github.io//assets/2016-02-20/4.png" alt="stage2" style="zoom:33%;" />

- 双方使用各自的私有素数（私钥）、以及共享的素数（种子值），通过商定的加密方式产生公钥，此公钥是可以公开给另一方的。
- 双方交换他们生成的公钥。

<img src="https://aczero.github.io//assets/2016-02-20/5.png" alt="stage3" style="zoom:33%;" />

- 收到公钥后，使用自己的私钥，对方的公钥以及共享的素数（种子值）计算出共享密钥，尽管这个共享密钥是通过对方的私钥和公钥计算出来的，但双方最后都会获得相同的共享密钥。

<img src="https://aczero.github.io//assets/2016-02-20/6.png" alt="stage4" style="zoom:33%;" />

###### SSH登录过程

SSH的登录主要分为了两个阶段：(1)协商好客户端和服务器双方通信所使用的共享密钥，用这个共享密钥实现后续会话全过程的对称加密。(2)使用非对称加密方式验证客户端的身份。

(1) 协商会话所使用的共享密钥

这是SSH会话建立的第一个阶段，在这个阶段中主要使用到了Diffie-Hellman算法。 下图是客户端(A)与服务器(B)建立会话的过程：

<img src="https://aczero.github.io//assets/2016-02-20/7.png" alt="ssh stage1" style="zoom:33%;" />

1. 客户端发起TCP连接。
2. 服务器会返回其支持的协议版本以及服务器的公共主机密钥，公共主机密钥用于判断服务器是否预期的主机。
3. 双方通过Diffie-Hellman算法交换一个会话密钥。
4. 双方获得共享密钥，用于为后续会话做对称加密。

(2)验证用户对服务器的访问权限

在协商好会话使用的共享密钥后，将进行用户验证。有两种方法可以用于验证用户身份：

1. 密码认证
2. SSH密钥对

***密码认证***

使用密码认证时，服务器会想客户端请求登录账户的密码，这个密码会经过对称加密。 SSH密码认证的步骤如下： <img src="https://aczero.github.io//assets/2016-02-20/8.png" alt="img" style="zoom:33%;" />

1. 服务器收到客户端请求后，把自己的公钥发送给客户端（这跟SSH密钥对不同，是服务器自身的公钥/私钥对）。
2. 客户端使用收到的公钥加密密码，并发送回服务器。
3. 服务器使用自己私钥解密信息，若密码正确，则通过验证。

***SSH密钥对验证***

密码验证的安全性并不算好，推荐使用SSH密钥对验证。使用密钥对验证前，要先将客户端的SSH密钥对的公钥填到服务器对应账户的`authorized_keys`文件中。 SSH密钥对验证的步骤如下：

<img src="https://aczero.github.io//assets/2016-02-20/9.png" alt="img" style="zoom:33%;" /><img src="https://aczero.github.io//assets/2016-02-20/10.png" alt="img" style="zoom:33%;" />

1. 客户端把他用于验证的SSH密钥对的ID发送给服务器
2. 服务器根据密钥对ID在对应用户的`authorized_keys`文件中进行检索
3. 假设服务器在文件找到了符合密钥对ID的公钥，服务器将生成一个随机数，并用这个公钥进行加密。
4. 服务器将加密后的信息发送给客户端
5. 假设客户端拥有对应的私钥，那他就可以从加密信息中解密出原来的随机数。
6. 客户端将得到的随机数与加密会话所使用的会话密钥间拼接在一起后，计算出其MD5哈希值。
7. 客户端把MD5哈希值发送回服务器。
8. 服务器自己使用相同的会话共享密钥和他生成的随机数计算出MD5值，把它和客户端返回的MD5值进行比较。如果两个值相等，则证明客户端拥有对应私钥，将通过验证



##### 超文本传输协议（HTTP）

万维网的基本协议



##### 文件传输（TFTP简单文件传输协议）



##### 网络管理（SNMP简单网络管理协议）

该协议提供了监控网络设备的方法， 以及配置管理,统计信息收集,性能管理及安全管理等



##### 域名系统（DNS）

该系统用于在internet中将域名及其公共广播的网络节点转换成IP地址



##### 客户-服务器体系结构（B/S）

有一个总是打开的主机（服务器），为客户主机请求提供服务。

特点：

1、服务器有固定IP，服务器总是打开。

2、客户直接没有直接通信



##### 对等（P2P）体系结构

对等网络（peer-to-peer， 简称P2P），又称点对点技术，是无中心服务器、依靠用户群（peers）交换信息的互联网体系。是一种新的通信模式，每个参与者具有同等的能力，可以发起一个通信会话。与有中心服务器的中央网络系统不同，对等网络的每个用户端既是一个节点，也有服务器的功能，任何一个节点无法直接找到其他节点，必须依靠其户群进行信息交流。



比特币（Bitcoin）的概念最初由[中本聪](https://baike.baidu.com/item/中本聪/5740822)在2008年11月1日提出，并于2009年1月3日正式诞生 。根据中本聪的思路设计发布的[开源软件](https://baike.baidu.com/item/开源软件/8105369)以及建构其上的[P2P](https://baike.baidu.com/item/P2P)网络。比特币是一种P2P形式的[虚拟](https://baike.baidu.com/item/虚拟/10866735)的加密[数字货币](https://baike.baidu.com/item/数字货币/8159530)。点对点的传输意味着一个去中心化的[支付系统](https://baike.baidu.com/item/支付系统/2429152)。与所有的货币不同，比特币不依靠特定货币机构发行，它依据特定算法，通过大量的计算产生，比特币经济使用整个P2P网络中众多节点构成的[分布式数据库](https://baike.baidu.com/item/分布式数据库/1238109)来确认并记录所有的交易行为，并使用密码学的设计来确保货币流通各个环节[安全性](https://baike.baidu.com/item/安全性/7664678)。P2P的去中心化特性与算法本身可以确保无法通过大量制造比特币来人为操控币值。基于密码学的设计可以使比特币只能被真实的拥有者转移或支付。这同样确保了[货币](https://baike.baidu.com/item/货币/85299)所有权与流通交易的匿名性。比特币与其他[虚拟货币](https://baike.baidu.com/item/虚拟货币/322734)最大的不同，是其总数量非常有限，具有的[稀缺性](https://baike.baidu.com/item/稀缺性/5410168)。



##### **TCP**和**UDP**两者区别：

1） TCP提供面向连接的传输，通信前要先建立连接（三次握手机制）； UDP提供无连接的传输，通信前不需要建立连接。

2） TCP提供可靠的传输（有序，无差错，不丢失，不重复）； UDP提供不可靠的传输。

3） TCP面向字节流的传输，因此它能将信息分割成组，并在接收端将其重组； UDP是面向数据报的传输，没有分组开销。

4） TCP提供拥塞控制和流量控制机制； UDP不提供拥塞控制和流量控制机制。

| 类型 | 是否面向连接 | 传输可靠性 | 传输形式   | 传输效率 | 所需资源 | 应用场景           | 首部字节 |
| ---- | ------------ | ---------- | ---------- | -------- | -------- | ------------------ | -------- |
| TCP  | 是           | 可靠       | 字节流     | 慢       | 多       | 文件传输、邮件传输 | 20~60    |
| UDP  | 否           | 不可靠     | 数据报文段 | 快       | 少       | 即时通讯、域名转换 | 8个字节  |

##### TCP首部

<img src="https://nyimapicture.oss-cn-beijing.aliyuncs.com/img/20201208164319.png" alt="img" style="zoom: 67%;" />

首部固定部分各字段的意义如下：

1.源端口和目的端口，各占2个字节。

2.序号：占4个字节，序号范围为0到2的32次方-1，序号增加到2的32次方-1之后，下一个序号变为0，在一个TCP连接中传送的字节流中的每一个字节都按顺序编号。首部中的序号字段值指的是本报文段所发送的数据的第一个字节的序号。可对4GB（4GB～2^32B）的数据进行编号。在一般情况下可保证当序号重复使用时，旧序号的数据早已通过网络到达终点了。

3.确认号：占4字节，是期望收到对方下一个报文段的第一个数据字节的序号。记住：若确认号是N，则表明：到序号N-1为止的所有数据都已正确收到。

4.数据偏移：占4位，它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远，这个字段实际上是指出TCP报文段的首部长度。

6.保留：占6位。保留为今后使用，目前置为0

7.紧急URG（URGent）：当URG=1时，表明紧急字段有效，告诉系统此报文中有紧急数据，应尽快传送。于是发送方TCP就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍是普通数据。这时要与首部中紧急指针字段配合使用。

8.确认ACK（ACKnowlegment）仅当ACK=1时确认号字段才有效，TCP规定，连接建立后所有传送的报文段都必须把ACK置1.

9.推送PSH（PuSH）：当两个应用进程进行交互式的通信时，有时在一端的应用进程希望在键入一个命令后立即就能收到对方的响应。在这种情况下，TCP就可以使用推送操作。

10.复位RST（ReSeT）:当RST=1时，表明TCP连接中出现严重错误，必须释放连接，然后再重新建立运输连接。

11.同步SYN，在连接建立时用来同步序号，当SYN=1而ACK=0时，表明这是一个连接请求报文段。对方若同意时，则应在响应的报文段中使SYN=1和ACK=1，因此，SYN置1就表示这是一个连接请求或连接接受报文。

12.终止FIN，用来释放一个连接，当FIN=1时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。

13.窗口，占2个字节，窗口指的是发送本报文段的一方的接收窗口，不是自己的发送窗口，告诉对方：从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量。窗口值作为接受方让发送方设置其发送窗口的依据。

14.校验和，占2字节。校验和字段检验的范围包括首部和数据这两部分。

15.紧急指针：占2个字节，紧急指针仅在URG=1时才有意义，它指出本报文段中的紧急数据的字节数。当所有紧急数据处理完毕时，TCP就告诉应用程序恢复到正常操作。值得注意的是，即使窗口为0时也可发送紧急数据。

15.选项：长度可变，最长可达40字节，当没有选项时，TCP的首部长度是20字节。

最大报文段长度MSS，MSS是指每一个TCP报文段中的数据字段的最大长度。



##### **TCP/IP** **参考模型** 面试高频指数：★★★★★

① 应用层

TCP/IP 模型将 OSI 参考模型中的会话层、表示层和应用层的功能合并到一个应用层实现，通过不同的应用层协议为不同的应用提供服务。例如：FTP、Telnet、DNS、SMTP 等。

② 传输层

该层对应于 OSI 参考模型的传输层，为上层实体提供源端到对端主机的通信功能。传输层定义了两个主要协议：传输控制协议（TCP）和用户数据报协议（UDP）。其中面向连接的 TCP 协议保证了数据的传输可靠性，面向无连接的 UDP 协议能够实现数据包简单、快速地传输。

③ 网际互联层 网络层

网际互联层对应 OSI 参考模型的网络层，主要负责相同或不同网络中计算机之间的通信。在网际互联层， IP 协议提供的是一个不可靠、无连接的数据报传递服务。该协议实现两个基本功能：寻址和分段。根据数据报报头中的目的地址将数据传送到目的地址，在这个过程中 IP 负责选择传送路线。除了 IP 协议外，该层另外两个主要协议是互联网组管理协议（IGMP）和互联网控制报文协议（ICMP）。

④ 网络接口层 物理层和数据链路层

网络接口层的功能对应于 OSI 参考模型中的物理层和数据链路层，它负责监视数据在主机和网络之间的交换。事实上，TCP/IP 并未真正描述这一层的实现，而由参与互连的各网络使用自己的物理层和数据链路层协议，然后与 TCP/IP 的网络接入层进行连接，因此具体的实现方法将随着网络类型的不同而有所差异。

##### **TCP/IP** **五层参考模型** 面试高频指数：★★★☆☆

五层体系的协议结构是综合了 OSI 和 TCP/IP 优点的一种协议，包括应用层、传输层、网络层、数据链路层和物理层。其中应用层对应 OSI 的上三层，下四层和 OSI 相同。五层协议的体系结构只是为介绍网络原理而设计的，实际应用还是 TCP/IP 四层体系结构。



##### **OSI** **模型和** **TCP/IP** **模型异同比较** 面试高频指数：★★★★☆

**相同点**

① OSI 参考模型与 TCP/IP 参考模型都采用了层次结构。

② 都能够提供面向连接和无连接两种通信服务机制。

**不同点**

① OSI 采用的七层模型； TCP/IP 是四层结构。

② TCP/IP 参考模型没有对网络接口层进行细分，只是一些概念性的描述； OSI 参考模型对服务和协议做了明确的区分。

③ OSI 先有模型，后有协议规范，适合于描述各种网络；TCP/IP 是先有协议集然后建立模型，不适用于非 TCP/IP 网络。

④ TCP/IP 一开始就提出面向连接和无连接服务，而 OSI 一开始只强调面向连接服务，直到很晚才开始制定无连接的服务标准。

⑤ OSI 参考模型虽然被看好，但将网络划分为七层，实现起来较困难；相反，TCP/IP 参考模型虽然有许多不尽人意的地方，但作为一种简化的分层结构还是比较成功的。



##### **为什么** **TCP/IP** **去除了表示层和会话层** 面试高频指数：★★☆☆☆

OSI 参考模型在提出时，他们的理想是非常好的，但实际上，由于会话层、表示层、应用层都是在应用程序内部实现的，最终产出的是一个应用数据包，而应用程序之间是几乎无法实现代码的抽象共享的，这也就造成 OSI 设想中的应用程序维度的分层是无法实现的，例如，我们几乎不会认为数据的压缩、加密算法算是一种协议，而会话的概念则更为抽象，难以用协议来进行描述，所以在后来的 TCP/IP 协议框架的设计中，便将表示层和会话层与应用层整合在一起，让整个过程更为清晰明了。



##### **数据如何在各层之间传输【数据的封装过程】** 面试高频指数：★★★☆☆

在发送主机端，一个应用层报文被传送到运输层。在最简单的情况下，运输层收取到报文并附上附加信息，该首部将被接收端的运输层使用。应用层报文和运输层首部信息一道构成了运输层报文段。附加的信息可能包括：允许接收端运输层向上向适当的应用程序交付报文的信息以及差错检测位信息。该信息让接收端能够判断报文中的比特是否在途中已被改变。运输层则向网络层传递该报文段，网络层增加了如源和目的端系统地址等网络层首部信息，生成了网络层数据报。该数据报接下来被传递给数据链路层，在数据链路层数据包添加发送端 MAC 地址和接收端 MAC 地址后被封装成数据帧，在物理层数据帧被封装成比特流，之后通过传输介质传送到对端。



### **第二部分：应用层**

#### **HTTP** **头部包含哪些信息** 面试高频指数：★★★☆☆

HTTP 头部本质上是一个传递额外重要信息的键值对。主要分为：通用头部，请求头部，响应头部和实体头部。

**通用头部**

| **协议头**        | **说明**                                                     | **举例**                                        |
| ----------------- | ------------------------------------------------------------ | ----------------------------------------------- |
| Cache-Control     | 用来指定当前的请求/回复中是否使用缓存机制                    | Cache-Control: no-store                         |
| Connection        | 控制不再转发给代理的首部字段，管理持久连接                   | Connection:keep-alive (Upgrade)                 |
| Date              | 报文创建时间                                                 | Date: Dec, 26 Dec 2015 17: 30: 00 GMT           |
| Trailer           | 会实现说明在报文主体后记录哪些首部字段，该首部字段可以使用在HTTP/1.1 版本分块传输编码时 | Trailer: Expiress                               |
| Transfer-Encoding | 用来改变报文格式                                             | Transfer-Encoding: chunked                      |
| Upgrade           | 要求服务器升级到一个高版本协议                               | Upgrade: HTTP/2.0, SHTTP/1.3,  IRC/6.9, RTA/x11 |
| Via               | 告诉服务器，这个请求是由哪些代理发出的                       | Via: 1.0 fred, 1.1 itbilu.com.com (Apache/1.1)  |
| Warning           | 一个一般性的警告，表示在实体内容中可能存在错误               | Warning: 199 Miscellaneous warning              |

**请求头部**

| **协议头**      | **说明**                                                     | **举例**                                            |
| --------------- | ------------------------------------------------------------ | --------------------------------------------------- |
| Accept          | 告诉服务器自己允许哪些媒体类型                               | Accept: text/plain                                  |
| Accept-Charset  | 浏览器申明可接受的字符集                                     | Accept-Charset: utf-8                               |
| Accept-Encoding | 浏览器申明自己接收的编码方法                                 | Accept-Encoding: gzip, deflate                      |
| Accept-Language | 浏览器可接受的响应内容语言列表                               | Accept-Language: en-US                              |
| Authorization   | 用于表示 HTTP 协议中需要认证资源的认证信息                   | Authorization: Basic OSdjJGRpbjpvcGVul  ANIc2SdDE== |
| Expect          | 表示客户端要求服务器做出特定的行为                           | Expect: 100-continue                                |
| From            | 发起此请求的用户的邮件地址                                   | From: user@itbilu.com                               |
| Host            | 表示服务器的域名以及服务器所监听的端口号                     | Host: www.itbilu.com:80                             |
| If-XXX          | 条件请求                                                     | If-Modified-Since: Dec, 26 Dec 2015 17:30:00 GMT    |
| Max-Forwards    | 限制该消息可被代理及网关转发的次数                           | Max-Forwards: 10                                    |
| Range           | 表示请求某个实体的一部分，字节偏移以 0 开始                  | Range: bytes=500-999                                |
| Referer         | 表示浏览器所访问的前一个页面，可以认为是之前访问页面的链接将浏览器带到了当前页面 | Referer: http://itbilu.com/nodejs                   |
| User-Agent      | 浏览器的身份标识字符串                                       | User-Agent: Mozilla/……                              |

**响应头部**

| **协议头**    | **说明**                         | **举例**                                       |
| ------------- | -------------------------------- | ---------------------------------------------- |
| Accept-Ranges | 字段的值表示可用于定义范围的单位 | Accept-Ranges: bytes                           |
| Age           | 创建响应的时间                   | Age：5744337                                   |
| ETag          | 唯一标识分配的资源               | Etag：W/"585cd998-7c0f"                        |
| Location      | 表示重定向后的 URL               | Location:http://www.zcmhi.com/archives/94.html |
| Retry-After   | 告知客户端多久后再发送请求       | Retry-After: 120                               |
| Server        | 告知客户端服务器信息             | Server: Apache/1.3.27 (Unix)  (Red-Hat/Linux)  |
| Vary          | 缓存控制                         | Vary: Origin                                   |

**实体头部**

| **协议头**       | **说明**                                      | **举例**                                     |
| ---------------- | --------------------------------------------- | -------------------------------------------- |
| Allow            | 对某网络资源的有效的请求行为，不允许则返回405 | Allow: GET, HEAD                             |
| Content-encoding | 返回内容的编码方式                            | Content-Encoding: gzip                       |
| Content-Length   | 返回内容的字节长度                            | Content-Length: 348                          |
| Content-Language | 响应体的语言                                  | Content-Language: en,zh                      |
| Content-Location | 请求资源可替代的备用的另一地址                | Content-Location: /index.htm                 |
| Content-MD5      | 返回资源的MD5校验值                           | Content-MD5:  Q2hlY2sgSW50ZWdyaXR5IQ==       |
| Content-Range    | 在整个返回体中本部分的字节位置                | Content-Range: bytes 21010-47021/47022       |
| Content-Type     | 返回内容的MIME类型                            | Content-Type: text/html; charset=utf-8       |
| Expires          | 响应过期的日期和时间                          | Expires: Thu, 01 Dec 2010 16:00:00 GMT       |
| Last-Modified    | 请求资源的最后修改时间                        | Last-Modified: Tue, 15 Nov 2010 12:45:26 GMT |

#### Keep-Alive 和非 Keep-Alive 区别，对服务器性能有影响吗 面试高频指数：★★★☆☆

对于非 Keep=Alive 来说，必须为每一个请求的对象建立和维护一个全新的连接。对于每一个这样的连接，客户机和服务器都要分配 TCP 的缓冲区和变量，这给服务器带来的严重的负担，因为一台 Web 服务器可能同时服务于数以百计的客户机请求。在 Keep-Alive 方式下，服务器在响应后保持该 TCP 连接打开，在同一个客户机与服务器之间的后续请求和响应报文可通过相同的连接进行传送。甚至位于同一台服务器的多个 Web 页面在从该服务器发送给同一个客户机时，可以在单个持久 TCP 连接上进行。

http1.0中默认是关闭的，需要在http头加入”Connection: Keep-Alive”，才能启用Keep-Alive； 
http 1.1中默认启用Keep-Alive，如果加入”Connection: close “才关闭。目前大部分浏览器都是用http1.1协议，也就是说默认都会发起Keep-Alive的连接请求了，所以是否能完成一个完整的Keep- Alive连接就看服务器设置情况。

然而，Keep-Alive 并不是没有缺点的，当长时间的保持 TCP 连接时容易导致系统资源被无效占用，若对 Keep-Alive 模式配置不当，将有可能比非 Keep-Alive 模式带来的损失更大。因此，我们需要正确地设置 keep-alive timeout 参数，当 TCP 连接在传送完最后一个 HTTP 响应，该连接会保持 keepalive_timeout 秒，之后就开始关闭这个链接。

#### **HTTP** **长连接短连接使用场景是什么** 面试高频指数：★★★☆☆

长连接：多用于操作频繁，点对点的通讯，而且客户端连接数目较少的情况。例如即时通讯、网络游戏等。

短连接：用户数目较多的Web网站的 HTTP 服务一般用短连接。例如京东，淘宝这样的大型网站一般客户端数量达到千万级甚至上亿，若采用长连接势必会使得服务端大量的资源被无效占用，所以一般使用的是短连接。

#### **怎么知道** **HTTP** **的报文长度** 面试高频指数：★★☆☆☆

当响应消息中存在 Content-Length 字段时，我们可以直接根据这个值来判断数据是否接收完成，例如客户端向服务器请求一个静态页面或者一张图片时，服务器能够很清楚的知道请求内容的大小，因此可以通过消息首部字段 Content- Length 来告诉客户端需要接收多少数据，但是如果服务器预先不知道请求内容的大小，例如加载动态页面的时候，就需要使用 Transfer-Encoding: chunked 的方式来代替 Content-Length。

分块传输编码（Chunked transfer encoding）是 HTTP/1.1 中引入的一种数据传输机制，其允许 HTTP 由服务器发送给客户端的数据可以分成多个部分，当数据分解成一系列数据块发送时，服务器就可以发送数据而不需要预先知道发送内容的总大小，每一个分块包含十六进制的长度值和数据，最后一个分块长度值为0，表示实体结束，客户机可以以此为标志确认数据已经接收完毕。

#### **HTTP** **方法了解哪些** 面试高频指数：★★★☆☆

HTTP/1.0 定义了三种请求方法：GET, POST 和 HEAD 方法。

HTTP/1.1 增加了六种请求方法：OPTIONS, PUT, PATCH, DELETE, TRACE 和 CONNECT 方法。

| **方法** | **描述**                                                     |
| -------- | ------------------------------------------------------------ |
| GET      | 请求指定的页面信息，并返回具体内容，通常只用于读取数据。     |
| HEAD     | 类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头。 |
| POST     | 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立或已有资源的更改。 |
| PUT      | 替换指定的资源，没有的话就新增。                             |
| DELETE   | 请求服务器删除 URL 标识的资源数据。                          |
| CONNECT  | 将服务器作为代理，让服务器代替用户进行访问其他页面。（翻墙） |
| OPTIONS  | 向服务器发送该方法，会返回对指定资源所支持的 HTTP 请求方法。 |
| TRACE    | 回显服务器收到的请求数据，即服务器返回自己收到的数据，主要用于测试和诊断。 |
| PATCH    | 是对 PUT 方法的补充，用来对已知资源进行局部更新。            |



#### HTTP1.0和HTTP1.1和HTTP2.0的区别

**HTTP1.0和HTTP1.1的区别**

    1.1 长连接(Persistent Connection)
       HTTP1.1支持长连接和请求的流水线处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启长连接keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。HTTP1.0需要使用keep-alive参数来告知服务器端要建立一个长连接。
    1.2 节约带宽
           HTTP1.0中存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能。HTTP1.1支持只发送header信息（不带任何body信息），如果服务器认为客户端有权限请求服务器，则返回100，客户端接收到100才开始把请求body发送到服务器；如果返回401，客户端就可以不用发送请求body了节约了带宽。
    1.3 HOST域
           在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname），HTTP1.0没有host域。随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都支持host域，且请求消息中如果没有host域会报告一个错误（400 Bad Request）。
    1.4缓存处理
           在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。
    1.5错误通知的管理
           在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

**HTTP1.1和HTTP2.0的区别**

    2.1 多路复用
      HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的。

<img src="/Users/rb/Desktop/找工作的资料/我的整理笔记/图片 2.jpg" alt="图片 2" style="zoom: 67%;" />



      2.2 头部数据压缩
      在HTTP1.1中，HTTP请求和响应都是由状态行、请求/响应头部、消息主体三部分组成。一般而言，消息主体都会经过gzip压缩，或者本身传输的就是压缩过后的二进制文件，但状态行和头部却没有经过任何压缩，直接以纯文本传输。随着Web功能越来越复杂，每个页面产生的请求数也越来越多，导致消耗在头部的流量越来越多，尤其是每次都要传输UserAgent、Cookie这类不会频繁变动的内容，完全是一种浪费。
       HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。


    2.3 服务器推送
       服务端推送是一种在客户端请求之前发送数据的机制。网页使用了许多资源：HTML、样式表、脚本、图片等等。在HTTP1.1中这些资源每一个都必须明确地请求。这是一个很慢的过程。浏览器从获取HTML开始，然后在它解析和评估页面的时候，增量地获取更多的资源。因为服务器必须等待浏览器做每一个请求，网络经常是空闲的和未充分使用的。
    
       为了改善延迟，HTTP2.0引入了server push，它允许服务端推送资源给浏览器，在浏览器明确地请求之前，免得客户端再次创建连接发送请求到服务器端获取。这样客户端可以直接从本地加载这些资源，不用再通过网络。

<img src="/Users/rb/Desktop/找工作的资料/我的整理笔记/图片 3.jpg" alt="图片 3" style="zoom: 67%;" />



#### GET 和 POST 的区别 面试高频指数：★★★★★

对于GET方式的请求，浏览器会把http header和data一并发送出去，服务端响应200，请求成功。对于POST方式的请求，浏览器会先发送http header给服务端，告诉服务端等一下会有数据过来，服务端响应100 continue，告诉浏览器我已经准备接收数据，浏览器再post发送一个data给服务端，服务端响应200，请求成功。

get 提交的数据会放在 URL 之后，并且请求参数会被完整的保留在浏览器的记录里，由于参数直接暴露在 URL 中，可能会存在安全问题，因此往往用于获取资源信息。而 post 参数放在请求主体中，并且参数不会被保留，相比 get 方法，post 方法更安全，主要用于修改服务器上的资源。

get 请求只支持 URL 编码，post 请求支持多种编码格式。（PS: URL 编码就是一种浏览器用来打包表单输入的格式。浏览器从表单中获取所有的name和其中的值 ，将它们以name/value参数编码（移去那些不能传送的字符，将数据排行等等）作为URL的一部分或者分离地发给服务器。URL 编码会将字符转换为可通过因特网传输的格式。）

get 只支持 ASCII 字符格式的参数，而 post 方法没有限制。

get 提交的数据大小有限制（这里所说的限制是针对浏览器而言的），而 post 方法提交的数据没限制

get 方式需要使用 Request.QueryString 来取得变量的值，而 post 方式通过 Request.Form 来获取。

get 方法产生一个 TCP 数据包，post 方法产生两个（并不是所有的浏览器中都产生两个）。



#### **GET** **的长度限制是多少** 面试高频指数：★★★☆☆

HTTP 中的 GET 方法是通过 URL 传递数据的，而 URL 本身并没有对数据的长度进行限制，真正限制 GET 长度的是浏览器，例如 IE 浏览器对 URL 的最大限制为 2000多个字符，大概 2KB左右，像 Chrome, FireFox 等浏览器能支持的 URL 字符数更多，其中 FireFox 中 URL 最大长度限制为 65536 个字符，Chrome 浏览器中 URL 最大长度限制为 8182 个字符。并且这个长度不是只针对数据部分，而是针对整个 URL 而言，在这之中，不同的服务器同样影响 URL 的最大长度限制。因此对于特定的浏览器，GET的长度限制不同。

由于 POST 方法请求参数在请求主体中，理论上讲，post 方法是没有大小限制的，而真正起限制作用的是服务器处理程序的处理能力。

------



#### 如何处理Get请求的中文乱码问题？

  1、如果使用tomcat作为服务器，那么修改tomcat配置文件conf/server.xml中，在 <Connector port="8082" protocol="HTTP/1.1" 中加入 URIEncoding="utf-8"的编码集

 2、前台需要对中文参数进行编码，调用js方法encodeURI（url），将url编码，然后请求。

​         后台接受时，需处理String str = new String(request.getParameter("param").getBytes("iso8859-1"),"UTF-8");

​         原因：tomcat不设置编码时，默认是iso8859-1，即tomcat默认会以iso8859-1编码接收get参数。 以上操作是将参数以iso8859-1编码转化为字节数组，然后再以UTF-8将字节数组转化为字符串。

​         另外需注意在框架的使用中：request.setCharacterEncoding(encoding);只对post请求有效。而且，spring的CharacterEncodingFilter也只是做了request(和response）.setCharacterEncoding(encoding);的操作。所以spring的filter配置不作用于get参数接收。



#### HTTP 与 HTTPs 的工作方式【建立连接的过程】 面试高频指数：★★★★☆

HTTP（Hyper Text Transfer Protocol: 超文本传输协议） 是一种简单的请求 - 响应协议，被用于在 Web 浏览器和网站服务器之间传递消息。HTTP 使用 TCP（而不是 UDP）作为它的支撑运输层协议。其默认工作在 TCP 协议 80 端口，HTTP 客户机发起一个与服务器的 TCP 连接，一旦连接建立，浏览器和服务器进程就可以通过套接字接口访问 TCP。客户机从套接字接口发送 HTTP 请求报文和接收 HTTP 响应报文。类似地，服务器也是从套接字接口接收 HTTP 请求报文和发送 HTTP 响应报文。其通信内容以明文的方式发送，不通过任何方式的数据加密。当通信结束时，客户端与服务器关闭连接。

HTTPS（Hyper Text Transfer Protocol over Secure Socket Layer）是以安全为目标的 HTTP 协议，在 HTTP 的基础上通过传输加密和身份认证的方式保证了传输过程的安全性。其工作流程如下：

① 客户端发起一个 HTTPS 请求，并连接到服务器的 443 端口，发送的信息主要包括自身所支持的算法列表和密钥长度等；

② 服务端将自身所支持的所有加密算法与客户端的算法列表进行对比并选择一种支持的加密算法，然后将它和其它密钥组件一同发送给客户端。

③ 服务器向客户端发送一个包含数字证书的报文，该数字证书中包含证书的颁发机构、过期时间、服务端的公钥等信息。

④ 最后服务端发送一个完成报文通知客户端 SSL 的第一阶段已经协商完成。

⑤ SSL 第一次协商完成后，客户端发送一个回应报文，报文中包含一个客户端生成的随机密码串，称为 pre_master_secre，并且该报文是经过证书中的公钥加密过的。

⑥ 紧接着客户端会发送一个报文提示服务端在此之后的报文是采用pre_master_secre 加密的。

⑦ 客户端向服务端发送一个 finish 报文，这次握手中包含第一次握手至今所有报文的整体校验值，最终协商是否完成取决于服务端能否成功解密。

⑧ 服务端同样发送与第 ⑥ 步中相同作用的报文，已让客户端进行确认，最后发送 finish 报文告诉客户端自己能够正确解密报文。

当服务端和客户端的 finish 报文交换完成之后，SSL 连接就算建立完成了，之后就进行和 HTTP 相同的通信过程，唯一不同的是在 HTTP 通信过程中并不是采用明文传输，而是采用对称加密的方式，其中对称密钥已经在 SSL 的建立过程中协商好了。

#### **HTTPS** **和** **HTTP** **的区别** 面试高频指数：★★★★☆

HTTP 协议以明文方式发送内容，数据都是未加密的，安全性较差。HTTPS 数据传输过程是加密的，安全性较好。

HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是 80 端口，后者是 443 端口。

HTTPS 协议需要到数字认证机构（Certificate Authority, CA）申请证书，一般需要一定的费用。

HTTP 页面响应比 HTTPS 快，主要因为 HTTP 使用 3 次握手建立连接，客户端和服务器需要握手 3 次，而 HTTPS 除了 TCP 的 3 次握手，还需要经历一个 SSL 协商过程。

#### **HTTPS** **的加密方式** 面试高频指数：★★★☆☆

HTTPS 采用对称加密和非对称加密相结合的方式，首先使用 SSL/TLS 协议进行加密传输，为了弥补非对称加密的缺点，HTTPS 采用证书来进一步加强非对称加密的安全性，通过非对称加密，客户端和服务端协商好之后进行通信传输的对称密钥，后续的所有信息都通过该对称秘钥进行加密解密，完成整个 HTTPS 的流程。

#### **客户端为什么信任第三方证书** 面试高频指数：★★☆☆☆

假设中间人篡改了证书原文，由于他没有 CA 机构的私钥，所以无法得到此时加密后的签名，因此无法篡改签名。客户端浏览器收到该证书后会发现原文和签名解密后的值不一致，则说明证书被中间人篡改，证书不可信，从而终止向服务器传输信息。

上述过程说明证书无法被篡改，我们考虑更严重的情况，例如中间人拿到了 CA 机构认证的证书，它想窃取网站 A 发送给客户端的信息，于是它成为中间人拦截到了 A 传给客户端的证书，然后将其替换为自己的证书。此时客户端浏览器收到的是被中间人掉包后的证书，但由于证书里包含了客户端请求的网站信息，因此客户端浏览器只需要把证书里的域名与自己请求的域名比对一下就知道证书有没有被掉包了。

#### **HTTP** **是不保存状态的协议****,****如何保存用户状态** 面试高频指数：★★★★☆

① 基于 Session 实现的会话保持

在客户端第一次向服务器发送 HTTP 请求后，服务器会创建一个 Session 对象并将客户端的身份信息以键值对的形式存储下来，然后分配一个会话标识（SessionId）给客户端，这个会话标识一般保存在客户端 Cookie 中，之后每次该浏览器发送 HTTP 请求都会带上 Cookie 中的 SessionId 到服务器，服务器根据会话标识就可以将之前的状态信息与会话联系起来，从而实现会话保持。

优点：安全性高，因为状态信息保存在服务器端。

缺点：由于大型网站往往采用的是分布式服务器，浏览器发送的 HTTP 请求一般要先通过负载均衡器才能到达具体的后台服务器，倘若同一个浏览器两次 HTTP 请求分别落在不同的服务器上时，基于 Session 的方法就不能实现会话保持了。

【解决方法：采用中间件，例如 Redis，我们通过将 Session 的信息存储在 Redis 中，使得每个服务器都可以访问到之前的状态信息】

② 基于 Cookie 实现的会话保持

当服务器发送响应消息时，在 HTTP 响应头中设置 Set-Cookie 字段，用来存储客户端的状态信息。客户端解析出 HTTP 响应头中的字段信息，并根据其生命周期创建不同的 Cookie，这样一来每次浏览器发送 HTTP 请求的时候都会带上 Cookie 字段，从而实现状态保持。基于 Cookie 的会话保持与基于 Session 实现的会话保持最主要的区别是前者完全将会话状态信息存储在浏览器 Cookie 中。

优点：服务器不用保存状态信息， 减轻服务器存储压力，同时便于服务端做水平拓展。

缺点：该方式不够安全，因为状态信息存储在客户端，这意味着不能在会话中保存机密数据。除此之外，浏览器每次发起 HTTP 请求时都需要发送额外的 Cookie 到服务器端，会占用更多带宽。

拓展：Cookie被禁用了怎么办？

若遇到 Cookie 被禁用的情况，则可以通过重写 URL 的方式将会话标识放在 URL 的参数里，也可以实现会话保持。

#### **状态码** **面试高频指数：****★★★★☆**

 **2XX——****表明请求被正常处理了**

1、200 OK：请求已正常处理。

2、204 No Content：请求处理成功，但没有任何资源可以返回给客户端，一般在只需要从客户端往服务器发送信息，而对客户端不需要发送新信息内容的情况下使用。

3、206 Partial Content：是对资源某一部分的请求，该状态码表示客户端进行了范围请求，而服务器成功执行了这部分的GET请求。响应报文中包含由Content-Range指定范围的实体内容。

**3XX——****表明浏览器需要执行某些特殊的处理以正确处理请求**

4、301 Moved Permanently：资源的uri已更新，你也更新下你的书签引用吧。永久性重定向，请求的资源已经被分配了新的URI，以后应使用资源现在所指的URI。

5、302 Found：资源的URI已临时定位到其他位置了，姑且算你已经知道了这个情况了。临时性重定向。和301相似，但302代表的资源不是永久性移动，只是临时性性质的。换句话说，已移动的资源对应的URI将来还有可能发生改变。

6、303 See Other：资源的URI已更新，你是否能临时按新的URI访问。该状态码表示由于请求对应的资源存在着另一个URL，应使用GET方法定向获取请求的资源。303状态码和302状态码有着相同的功能，但303状态码明确表示客户端应当采用GET方法获取资源，这点与302状态码有区别。

当301,302,303响应状态码返回时，几乎所有的浏览器都会把POST改成GET，并删除请求报文内的主体，之后请求会自动再次发送。

7、304 Not Modified：资源已找到，但未符合条件请求。该状态码表示客户端发送附带条件的请求时（采用GET方法的请求报文中包含If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since中任一首部）服务端允许请求访问资源，但因发生请求未满足条件的情况后，直接返回304.。

8、307 Temporary Redirect：临时重定向。与302有相同的含义。

4XX——表明客户端是发生错误的原因所在。

9、400 Bad Request：服务器端无法理解客户端发送的请求，请求报文中可能存在语法错误。

10、401 Unauthorized：该状态码表示发送的请求需要有通过HTTP认证（BASIC认证，DIGEST认证）的认证信息。

11、403 Forbidden：不允许访问那个资源。该状态码表明对请求资源的访问被服务器拒绝了。（权限，未授权IP等）

12、404 Not Found：服务器上没有请求的资源。路径错误等。

5XX——服务器本身发生错误

13、500 Internal Server Error：貌似内部资源出故障了。该状态码表明服务器端在执行请求时发生了错误。也有可能是web应用存在bug或某些临时故障。

14、503 Service Unavailable：抱歉，我现在正在忙着。该状态码表明服务器暂时处于超负载或正在停机维护，现在无法处理请求。

#### **HTTP/1.1** **和** **HTTP/1.0** **的区别** 面试高频指数：★★★☆☆

主要区别如下：

**缓存处理**：在 HTTP/1.0 中主要使用 header 里的 if-modified-Since, Expries 来做缓存判断的标准。而 HTTP/1.1 请求头中添加了更多与缓存相关的字段，从而支持更为灵活的缓存策略，例如 Entity-tag, If-Unmodified-Since, If-Match, If-None-Match 等可供选择的缓存头来控制缓存策略。

**节约带宽**： 当客户端请求某个资源时，HTTP/1.0 默认将该资源相关的整个对象传送给请求方，但很多时候可能客户端并不需要对象的所有信息。而在 HTTP/1.1 的请求头中引入了 range 头域，它允许只请求部分资源，其使得开发者可以多线程请求某一资源，从而充分的利用带宽资源，实现高效并发。

**错误通知的管理**：HTTP/1.1 在 1.0 的基础上新增了 24 个错误状态响应码，例如 414 表示客户端请求中所包含的 URL 地址太长，以至于服务器无法处理；410 表示所请求的资源已经被永久删除。

**Host** **请求头**：早期 HTTP/1.0 中认为每台服务器都绑定一个唯一的 IP 地址并提供单一的服务，请求消息中的 URL 并没有传递主机名。而随着虚拟主机的出现，一台物理服务器上可以存在多个虚拟主机，并且它们共享同一个 IP 地址。为了支持虚拟主机，HTTP/1.1 中添加了 host 请求头，请求消息和响应消息中应声明这个字段，若请求消息中缺少该字段时服务端会响应一个 404 错误状态码。

**长连接**：HTTP/1.0 默认浏览器和服务器之间保持短暂连接，浏览器的每次请求都需要与服务器建立一个 TCP 连接，服务器完成后立即断开 TCP 连接。HTTP/1.1 默认使用的是持久连接，其支持在同一个 TCP 请求中传送多个 HTTP 请求和响应。此之前的 HTTP 版本的默认连接都是使用非持久连接，如果想要在旧版本的 HTTP 协议上维持持久连接，则需要指定 Connection 的首部字段的值为 Keep-Alive。

#### **HTTP/1.X** **和** **HTTP/2.0** **的区别** 面试高频指数：★★★☆☆

相比于 HTTP/1.X 的文本（字符串）传送， HTTP/2.0 采用二进制传送。客户端和服务器传输数据时把数据分成帧，帧组成了数据流，流具有流 ID 标识和优先级，通过优先级以及流依赖能够一定程度上解决关键请求被阻塞的问题。

HTTP/2.0 支持多路复用。因为流 ID 的存在， 通过同一个 HTTP 请求可以实现多个 HTTP 请求传输，客户端和服务器可以通过流 ID 来标识究竟是哪个流从而定位到是哪个 HTTP 请求。

HTTP/2.0 头部压缩。HTTP/2.0 通过 gzip 和 compress 压缩头部然后再发送，同时通信双方会维护一张头信息表，所有字段都记录在这张表中，在每次 HTTP 传输时只需要传头字段在表中的索引即可，大大减小了重传次数和数据量。

HTTP/2.0 支持服务器推送。 服务器在客户端未经请求许可的情况下，可预先向客户端推送需要的内容，客户端在退出服务时可通过发送复位相关的请求来取消服务端的推送。

#### **HTTP/3** **了解吗** 面试高频指数：★★☆☆☆

**HTTP/2** **存在的问题**

我们知道，传统 Web 平台的数据传输都基于 TCP 协议，而 TCP 协议在创建连接之前不可避免的需要三次握手，如果需要提高数据交互的安全性，即增加传输层安全协议（TLS），还会增加更多的握手次数。 HTTP 从 1.0 到 2.0，其传输层都是基于 TCP 协议的。即使是带来巨大性能提升的 HTTP/2，也无法完全解决 TCP 协议存在的固有问题（慢启动，拥塞窗口尺寸的设置等）。此外，HTTP/2 多路复用只是减少了连接数，其队头的拥塞问题并没有完全解决，倘若 TCP 丢包率过大，则 HTTP/2 的表现将不如 HTTP/1.1。

**QUIC** **协议**

QUIC（Quick UDP Internet Connections），直译为快速 UDP 网络连接，是谷歌制定的一种基于 UDP 的低延迟传输协议。其主要目的是解决采用传输层 TCP 协议存在的问题，同时满足传输层和应用层对多连接、低延迟等的需求。该协议融合了 TCP, TLS, HTTP/2 等协议的特性，并基于 UDP传输。该协议带来的主要提升有：

低延迟连接。当客户端第一次连接服务器时，QUIC 只需要 1 RTT（Round-Trid Time）延迟就可以建立安全可靠的连接（采用 TLS 1.3 版本），相比于 TCP + TLS 的 3 次 RTT 要更加快捷。之后，客户端可以在本地缓存加密的认证信息，当再次与服务器建立连接时可以实现 0 RTT 的连接建立延迟。

QUIC 复用了 HTTP/2 协议的多路复用功能，由于 QUIC 基于 UDP，所以也避免了 HTTP/2存在的队头阻塞问题。

基于 UDP 协议的 QUIC 运行在用户域而不是系统内核，这使得 QUIC 协议可以快速的更新和部署，从而很好地解决了 TPC 协议部署及更新的困难。

QUIC 的报文是经过加密和认证的，除了少量的报文，其它所有的 QUIC 报文头部都经过了认证，报文主体经过了加密。只要有攻击者篡改 QUIC 报文，接收端都能及时发现。

具有向前纠错机制，每个数据包携带了除了本身内容外的部分其他数据包的内容，使得在出现少量丢包的情况下，尽量地减少其它包的重传次数，其通过牺牲单个包所携带的有效数据大小换来更少的重传次数，这在丢包数量较小的场景下能够带来一定程度的性能提升。

HTTP/3

HTTP/3 是在 QUIC 基础上发展起来的，其底层使用 UDP 进行数据传输，上层仍然使用 HTTP/2。在 UDP 与 HTTP/2 之间存在一个 QUIC 层，其中 TLS 加密过程在该层进行处理。HTTP/3 主要有以下几个特点：

① 使用 UDP 作为传输层进行通信；

② 在 UDP 之上的 QUIC 协议保证了 HTTP/3 的安全性。QUIC 在建立连接的过程中就完成了 TLS 加密握手；

③ 建立连接快，正常只需要 1 RTT 即可建立连接。如果有缓存之前的会话信息，则直接验证和建立连接，此过程 0 RTT。建立连接时，也可以带有少量业务数据；

④ 不和具体底层连接绑定，QUIC 为每个连接的两端分别分配了一个唯一 ID，上层连接只认这对逻辑 ID。网络切换或者断连时，只需要继续发送数据包即可完成连接的建立；

⑤ 使用 QPACK 进行头部压缩，因为 在 HTTP/2 中的 HPACK 要求传输过程有序，这会导致队头阻塞，而 QPACK 不存在这个问题。

#### **DNS** **的作用和原理** 面试高频指数：★★★★☆

DNS（Domain Name System）是域名系统的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，用于 TCP/IP 网络。

DNS 的作用：通常我们有两种方式识别主机：通过主机名或者 IP 地址。人们喜欢便于记忆的主机名表示，而路由器则喜欢定长的、有着层次结构的 IP 地址。为了满足这些不同的偏好，我们就需要一种能够进行主机名到 IP 地址转换的目录服务，域名系统作为将域名和 IP 地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。

DNS 域名解析原理

DNS 采用了分布式的设计方案，其域名空间采用一种树形的层次结构：

上图展示了 DNS 服务器的部分层次结构，从上到下依次为根域名服务器、顶级域名服务器和权威域名服务器。其实根域名服务器在因特网上有13个，大部分位于北美洲。第二层为顶级域服务器，这些服务器负责顶级域名（如 com、org、net、edu）和所有国家的顶级域名（如uk、fr、ca 和 jp）。在第三层为权威 DNS 服务器，因特网上具有公共可访问主机（例如 Web 服务器和邮件服务器）的每个组织机构必须提供公共可访问的 DNS 记录，这些记录由组织机构的权威 DNS 服务器负责保存，这些记录将这些主机的名称映射为 IP 地址。

除此之外，还有一类重要的 DNS 服务器，叫做本地 DNS 服务器。本地 DNS 服务器严格来说不在 DNS 服务器的层次结构中，但它对 DNS 层次结构是很重要的。一般来说，每个网络服务提供商（ISP） 都有一台本地 DNS 服务器。当主机与某个 ISP 相连时，该 ISP 提供一台主机的 IP 地址，该主机具有一台或多台其本地 DNS 服务器的 IP 地址。主机的本地 DNS 服务器通常和主机距离较近，当主机发起 DNS 请求时，该请求被发送到本地 DNS 服务器，它起着代理的作用，并将该请求转发到 DNS 服务器层次结构中。

我们以一个例子来了解 DNS 的工作原理，假设主机 A（IP 地址为 abc.xyz.edu） 想知道主机 B 的 IP 地址 （def.mn.edu），如下图所示，主机 A 首先向它的本地 DNS 服务器发送一个 DNS 查询报文。该查询报文含有被转换的主机名 def.mn.edu。本地 DNS 服务器将该报文转发到根 DNS 服务器，根 DNS 服务器注意到查询的 IP 地址前缀为 edu 后向本地 DNS 服务器返回负责 edu 的顶级域名服务器的 IP 地址列表。该本地 DNS 服务器则再次向这些 顶级域名服务器发送查询报文。该顶级域名服务器注意到 mn.edu 的前缀，并用权威域名服务器的 IP 地址进行响应。通常情况下，顶级域名服务器并不总是知道每台主机的权威 DNS 服务器的 IP 地址，而只知道中间的某个服务器，该中间 DNS 服务器依次能找到用于相应主机的 IP 地址，我们假设中间经历了权威服务器 ① 和 ②，最后找到了负责 def.mn.edu 的权威 DNS 服务器 ③，之后，本地 DNS 服务器直接向该服务器发送查询报文从而获得主机 B 的IP 地址。

在上图中，IP 地址的查询其实经历了两种查询方式，分别是递归查询和迭代查询。

拓展：域名解析查询的两种方式

递归查询：如果主机所询问的本地域名服务器不知道被查询域名的 IP 地址，那么本地域名服务器就以 DNS 客户端的身份，向其他根域名服务器继续发出查询请求报文，即替主机继续查询，而不是让主机自己进行下一步查询，如上图步骤（1）和（10）。

迭代查询：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地服务器下一步应该找哪个域名服务器进行查询，然后让本地服务器进行后续的查询，如上图步骤（2）~（9）。

#### **DNS** **为什么用** **UDP** 面试高频指数：★★☆☆☆

更正确的答案是 DNS 既使用 TCP 又使用 UDP。

当进行区域传送（主域名服务器向辅助域名服务器传送变化的那部分数据）时会使用 TCP，因为数据同步传送的数据量比一个请求和应答的数据量要多，而 TCP 允许的报文长度更长，因此为了保证数据的正确性，会使用基于可靠连接的 TCP。

当客户端向 DNS 服务器查询域名 ( 域名解析) 的时候，一般返回的内容不会超过 UDP 报文的最大长度，即 512 字节。用 UDP 传输时，不需要经过 TCP 三次握手的过程，从而大大提高了响应速度，但这要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。

#### **怎么实现** **DNS** **劫持** 面试高频指数：★★★☆☆

DNS 劫持即域名劫持，是通过将原域名对应的 IP 地址进行替换从而使得用户访问到错误的网站或者使得用户无法正常访问网站的一种攻击方式。域名劫持往往只能在特定的网络范围内进行，范围外的 DNS 服务器能够返回正常的 IP 地址。攻击者可以冒充原域名所属机构，通过电子邮件的方式修改组织机构的域名注册信息，或者将域名转让给其它组织，并将新的域名信息保存在所指定的 DNS 服务器中，从而使得用户无法通过对原域名进行解析来访问目的网址。

具体实施步骤如下：

① 获取要劫持的域名信息：攻击者首先会访问域名查询站点查询要劫持的域名信息。

② 控制域名相应的 E-MAIL 账号：在获取到域名信息后，攻击者通过暴力破解或者专门的方法破解公司注册域名时使用的 E-mail 账号所对应的密码。更高级的攻击者甚至能够直接对 E-mail 进行信息窃取。

③ 修改注册信息：当攻击者破解了 E-MAIL 后，会利用相关的更改功能修改该域名的注册信息，包括域名拥有者信息，DNS 服务器信息等。

④ 使用 E-MAIL 收发确认函：在修改完注册信息后，攻击者在 E-mail 真正拥有者之前收到修改域名注册信息的相关确认信息，并回复确认修改文件，待网络公司恢复已成功修改信件后，攻击者便成功完成 DNS 劫持。

用户端的一些预防手段：

直接通过 IP 地址访问网站，避开 DNS 劫持。

由于域名劫持往往只能在特定的网络范围内进行，因此一些高级用户可以通过网络设置让 DNS 指向正常的域名服务器以实现对目的网址的正常访问，例如将计算机首选 DNS 服务器的地址固定为 8.8.8.8。

#### **socket()** **套接字有哪些**面试高频指数：★★★☆☆

套接字（Socket）是对网络中不同主机上的应用进程之间进行双向通信的端点的抽象，网络进程通信的一端就是一个套接字，不同主机上的进程便是通过套接字发送报文来进行通信。例如 TCP 用主机的 IP 地址 + 端口号作为 TCP 连接的端点，这个端点就叫做套接字。

套接字主要有以下三种类型：

流套接字（SOCK_STREAM）：流套接字基于 TCP 传输协议，主要用于提供面向连接、可靠的数据传输服务。由于 TCP 协议的特点，使用流套接字进行通信时能够保证数据无差错、无重复传送，并按顺序接收，通信双方不需要在程序中进行相应的处理。

数据报套接字（SOCK_DGRAM）：和流套接字不同，数据报套接字基于 UDP 传输协议，对应于无连接的 UDP 服务应用。该服务并不能保证数据传输的可靠性，也无法保证对端能够顺序接收到数据。此外，通信两端不需建立长时间的连接关系，当 UDP 客户端发送一个数据给服务器后，其可以通过同一个套接字给另一个服务器发送数据。当用 UDP 套接字时，丢包等问题需要在程序中进行处理。

·    原始套接字（SOCK_RAW）：由于流套接字和数据报套接字只能读取 TCP 和 UDP 协议的数据，当需要传送非传输层数据包（例如 Ping 命令时用的 ICMP 协议数据包）或者遇到操作操作系统无法处理的数据包时，此时就需要建立原始套接字来发送。

#### URI（统一资源标识符）和 URL（统一资源定位符）之间的区别 面试高频指数：★★★☆☆

URL，即统一资源定位符 (Uniform Resource Locator )，URL 其实就是我们平时上网时输入的网址，它标识一个互联网资源，并指定对其进行操作或获取该资源的方法。例如 https://leetcode-cn.com/problemset/all/ 这个 URL，标识一个特定资源并表示该资源的某种形式是可以通过 HTTP 协议从相应位置获得。

从定义即可看出，URL 是 URI 的一个子集，两者都定义了资源是什么，而 URL 还定义了如何能访问到该资源。URI 是一种语义上的抽象概念，可以是绝对的，也可以是相对的，而URL则必须提供足够的信息来定位，是绝对的。简单地说，只要能唯一标识资源的就是 URI，在 URI 的基础上给出其资源的访问方式的就是 URL。

#### 为什么 fidder，charles 能抓到你的包【抓取数据包的过程】面试高频指数：★★☆☆☆

假如我们需要抓取客户端的数据包，需要监控客户端与服务器交互之间的网络节点，监控其中任意一个网络节点（网卡），获取所有经过网卡中的数据，对这些数据按照网络协议进行解析，这就是抓包的基本原理。而中间的网络节点不受我们控制，是基本无法实现抓包的，因此只能在客户端与服务器之间进行抓包。

① 当采用抓包工具抓取 HTTP 数据包时，过程较为简单：

首先抓包工具会提出代理服务，客户端需要连接该代理；

客户端发出 HTTP 请求时，会经过抓包工具的代理，抓包工具将请求的原文进行展示；

抓包工具使用该原文将请求发送给服务器；

服务器返回结果给抓包工具，抓包工具将返回结果进行展示；

抓包工具将服务器返回的结果原样返回给客户端。

这里抓包工具相当于透明人，数据经过的时候它一只手接到数据，然后另一只手把数据传出去。

② 当抓取 HTTPS 数据包时：

客户端连接抓包工具提供的代理服务，并安装抓包工具的根证书；

客户端发出 HTTPS 请求，抓包工具模拟服务器与客户端进行 TLS 握手交换密钥等流程；

抓包工具发送一个 HTTPS 请求给客户端请求的目标服务器，并与目标服务器进行 TLS 握手交换密钥等流程；

客户端使用与抓包工具协定好的密钥加密数据后发送给抓包工具；

抓包工具使用与客户端协定好的密钥解密数据，并将结果进行展示；

抓包工具将解密后的客户端数据，使用与服务器协定好的密钥进行加密后发送给目标服务器；

服务器解密数据后，做对应的逻辑处理，然后将返回结果使用与抓包工具协定好的密钥进行加密发送给抓包工具；

抓包工具将服务器返回的结果，用与服务器协定好的密钥解密，并将结果进行展示；

抓包工具将解密后的服务器返回数据，使用与客户端协定好的密钥进行加密后发送给客户端；

客户端解密数据。

这个时候抓包工具对客户端来说相当于服务器，对服务器来说相当于客户端。在这个传输过程中，客户端会以为它就是目标服务器，服务器也会以为它就是请求发起的客户端。

#### 如果你访问一个网站很慢，怎么排查和解决 面试高频指数：★★★☆☆

网页打开速度慢的原因有很多，这里列举出一些较常出现的问题：

① 首先最直接的方法是查看本地网络是否正常，可以通过网络测速软件例如电脑管家等对电脑进行测速，若网速正常，我们查看网络带宽是否被占用，例如当你正在下载电影时并且没有限速，是会影响你打开网页的速度的，这种情况往往是处理器内存小导致的；

② 当网速测试正常时，我们对网站服务器速度进行排查，通过 ping 命令查看链接到服务器的时间和丢包等情况，一个速度好的机房，首先丢包率不能超过 1%，其次 ping 值要小，最后是 ping 值要稳定，如最大和最小差值过大说明路由不稳定。或者我们也可以查看同台服务器上其他网站的打开速度，看是否其他网站打开也慢。

③ 如果网页打开的速度时快时慢，甚至有时候打不开，有可能是空间不稳定的原因。当确定是该问题时，就要找你的空间商解决或换空间商了，如果购买空间的话，可选择购买购买双线空间或多线空间；如果是在有的地方打开速度快，有的地方打开速度慢，那应该是网络线路的问题。电信线路用户访问放在联通服务器的网站，联通线路用户访问放在电信服务器上的网站，相对来说打开速度肯定是比较慢。

④ 从网站本身找原因。网站的问题主要包括网站程序设计、网页设计结构和网页内容三个部分。

网站程序设计：当访问网页中有拖慢网站打开速度的代码，会影响网页的打开速度，例如网页中的统计代码，我们最好将其放在网站的末尾。因此我们需要查看网页程序的设计结构是否合理；

网页设计结构：如果是 table 布局的网站，查看是否嵌套次数太多，或是一个大表格分成多个表格这样的网页布局，此时我们可以采用 div 布局并配合 css 进行优化。

网页内容：查看网页中是否有许多尺寸大的图片或者尺寸大的 flash 存在，我们可以通过降低图片质量，减小图片尺寸，少用大型 flash 加以解决。此外，有的网页可能过多地引用了其他网站的内容，若某些被引用的网站访问速度慢，或者一些页面已经不存在了，打开的速度也会变慢。一种直接的解决方法是去除不必要的加载项。

**交换机和路由器的区别**

交换机拥有一条很高带宽的背部总线和内部交换矩阵。交换机的所有的端口都挂接在这条总线上，控制电路收到数据包以后，处理端口会查找内存中的地址对照表以确定目的MAC（网卡的硬件地址）的NIC（网卡）挂接在哪个端口上，通过内部交换矩阵迅速将数据包传送到目的端口，目的MAC若不存在则广播到所有的端口，接收端口回应后交换机会“学习”新的地址，并把它添加入内部MAC地址表中。

使用交换机也可以把网络“分段”，通过对照MAC地址表，交换机只允许必要的网络流量通过交换机。通过交换机的过滤和转发，可以有效的隔离广播风暴，减少误包和错包的出现，避免共享冲突。

交换机在同一时刻可进行多个端口对之间的数据传输。每一端口都可视为独立的网段，连接在其上的网络设备独自享有全部的带宽，无须同其他设备竞争使用。当节点A向节点D发送数据时，节点B可同时向节点C发送数据，而且这两个传输都享有网络的全部带宽，都有着自己的虚拟连接。假使这里使用的是10Mbps的以太网交换机，那么该交换机这时的总流通量就等于2×10Mbps＝20Mbps，而使用10Mbps的共享式HUB时，一个HUB的总流通量也不会超出10Mbps。

总之，交换机是一种基于MAC地址识别，能完成封装转发数据包功能的网络设备。交换机可以“学习”MAC地址，并把其存放在内部地址表中，通过在数据帧的始发者和目标接收者之间建立临时的交换路径，使数据帧直接由源地址到达目的地址。

从过滤网络流量的角度来看，路由器的作用与交换机和网桥非常相似。但是与工作在网络物理层，从物理上划分网段的交换机不同，路由器使用专门的软件协议从逻辑上对整个网络进行划分。例如，一台支持IP协议的路由器可以把网络划分成多个子网段，只有指向特殊IP地址的网络流量才可以通过路由器。对于每一个接收到的数据包，路由器都会重新计算其校验值，并写入新的物理地址。因此，使用路由器转发和过滤数据的速度往往要比只查看数据包物理地址的交换机慢。但是，对于那些结构复杂的网络，使用路由器可以提高网络的整体效率。路由器的另外一个明显优势就是可以自动过滤网络广播。

集线器与路由器在功能上有什么不同?

首先说HUB,也就是集线器。它的作用可以简单的理解为将一些机器连接起来组成一个局域网。而交换机（又名交换式集线器）作用与集线器大体相同。但是两者在性能上有区别：集线器采用的式共享带宽的工作方式，而交换机是独享带宽。这样在机器很多或数据量很大时，两者将会有比较明显的。而路由器与以上两者有明显区别，它的作用在于连接不同的网段并且找到网络中数据传输最合适的路径。路由器是产生于交换机之后，就像交换机产生于集线器之后，所以路由器与交换机也有一定联系，不是完全独立的两种设备。路由器主要克服了交换机不能路由转发数据包的不足。

总的来说，路由器与交换机的主要区别体现在以下几个方面：

（1）工作层次不同
 最初的的交换机是工作在数据链路层，而路由器一开始就设计工作在网络层。由于交换机工作在数据链路层，所以它的工作原理比较简单，而路由器工作在网络层，可以得到更多的协议信息，路由器可以做出更加智能的转发决策。

（2）数据转发所依据的对象不同
 交换机是利用物理地址或者说MAC地址来确定转发数据的目的地址。而路由器则是利用IP地址来确定数据转发的地址。IP地址是在软件中实现的，描述的是设备所在的网络。MAC地址通常是硬件自带的，由网卡生产商来分配的，而且已经固化到了网卡中去，一般来说是不可更改的。而IP地址则通常由网络管理员或系统自动分配。

（3）传统的交换机只能分割冲突域，不能分割广播域；而路由器可以分割广播域
 由交换机连接的网段仍属于同一个广播域，广播数据包会在交换机连接的所有网段上传播，在某些情况下会导致通信拥挤和安全漏洞。连接到路由器上的网段会被分配成不同的广播域，广播数据不会穿过路由器。虽然第三层以上交换机具有VLAN功能，也可以分割广播域，但是各子广播域之间是不能通信交流的，它们之间的交流仍然需要路由器。

（4）路由器提供了防火墙的服务
 路由器仅仅转发特定地址的数据包，不传送不支持路由协议的数据包传送和未知目标网络数据包的传送，从而可以防止广播风暴。

#### **其他协议**面试高频指数：★☆☆☆☆

对于应用层来说，考察的重点集中在 HTTP 协议和 DNS 这两块，其他协议考察较少，我们仅加以了解即可。

FTP

FTP（File Transfer Protocol，文件传输协议）是用于在网络上进行文件传输的一套标准协议，使用客户/服务器模式，使用 TCP 数据报，提供交互式访问，双向传输。

TFTP（Trivial File Transfer Protocol，简单文件传输协议）一个小且易实现的文件传输协议，也使用客户/服务器方式，使用 UDP 数据报，只支持文件传输而不支持交互，没有列目录，不能对用户进行身份鉴定。

SMTP

SMTP（Simple Main Transfer Protocol，简单邮件传输协议）是在 Internet 传输 Email 的标准，是一个相对简单的基于文本的协议。在其之上指定了一条消息的一个或多个接收者（在大多数情况下被确认是存在的），然后消息文本会被传输。可以很简单地通过 Telnet 程序来测试一个 SMTP 服务器。SMTP 使用 TCP 端口 25。 

DHCP

DHCP ( Dynamic Host Configuration Protocol，动态主机设置协议 ) 是一个局域网的网络协议，使用 UDP 协议工作，主要有两个用途： 

用于内部网络或网络服务供应商自动分配 IP 地址给用户

用于内部网络管理员作为对所有电脑作中央管理的手段

SNMP

SNMP（Simple Network Management Protocol，简单网络管理协议）构成了互联网工程工作小组（IETF，Internet Engineering Task Force）定义的 Internet 协议族的一部分。该协议能够支持网络管理系统，用以监测连接到网络上的设备是否有任何引起管理上关注的情况。

#### 网页解析全过程【用户输入网址到显示对应页面的全过程】面试高频指数：★★★★★

① DNS 解析：当用户输入一个网址并按下回车键的时候，浏览器获得一个域名，而在实际通信过程中，我们需要的是一个 IP 地址，因此我们需要先把域名转换成相应 IP 地址。【具体细节参看问题 16，17】

② TCP 连接：浏览器通过 DNS 获取到 Web 服务器真正的 IP 地址后，便向 Web 服务器发起 TCP 连接请求，通过 TCP 三次握手建立好连接后，浏览器便可以将 HTTP 请求数据发送给服务器了。【三次握手放在传输层详细讲解】

③ 发送 HTTP 请求：浏览器向 Web 服务器发起一个 HTTP 请求，HTTP 协议是建立在 TCP 协议之上的应用层协议，其本质是在建立起的TCP连接中，按照HTTP协议标准发送一个索要网页的请求。在这一过程中，会涉及到负载均衡等操作。 

拓展：什么是负载均衡？ 

负载均衡，英文名为 Load Balance，其含义是指将负载（工作任务）进行平衡、分摊到多个操作单元上进行运行，例如 FTP 服务器、Web 服务器、企业核心服务器和其他主要任务服务器等，从而协同完成工作任务。负载均衡建立在现有的网络之上，它提供了一种透明且廉价有效的方法扩展服务器和网络设备的带宽、增加吞吐量、加强网络处理能力并提高网络的灵活性和可用性。 

负载均衡是分布式系统架构设计中必须考虑的因素之一，例如天猫、京东等大型用户网站中为了处理海量用户发起的请求，其往往采用分布式服务器，并通过引入反向代理等方式将用户请求均匀分发到每个服务器上，而这一过程所实现的就是负载均衡。 

④ 处理请求并返回：服务器获取到客户端的 HTTP 请求后，会根据 HTTP 请求中的内容来决定如何获取相应的文件，并将文件发送给浏览器。 

⑤ 浏览器渲染：浏览器根据响应开始显示页面，首先解析 HTML 文件构建 DOM 树，然后解析 CSS 文件构建渲染树，等到渲染树构建完成后，浏览器开始布局渲染树并将其绘制到屏幕上。 

⑥ 断开连接：客户端和服务器通过四次挥手终止 TCP 连接。【其中的细节放在传输层详细讲解】

### **第三部分：传输层**

#### 三次握手和四次挥手机制  面试高频指数：★★★★★

三次握手

三次握手是 TCP 连接的建立过程。在握手之前，主动打开连接的客户端结束 CLOSE 阶段，被动打开的服务器也结束 CLOSE 阶段，并进入 LISTEN 阶段。随后进入三次握手阶段：

① 首先客户端向服务器发送一个 SYN 包，并等待服务器确认，其中： 

标志位为 SYN，表示请求建立连接；

序号为 Seq = x（x 一般为 1）；

随后客户端进入 SYN-SENT 阶段。

② 服务器接收到客户端发来的 SYN 包后，对该包进行确认后结束 LISTEN 阶段，并返回一段 TCP 报文，其中： 

标志位为 SYN 和 ACK，表示确认客户端的报文 Seq 序号有效，服务器能正常接收客户端发送的数据，并同意创建新连接；

序号为 Seq = y；

确认号为 Ack = x + 1，表示收到客户端的序号 Seq 并将其值加 1 作为自己确认号 Ack 的值，随后服务器端进入 SYN-RECV 阶段。

③ 客户端接收到发送的 SYN + ACK 包后，明确了从客户端到服务器的数据传输是正常的，从而结束 SYN-SENT 阶段。并返回最后一段报文。其中： 

标志位为 ACK，表示确认收到服务器端同意连接的信号；

序号为 Seq = x + 1，表示收到服务器端的确认号 Ack，并将其值作为自己的序号值；

确认号为 Ack= y + 1，表示收到服务器端序号 seq，并将其值加 1 作为自己的确认号 Ack 的值。

随后客户端进入 ESTABLISHED。

当服务器端收到来自客户端确认收到服务器数据的报文后，得知从服务器到客户端的数据传输是正常的，从而结束 SYN-RECV 阶段，进入 ESTABLISHED 阶段，从而完成三次握手。 

四次挥手： 

四次挥手即 TCP 连接的释放，这里假设客户端主动释放连接。在挥手之前主动释放连接的客户端结束 ESTABLISHED 阶段，随后开始四次挥手：

① 首先客户端向服务器发送一段 TCP 报文表明其想要释放 TCP 连接，其中：

标记位为 FIN，表示请求释放连接；

序号为 Seq = u；

随后客户端进入 FIN-WAIT-1 阶段，即半关闭阶段，并且停止向服务端发送通信数据。

② 服务器接收到客户端请求断开连接的 FIN 报文后，结束 ESTABLISHED 阶段，进入 CLOSE-WAIT 阶段并返回一段 TCP 报文，其中： 

标记位为 ACK，表示接收到客户端释放连接的请求；

序号为 Seq = v；

确认号为 Ack = u + 1，表示是在收到客户端报文的基础上，将其序号值加 1 作为本段报文确认号 Ack 的值；

随后服务器开始准备释放服务器端到客户端方向上的连接。

客户端收到服务器发送过来的 TCP 报文后，确认服务器已经收到了客户端连接释放的请求，随后客户端结束 FIN-WAIT-1 阶段，进入 FIN-WAIT-2 阶段。 

③ 服务器端在发出 ACK 确认报文后，服务器端会将遗留的待传数据传送给客户端，待传输完成后即经过 CLOSE-WAIT 阶段，便做好了释放服务器端到客户端的连接准备，再次向客户端发出一段 TCP 报文，其中： 

标记位为 FIN 和 ACK，表示已经准备好释放连接了；

序号为 Seq = w；

确认号 Ack = u + 1，表示是在收到客户端报文的基础上，将其序号 Seq 的值加 1 作为本段报文确认号 Ack 的值。

随后服务器端结束 CLOSE-WAIT 阶段，进入 LAST-ACK 阶段。并且停止向客户端发送数据。 

④ 客户端收到从服务器发来的 TCP 报文，确认了服务器已经做好释放连接的准备，于是结束 FIN-WAIT-2 阶段，进入 TIME-WAIT 阶段，并向服务器发送一段报文，其中： 

标记位为 ACK，表示接收到服务器准备好释放连接的信号；

序号为 Seq= u + 1，表示是在已收到服务器报文的基础上，将其确认号 Ack 值作为本段序号的值；

确认号为 Ack= w + 1，表示是在收到了服务器报文的基础上，将其序号 Seq 的值作为本段报文确认号的值。

随后客户端开始在 TIME-WAIT 阶段等待 2 MSL。服务器端收到从客户端发出的 TCP 报文之后结束 LAST-ACK 阶段，进入 CLOSED 阶段。由此正式确认关闭服务器端到客户端方向上的连接。客户端等待完 2 MSL 之后，结束 TIME-WAIT 阶段，进入 CLOSED 阶段，由此完成「四次挥手」。

#### **如果三次握手的时候每次握手信息对方没有收到会怎么样** 面试高频指数：★★★★☆

若第一次握手服务器未接收到客户端请求建立连接的数据包时，服务器不会进行任何相应的动作，而客户端由于在一段时间内没有收到服务器发来的确认报文， 因此会等待一段时间后重新发送 SYN 同步报文，若仍然没有回应，则重复上述过程直到发送次数超过最大重传次数限制后，建立连接的系统调用会返回 -1。

若第二次握手客户端未接收到服务器回应的 ACK 报文时，客户端会采取第一次握手失败时的动作，这里不再重复，而服务器端此时将阻塞在 accept() 系统调用处等待 client 再次发送 ACK 报文。

若第三次握手服务器未接收到客户端发送过来的 ACK 报文，同样会采取类似于客户端的超时重传机制，若重传次数超过限制后仍然没有回应，则 accep() 系统调用返回 -1，服务器端连接建立失败。但此时客户端认为自己已经连接成功了，因此开始向服务器端发送数据，但是服务器端的 accept() 系统调用已返回，此时没有在监听状态。因此服务器端接收到来自客户端发送来的数据时会发送 RST 报文给 客户端，消除客户端单方面建立连接的状态。

第 2 次握手传回了 ACK，为什么还要传回 SYN

面试高频指数：★★★★☆

ACK 是为了告诉客户端发来的数据已经接收无误，而传回 SYN 是为了告诉客户端，服务端收到的消息确实是客户端发送的消息。

为什么要四次挥手？

面试高频指数：★★★★☆

释放 TCP 连接时之所以需要四次挥手，是因为 FIN 释放连接报文和 ACK 确认接收报文是分别在两次握手中传输的。 当主动方在数据传送结束后发出连接释放的通知，由于被动方可能还有必要的数据要处理，所以会先返回 ACK 确认收到报文。当被动方也没有数据再发送的时候，则发出连接释放通知，对方确认后才完全关闭TCP连接。

举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。

CLOSE-WAIT 和 TIME-WAIT 的状态和意义

面试高频指数：★★★★★

在服务器收到客户端关闭连接的请求并告诉客户端自己已经成功收到了该请求之后，服务器进入了 CLOSE-WAIT 状态，然而此时有可能服务端还有一些数据没有传输完成，因此不能立即关闭连接，而 CLOSE-WAIT 状态就是为了保证服务器在关闭连接之前将待发送的数据发送完成。

TIME-WAIT 发生在第四次挥手，当客户端向服务端发送 ACK 确认报文后进入该状态，若取消该状态，即客户端在收到服务端的 FIN 报文后立即关闭连接，此时服务端相应的端口并没有关闭，若客户端在相同的端口立即建立新的连接，则有可能接收到上一次连接中残留的数据包，可能会导致不可预料的异常出现。除此之外，假设客户端最后一次发送的 ACK 包在传输的时候丢失了，由于 TCP 协议的超时重传机制，服务端将重发 FIN 报文，若客户端并没有维持 TIME-WAIT 状态而直接关闭的话，当收到服务端重新发送的 FIN 包时，客户端就会用 RST 包来响应服务端，这将会使得对方认为是有错误发生，然而其实只是正常的关闭连接过程，并没有出现异常情况。 

TIME_WAIT 状态会导致什么问题，怎么解决

面试高频指数：★★★☆☆

我们考虑高并发短连接的业务场景，在高并发短连接的 TCP 服务器上，当服务器处理完请求后主动请求关闭连接，这样服务器上会有大量的连接处于 TIME_WAIT 状态，服务器维护每一个连接需要一个 socket，也就是每个连接会占用一个文件描述符，而文件描述符的使用是有上限的，如果持续高并发，会导致一些正常的 连接失败。

 

解决方案：修改配置或设置 SO_REUSEADDR 套接字，使得服务器处于 TIME-WAIT 状态下的端口能够快速回收和重用。

 

TIME-WAIT 为什么是 2MSL

面试高频指数：★★★★☆

当客户端发出最后的 ACK 确认报文时，并不能确定服务器端能够收到该段报文。所以客户端在发送完 ACK 确认报文之后，会设置一个时长为 2 MSL 的计时器。MSL（Maximum Segment Lifetime），指一段 TCP 报文在传输过程中的最大生命周期。2 MSL 即是服务器端发出 FIN 报文和客户端发出的 ACK 确认报文所能保持有效的最大时长。

 

若服务器在 1 MSL 内没有收到客户端发出的 ACK 确认报文，再次向客户端发出 FIN 报文。如果客户端在 2 MSL 内收到了服务器再次发来的 FIN 报文，说明服务器由于一些原因并没有收到客户端发出的 ACK 确认报文。客户端将再次向服务器发出 ACK 确认报文，并重新开始 2 MSL 的计时。

 

若客户端在 2MSL 内没有再次收到服务器发送的 FIN 报文，则说明服务器正常接收到客户端 ACK 确认报文，客户端可以进入 CLOSE 阶段，即完成四次挥手。

 

所以客户端要经历 2 MSL 时长的 TIME-WAIT 阶段，为的是确认服务器能否接收到客户端发出的 ACK 确认报文。

有很多 TIME-WAIT 状态如何解决

面试高频指数：★★★☆☆

服务器可以设置 SO_REUSEADDR 套接字选项来通知内核，如果端口被占用，但 TCP 连接位于 TIME_WAIT 状态时可以重用端口。如果你的服务器程序停止后想立即重启，而新的套接字依旧希望使用同一端口，此时 SO_REUSEADDR 选项就可以避免 TIME-WAIT 状态。

 

也可以采用长连接的方式减少 TCP 的连接与断开，在长连接的业务中往往不需要考虑 TIME-WAIT 状态，但其实在长连接的业务中并发量一般不会太高。

有很多 CLOSE-WAIT 怎么解决

面试高频指数：★★★☆☆

首先检查是不是自己的代码问题（看是否服务端程序忘记关闭连接），如果是，则修改代码。

调整系统参数，包括句柄相关参数和 TCP/IP 的参数，一般一个 CLOSE_WAIT 会维持至少 2 个小时的时间，我们可以通过调整参数来缩短这个时间。

TCP 协议中的定时器

面试高频指数：★★☆☆☆

TCP中有七种计时器，分别为：

 

建立连接定时器：顾名思义，该定时器是在建立 TCP 连接的时候使用的，在 TCP 三次握手的过程中，发送方发送 SYN 时，会启动一个定时器（默认为 3 秒），若 SYN 包丢失了，那么 3 秒以后会重新发送 SYN 包，直到达到重传次数。

 

重传定时器：该计时器主要用于 TCP 超时重传机制中，当TCP 发送报文段时，就会创建特定报文的重传计时器，并可能出现两种情况：

 

① 若在计时器截止之前发送方收到了接收方的 ACK 报文，则撤销该计时器；

 

② 若计时器截止时间内并没有收到接收方的 ACK 报文，则发送方重传报文，并将计时器复位。

 

坚持计时器：我们知道 TCP 通过让接受方指明希望从发送方接收的数据字节数（窗口大小）来进行流量控制，当接收端的接收窗口满时，接收端会告诉发送端此时窗口已满，请停止发送数据。此时发送端和接收端的窗口大小均为0，直到窗口变为非0时，接收端将发送一个 确认 ACK 告诉发送端可以再次发送数据，但是该报文有可能在传输时丢失。若该 ACK 报文丢失，则双方可能会一直等待下去，为了避免这种死锁情况的发生，发送方使用一个坚持定时器来周期性地向接收方发送探测报文段，以查看接收方窗口是否变大。

 

延迟应答计时器：延迟应答也被称为捎带 ACK，这个定时器是在延迟应答的时候使用的，为了提高网络传输的效率，当服务器接收到客户端的数据后，不是立即回 ACK 给客户端，而是等一段时间，这样如果服务端有数据需要发送给客户端的话，就可以把数据和 ACK 一起发送给客户端了。

 

保活定时器：该定时器是在建立 TCP 连接时指定 SO_KEEPLIVE 时才会生效，当发送方和接收方长时间没有进行数据交互时，该定时器可以用于确定对端是否还活着。

 

FIN_WAIT_2 定时器：当主动请求关闭的一方发送 FIN 报文给接收端并且收到其对 FIN 的确认 ACK后进入 FIN_WAIT_2状态。如果这个时候因为网络突然断掉、被动关闭的一端宕机等原因，导致请求方没有收到接收方发来的 FIN，主动关闭的一方会一直等待。该定时器的作用就是为了避免这种情况的发生。当该定时器超时的时候，请求关闭方将不再等待，直接释放连接。

 

TIME_WAIT 定时器：我们知道在 TCP 四次挥手中，发送方在最后一次挥手之后会进入 TIME_WAIT 状态，不直接进入 CLOSE 状态的主要原因是被动关闭方万一在超时时间内没有收到最后一个 ACK，则会重发最后的 FIN，2 MSL（报文段最大生存时间）等待时间保证了重发的 FIN 会被主动关闭的一段收到且重新发送最后一个 ACK 。还有一个原因是在这 2 MSL 的时间段内任何迟到的报文段会被接收方丢弃，从而防止老的 TCP 连接的包在新的 TCP 连接里面出现。

TCP 是如何保证可靠性的

面试高频指数：★★★★☆

数据分块：应用数据被分割成 TCP 认为最适合发送的数据块。

序列号和确认应答：TCP 给发送的每一个包进行编号，在传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答，即发送 ACK 报文，这个 ACK 报文当中带有对应的确认序列号，告诉发送方成功接收了哪些数据以及下一次的数据从哪里开始发。除此之外，接收方可以根据序列号对数据包进行排序，把有序数据传送给应用层，并丢弃重复的数据。

校验和： TCP 将保持它首部和数据部分的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到报文段的检验和有差错，TCP 将丢弃这个报文段并且不确认收到此报文段。

流量控制： TCP 连接的双方都有一个固定大小的缓冲空间，发送方发送的数据量不能超过接收端缓冲区的大小。当接收方来不及处理发送方的数据，会提示发送方降低发送的速率，防止产生丢包。TCP 通过滑动窗口协议来支持流量控制机制。

拥塞控制： 当网络某个节点发生拥塞时，减少数据的发送。

ARQ协议： 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。

超时重传： 当 TCP 发出一个报文段后，它启动一个定时器，等待目的端确认收到这个报文段。如果超过某个时间还没有收到确认，将重发这个报文段。

UDP 为什么是不可靠的？bind 和 connect 对于 UDP 的作用是什么

面试高频指数：★★★☆☆

UDP 只有一个 socket 接收缓冲区，没有 socket 发送缓冲区，即只要有数据就发，不管对方是否可以正确接收。而在对方的 socket 接收缓冲区满了之后，新来的数据报无法进入到 socket 接受缓冲区，此数据报就会被丢弃，因此 UDP 不能保证数据能够到达目的地，此外，UDP 也没有流量控制和重传机制，故UDP的数据传输是不可靠的。

和 TCP 建立连接时采用三次握手不同，UDP 中调用 connect 只是把对端的 IP 和 端口号记录下来，并且 UDP 可多多次调用 connect 来指定一个新的 IP 和端口号，或者断开旧的 IP 和端口号（通过设置 connect 函数的第二个参数）。和普通的 UDP 相比，调用 connect 的 UDP 会提升效率，并且在高并发服务中会增加系统稳定性。

当 UDP 的发送端调用 bind 函数时，就会将这个套接字指定一个端口，若不调用 bind 函数，系统内核会随机分配一个端口给该套接字。当手动绑定时，能够避免内核来执行这一操作，从而在一定程度上提高性能。

**TCP** **超时重传的原理**

面试高频指数：★★★☆☆

发送方在发送一次数据后就开启一个定时器，在一定时间内如果没有得到发送数据包的 ACK 报文，那么就重新发送数据，在达到一定次数还没有成功的话就放弃重传并发送一个复位信号。其中超时时间的计算是超时的核心，而定时时间的确定往往需要进行适当的权衡，因为当定时时间过长会造成网络利用率不高，定时太短会造成多次重传，使得网络阻塞。在 TCP 连接过程中，会参考当前的网络状况从而找到一个合适的超时时间。

TCP 的停止等待协议是什么

面试高频指数：★★★☆☆

停止等待协议是为了实现 TCP 可靠传输而提出的一种相对简单的协议，该协议指的是发送方每发完一组数据后，直到收到接收方的确认信号才继续发送下一组数据。我们通过四种情形来帮助理解停等协议是如何实现可靠传输的：

① 无差错传输

如上述左图所示，A 发送分组 Msg 1，发完就暂停发送，直到收到接收方确认收到 Msg 1 的报文后，继续发送 Msg 2，以此类推，该情形是通信中的一种理想状态。

② 出现差错

如上述右图所示，发送方发送的报文出现差错导致接收方不能正确接收数据，出现差错的情况主要分为两种：

发送方发送的 Msg 1 在中途丢失了，接收方完全没收到数据。

接收方收到 Msg 1 后检测出现了差错，直接丢弃 Msg 1。

上面两种情形，接收方都不会回任何消息给发送方，此时就会触发超时传输机制，即发送方在等待一段时间后仍然没有收到接收方的确认，就认为刚才发送的数据丢失了，因此重传前面发送过的数据。

③ 确认丢失

当接收方回应的 Msg 1 确认报文在传输过程中丢失，发送方无法接收到确认报文。于是发送方等待一段时间后重传 Msg 1，接收方将收到重复的 Msg1 数据包，此时接收方会丢弃掉这个重复报文并向发送方再次发送 Msg1 的确认报文。

④ 确认迟到

当接收方回应的 Msg 1 确认报文由于网络各种原因导致发送方没有及时收到，此时发送方在超时重传机制的作用下再次发送了 Msg 数据包，接收方此时进行和确认丢失情形下相同的动作（丢弃重复的数据包并再次发送 Msg 1 确认报文）。发送方此时收到了接收方的确认数据包，于是继续进行数据发送。过了一段时间后，发送方收到了迟到的 Msg 1 确认包会直接丢弃。

上述四种情形即停止等待协议中所出现的所有可能情况。

TCP 最大连接数限制

面试高频指数：★★☆☆☆

Client 最大 TCP 连接数

client 在每次发起 TCP 连接请求时，如果自己并不指定端口的话，系统会随机选择一个本地端口（local port），该端口是独占的，不能和其他 TCP 连接共享。TCP 端口的数据类型是 unsigned short，因此本地端口个数最大只有 65536，除了端口 0不能使用外，其他端口在空闲时都可以正常使用，这样可用端口最多有 65535 个。

Server最大 TCP 连接数

server 通常固定在某个本地端口上监听，等待 client 的连接请求。不考虑地址重用（Unix 的 SO_REUSEADDR 选项）的情况下，即使 server 端有多个 IP，本地监听端口也是独占的，因此 server 端 TCP 连接 4 元组中只有客户端的 IP 地址和端口号是可变的，因此最大 TCP 连接为客户端 IP 数 × 客户端 port 数，对 IPV4，在不考虑 IP 地址分类的情况下，最大 TCP 连接数约为 2 的 32 次方（IP 数）× 2 的 16 次方（port 数），也就是 server 端单机最大 TCP 连接数约为 2 的 48 次方。

然而上面给出的是只是理论上的单机最大连接数，在实际环境中，受到明文规定（一些 IP 地址和端口具有特殊含义，没有对外开放）、机器资源、操作系统等的限制，特别是 sever 端，其最大并发 TCP 连接数远不能达到理论上限。对 server 端，通过增加内存、修改最大文件描述符个数等参数，单机最大并发 TCP 连接数超过 10 万 是没问题的。

TCP 流量控制与拥塞控制

面试高频指数：★★★★☆

流量控制

所谓流量控制就是让发送方的发送速率不要太快，让接收方来得及接收。如果接收方来不及接收发送方发送的数据，那么就会有分组丢失。在 TCP 中利用可边长的滑动窗口机制可以很方便的在 TCP 连接上实现对发送方的流量控制。主要的方式是接收方返回的 ACK 中会包含自己的接收窗口大小，以控制发送方此次发送的数据量大小（发送窗口大小）。

拥塞控制

在实际的网络通信系统中，除了发送方和接收方外，还有路由器，交换机等复杂的网络传输线路，此时就需要拥塞控制。拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况。常用的解决方法有：慢开始和拥塞避免、快重传和快恢复。

拥塞控制和流量控制的区别

拥塞控制往往是一种全局的，防止过多的数据注入到网络之中，而TCP连接的端点只要不能收到对方的确认信息，猜想在网络中发生了拥塞，但并不知道发生在何处，因此，流量控制往往指点对点通信量的控制，是端到端的问题。

如果接收方滑动窗口满了，发送方会怎么做

面试高频指数：★★★★☆

基于 TCP 流量控制中的滑动窗口协议，我们知道接收方返回给发送方的 ACK 包中会包含自己的接收窗口大小，若接收窗口已满，此时接收方返回给发送方的接收窗口大小为 0，此时发送方会等待接收方发送的窗口大小直到变为非 0 为止，然而，接收方回应的 ACK 包是存在丢失的可能的，为了防止双方一直等待而出现死锁情况，此时就需要坚持计时器来辅助发送方周期性地向接收方查询，以便发现窗口是否变大【坚持计时器参考问题】，当发现窗口大小变为非零时，发送方便继续发送数据。

TCP 拥塞控制采用的四种算法

面试高频指数：★★★☆☆

慢开始

当发送方开始发送数据时，由于一开始不知道网络负荷情况，如果立即将大量的数据字节传输到网络中，那么就有可能引起网络拥塞。一个较好的方法是在一开始发送少量的数据先探测一下网络状况，即由小到大的增大发送窗口（拥塞窗口 cwnd）。慢开始的慢指的是初始时令 cwnd为 1，即一开始发送一个报文段。如果收到确认，则 cwnd = 2，之后每收到一个确认报文，就令 cwnd = cwnd* 2。

但是，为了防止拥塞窗口增长过大而引起网络拥塞，另外设置了一个慢开始门限 ssthresh。

① 当 cwnd < ssthresh 时，使用上述的慢开始算法；

② 当 cwnd > ssthresh 时，停止使用慢开始，转而使用拥塞避免算法；

③ 当 cwnd == ssthresh 时，两者均可。

拥塞避免

拥塞控制是为了让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT （往返时间定义为发送方发送数据到收到确认报文所经历的时间）就把发送方的 cwnd 值加 1，通过让 cwnd 线性增长，防止很快就遇到网络拥塞状态。

当网络拥塞发生时，让新的慢开始门限值变为发生拥塞时候的值的一半,并将拥塞窗口置为 1 ,然后再次重复两种算法（慢开始和拥塞避免）,这时一瞬间会将网络中的数据量大量降低。

快重传

快重传算法要求接收方每收到一个失序的报文就立即发送重复确认，而不要等到自己发送数据时才捎带进行确认，假定发送方发送了 Msg 1 ~ Msg 4 这 4 个报文，已知接收方收到了 Msg 1，Msg 3 和 Msg 4 报文，此时因为接收到收到了失序的数据包，按照快重传的约定，接收方应立即向发送方发送 Msg 1 的重复确认。 于是在接收方收到 Msg 4 报文的时候，向发送方发送的仍然是 Msg 1 的重复确认。这样，发送方就收到了 3 次 Msg 1 的重复确认，于是立即重传对方未收到的 Msg 报文。由于发送方尽早重传未被确认的报文段，因此，快重传算法可以提高网络的吞吐量。

快恢复

快恢复算法是和快重传算法配合使用的，该算法主要有以下两个要点：

① 当发送方连续收到三个重复确认，执行乘法减小，慢开始门限 ssthresh 值减半；

② 由于发送方可能认为网络现在没有拥塞，因此与慢开始不同，把 cwnd 值设置为 ssthresh 减半之后的值，然后执行拥塞避免算法，线性增大 cwnd。

TCP 粘包问题

面试高频指数：★★★☆☆

为什么会发生TCP粘包和拆包?

① 发送方写入的数据大于套接字缓冲区的大小，此时将发生拆包。

② 发送方写入的数据小于套接字缓冲区大小，由于 TCP 默认使用 Nagle 算法，只有当收到一个确认后，才将分组发送给对端，当发送方收集了多个较小的分组，就会一起发送给对端，这将会发生粘包。

③ 进行 MSS （最大报文长度）大小的 TCP 分段，当 TCP 报文的数据部分大于 MSS 的时候将发生拆包。

④ 发送方发送的数据太快，接收方处理数据的速度赶不上发送端的速度，将发生粘包。

常见解决方法

① 在消息的头部添加消息长度字段，服务端获取消息头的时候解析消息长度，然后向后读取相应长度的内容。

② 固定消息数据的长度，服务端每次读取既定长度的内容作为一条完整消息，当消息不够长时，空位补上固定字符。但是该方法会浪费网络资源。

③ 设置消息边界，也可以理解为分隔符，服务端从数据流中按消息边界分离出消息内容，一般使用换行符。

什么时候需要处理粘包问题？

当接收端同时收到多个分组，并且这些分组之间毫无关系时，需要处理粘包；而当多个分组属于同一数据的不同部分时，并不需要处理粘包问题。

TCP 报文包含哪些信息

面试高频指数：★★☆☆☆

TCP 报文是 TCP 传输的的数据单元，也叫做报文段，其报文格式如下图所示：

![img](file://localhost/Users/rb/Library/Group%20Containers/UBF8T346G9.Office/msoclip1/01/clip_image004.gif)
 源端口和目的端口号：它用于多路复用/分解来自或送往上层应用的数据，其和 IP 数据报中的源 IP 与目的 IP 地址一同确定一条 TCP 连接。

序号和确认号字段：序号是本报文段发送的数据部分中第一个字节的编号，在 TCP 传送的流中，每一个字节一个序号。例如一个报文段的序号为 100，此报文段数据部分共有 100 个字节，则下一个报文段的序号为 200。序号确保了 TCP 传输的有序性。确认号，即 ACK，指明下一个想要收到的字节序号，发送 ACK 时表明当前序号之前的所有数据已经正确接收。这两个字段的主要目的是保证数据可靠传输。

首部长度：该字段指示了以 32 比特的字为单位的 TCP 的首部长度。其中固定字段长度为 20 字节，由于首部长度可能含有可选项内容，因此 TCP 报头的长度是不确定的，20 字节是 TCP 首部的最小长度。

保留：为将来用于新的用途而保留。

控制位：URG 表示紧急指针标志，该位为 1 时表示紧急指针有效，为 0 则忽略；ACK 为确认序号标志，即相应报文段包括一个对已被成功接收报文段的确认；PSH 为 push 标志，当该位为 1 时，则指示接收方在接收到该报文段以后，应尽快将这个报文段交给应用程序，而不是在缓冲区排队； RST 为重置连接标志，当出现错误连接时，使用此标志来拒绝非法的请求；SYN 为同步序号，在连接的建立过程中使用，例如三次握手时，发送方发送 SYN 包表示请求建立连接；FIN 为 finish 标志，用于释放连接，为 1 时表示发送方已经没有数据发送了，即关闭本方数据流。

接收窗口：主要用于 TCP 流量控制。该字段用来告诉发送方其窗口（缓冲区）大小，以此控制发送速率，从而达到流量控制的目的。

校验和：奇偶校验，此校验和是对整个 TCP 报文段，包括 TCP 头部和 数据部分。该校验和是一个端到端的校验和，由发送端计算和存储，并由接收端进行验证，主要目的是检验数据是否发生改动，若检测出差错，接收方会丢弃该 TCP 报文。

紧急数据指针：紧急数据用于告知紧急数据所在的位置，在URG标志位为 1 时才有效。当紧急数据存在时，TCP 必须通知接收方的上层实体，接收方会对紧急模式采取相应的处理。

选项：该字段一般为空，可根据首部长度进行推算。主要有以下作用：

① TCP 连接初始化时，通信双方确认最大报文长度。

② 在高速数据传输时，可使用该选项协商窗口扩大因子。

③ 作为时间戳时，提供一个 较为精准的 RTT，主要为了更好的实现 TCP 流量控制协议。

数据：TCP 报文中的数据部分也是可选的，例如在 TCP 三次握手和四次挥手过程中，通信双方交换的报文只包含头部信息，数据部分为空，只有当连接成功建立后，TCP 包才真正携带数据。

SYN FLOOD 是什么

面试高频指数：★★★☆☆

SYN Flood 是种典型的 DoS（拒绝服务）攻击，其目的是通过消耗服务器所有可用资源使服务器无法用于处理合法请求。通过重复发送初始连接请求（SYN）数据包，攻击者能够压倒目标服务器上的所有可用端口，导致目标设备根本不响应合法请求。

为什么服务端易受到 SYN 攻击

面试高频指数：★★★☆☆

在 TCP 建立连接的过程中，因为服务端不确定自己发给客户端的 SYN-ACK 消息或客户端反馈的 ACK 消息是否会丢在半路，所以会给每个待完成的半开连接状态设一个定时器，如果超过时间还没有收到客户端的 ACK 消息，则重新发送一次 SYN-ACK 消息给客户端，直到重试超过一定次数时才会放弃。

服务端为了维持半开连接状态，需要分配内核资源维护半开连接。当攻击者伪造海量的虚假 IP 向服务端发送 SYN 包时，就形成了 SYN FLOOD 攻击。攻击者故意不响应 ACK 消息，导致服务端被大量注定不能完成的半开连接占据，直到资源耗尽，停止响应正常的连接请求。

解决方法：

直接的方法是提高 TCP 端口容量的同时减少半开连接的资源占用时间，然而该方法只是稍稍提高了防御能力；

部署能够辨别恶意 IP 的路由器，将伪造 IP 地址的发送方发送的 SYN 消息过滤掉，该方案作用一般不是太大；

上述两种方法虽然在一定程度上能够提高服务器的防御能力，但是没有从根本上解决服务器资源消耗殆尽的问题，而以下几种方法的出发点都是在发送方发送确认回复后才开始分配传输资源，从而避免服务器资源消耗殆尽。

SYN Cache：该方法首先构造一个全局 Hash Table，用来缓存系统当前所有的半开连接信息。在 Hash Table 中的每个桶的容量大小是有限制的，当桶满时，会主动丢掉早来的信息。当服务端收到一个 SYN 消息后，会通过一个映射函数生成一个相应的 Key 值，使得当前半连接信息存入相应的桶中。当收到客户端正确的确认报文后，服务端才开始分配传输资源块，并将相应的半开连接信息从表中删除。和服务器传输资源相比，维护表的开销要小得多。

SYN Cookies：该方案原理和 HTTP Cookies 技术类似，服务端通过特定的算法将半开连接信息编码成序列号或者时间戳，用作服务端给客户端的消息编号，随 SYN-ACK 消息一同返回给连接发起方，这样在连接建立完成前服务端不保存任何信息，直到发送方发送 ACK 确认报文并且服务端成功验证编码信息后，服务端才开始分配传输资源。若请求方是攻击者，则不会向服务端会 ACK 消息，由于未成功建立连接，因此服务端并没有花费任何额外的开销。

然而该方案也存在一些缺点，由于服务端并不保存半开连接状态，因此也就丧失了超时重传的能力，这在一定程度上降低了正常用户的连接成功率。此外，客户端发送给服务端的确认报文存在传输丢失的可能，当 ACK 确认报文丢失时，服务端和客户端会对连接的成功与否产生歧义，此时就需要上层应用采取相应的策略进行处理了。

SYN Proxy：在客户端和服务器之间部署一个代理服务器，类似于防火墙的作用。通过代理服务器与客户端进行建立连接的过程，之后代理服务器充当客户端将成功建立连接的客户端信息发送给服务器。这种方法基本不消耗服务器的资源，但是建立连接的时间变长了（总共需要 6 次握手）。

高并发服务器客户端主动关闭连接和服务端主动关闭连接的区别

面试高频指数：★☆☆☆☆

以下是针对 TCP 服务来说的：

服务端主动关闭连接

在高并发场景下，当服务端主动关闭连接时，此时服务器上就会有大量的连接处于 TIME-WAIT 状态【详解见问题 7, 8, 9】

客户端主动关闭连接

当客户端主动关闭连接时，我们并不需要关心 TIME-WAIT 状态过多造成的问题，但是需要关注服务端保持大量的 CLOSE-WAIT 状态时会产生的问题【见问题 10 的解决方法】

无论是客户端还是服务器主动关闭连接，从本质上来说，在高并发场景下主要关心的就是服务端的资源占用问题，而这也是采用 TCP 传输协议必须要面对的问题，其问题解决的出发点也是如何处理好服务质量和资源消耗之间的关系。

### 第四部分：网络层

IP 协议的定义和作用

面试高频指数：★★★☆☆

IP 协议（Internet Protocol）又称互联网协议，是支持网间互联的数据包协议。该协议工作在网络层，主要目的就是为了提高网络的可扩展性，和传输层 TCP 相比，IP 协议提供一种无连接/不可靠、尽力而为的数据包传输服务，其与TCP协议（传输控制协议）一起构成了TCP/IP 协议族的核心。IP 协议主要有以下几个作用：

寻址和路由：在IP 数据包中会携带源 IP 地址和目的 IP 地址来标识该数据包的源主机和目的主机。IP 数据报在传输过程中，每个中间节点（IP 网关、路由器）只根据网络地址进行转发，如果中间节点是路由器，则路由器会根据路由表选择合适的路径。IP 协议根据路由选择协议提供的路由信息对 IP 数据报进行转发，直至抵达目的主机。

分段与重组：IP 数据包在传输过程中可能会经过不同的网络，在不同的网络中数据包的最大长度限制是不同的，IP 协议通过给每个 IP 数据包分配一个标识符以及分段与组装的相关信息，使得数据包在不同的网络中能够传输，被分段后的 IP 数据报可以独立地在网络中进行转发，在到达目的主机后由目的主机完成重组工作，恢复出原来的 IP 数据包。

域名和 IP 的关系，一个 IP 可以对应多个域名吗

面试高频指数：★★☆☆☆

IP 在同一个网络中是唯一的，用来标识每一个网络上的设备，其相当于一个人的身份证号；域名在同一个网络中也是唯一的，就像一个人的名字，绰号。假如你有多个不同的绰号，你的朋友可以用其中任何一个绰号叫你，但你的身份证号码却是唯一的。由此我们可以看出一个域名只能对应一个 IP 地址，是一对一的关系；而一个 IP 却可以对应多个域名，是一对多的关系。

IPV4 地址不够如何解决

面试高频指数：★★★☆☆

DHCP：动态主机配置协议。动态分配 IP 地址，只给接入网络的设备分配IP地址，因此同一个 MAC 地址的设备，每次接入互联网时，得到的IP地址不一定是相同的，该协议使得空闲的 IP 地址可以得到充分利用。

CIDR：无类别域间路由。CIDR 消除了传统的 A 类、B 类、C 类地址以及划分子网的概念，因而更加有效的分配 IPv4 的地址空间，但无法从根本上解决地址耗尽问题。

NAT：网络地址转换协议。我们知道属于不同局域网的主机可以使用相同的 IP 地址，从而一定程度上缓解了 IP 资源枯竭的问题。然而主机在局域网中使用的 IP 地址是不能在公网中使用的，当局域网主机想要与公网进行通信时， NAT 方法可以将该主机 IP 地址转换成全球 IP 地址。该协议能够有效解决 IP 地址不足的问题。

IPv6 ：作为接替 IPv4 的下一代互联网协议，其可以实现 2 的 128 次方个地址，而这个数量级，即使是给地球上每一颗沙子都分配一个IP地址，该协议能够从根本上解决 IPv4 地址不够用的问题。

路由器的分组转发流程

面试高频指数：★★★☆☆

① 从 IP 数据包中提取出目的主机的 IP 地址，找到其所在的网络；

② 判断目的 IP 地址所在的网络是否与本路由器直接相连，如果是，则不需要经过其它路由器直接交付，否则执行 ③；

③ 检查路由表中是否有目的 IP 地址的特定主机路由。如果有，则按照路由表传送到下一跳路由器中，否则执行 ④；

④ 逐条检查路由表，若找到匹配路由，则按照路由表转发到下一跳路由器中，否则执行步骤 ⑤；

⑤ 若路由表中设置有默认路由，则按照默认路由转发到默认路由器中，否则执行步骤 ⑥；

⑥ 无法找到合适路由，向源主机报错。

路由器和交换机的区别

面试高频指数：★★★★☆

交换机：交换机用于局域网，利用主机的物理地址（MAC 地址）确定数据转发的目的地址，它工作与数据链路层。

路由器：路由器通过数据包中的目的 IP 地址识别不同的网络从而确定数据转发的目的地址，网络号是唯一的。路由器根据路由选择协议和路由表信息从而确定数据的转发路径，直到到达目的网络，它工作于网络层。

ICMP 协议概念/作用

面试高频指数：★★☆☆☆

ICMP（Internet Control Message Protocol）是因特网控制报文协议，主要是实现 IP 协议中未实现的部分功能，是一种网络层协议。该协议并不传输数据，只传输控制信息来辅助网络层通信。其主要的功能是验证网络是否畅通（确认接收方是否成功接收到 IP 数据包）以及辅助 IP 协议实现可靠传输（若发生 IP 丢包，ICMP 会通知发送方 IP 数据包被丢弃的原因，之后发送方会进行相应的处理）。

ICMP 的应用

面试高频指数：★☆☆☆☆

Ping

Ping（Packet Internet Groper），即因特网包探测器，是一种工作在网络层的服务命令，主要用于测试网络连接量。本地主机通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 响应报文，Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率从而推断网络是否通常、运行是否正常等。

TraceRoute

TraceRoute 是 ICMP 的另一个应用，其主要用来跟踪一个分组从源点耗费最少 TTL 到达目的地的路径。TraceRoute 通过逐渐增大 TTL 值并重复发送数据报来实现其功能，首先，TraceRoute 会发送一个 TTL 为 1 的 IP 数据报到目的地，当路径上的第一个路由器收到这个数据报时，它将 TTL 的值减 1，此时 TTL = 0，所以路由器会将这个数据报丢掉，并返回一个差错报告报文，之后源主机会接着发送一个 TTL 为 2 的数据报，并重复此过程，直到数据报能够刚好到达目的主机。此时 TTL = 0，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文，之后源主机便知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。

两台电脑连起来后 ping 不通，你觉得可能存在哪些问题？

面试高频指数：★★★☆☆

首先看网络是否连接正常，检查网卡驱动是否正确安装。

局域网设置问题，检查 IP 地址是否设置正确。

看是否被防火墙阻拦（有些设置中防火墙会对 ICMP 报文进行过滤），如果是的话，尝试关闭防火墙 。

看是否被第三方软件拦截。

两台设备间的网络延迟是否过大（例如路由设置不合理），导致 ICMP 报文无法在规定的时间内收到。

ARP 地址解析协议的原理和地址解析过程

面试高频指数：★★★★☆

ARP（Address Resolution Protocol）是地址解析协议的缩写，该协议提供根据 IP 地址获取物理地址的功能，它工作在第二层，是一个数据链路层协议，其在本层和物理层进行联系，同时向上层提供服务。当通过以太网发送 IP 数据包时，需要先封装 32 位的 IP 地址和 48位 MAC 地址。在局域网中两台主机进行通信时需要依靠各自的物理地址进行标识，但由于发送方只知道目标 IP 地址，不知道其 MAC 地址，因此需要使用地址解析协议。 ARP 协议的解析过程如下：

① 首先，每个主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址之间的对应关系；

② 当源主机要发送数据时，首先检查 ARP 列表中是否有 IP 地址对应的目的主机 MAC 地址，如果存在，则可以直接发送数据，否则就向同一子网的所有主机发送 ARP 数据包。该数据包包括的内容有源主机的 IP 地址和 MAC 地址，以及目的主机的 IP 地址。

③ 当本网络中的所有主机收到该 ARP 数据包时，首先检查数据包中的 目的 主机IP 地址是否是自己的 IP 地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的 IP 和 MAC 地址写入到 ARP 列表中，如果已经存在，则覆盖，然后将自己的 MAC 地址写入 ARP 响应包中，告诉源主机自己是它想要找的 MAC 地址。

④ 源主机收到 ARP 响应包后。将目的主机的 IP 和 MAC 地址写入 ARP 列表，并利用此信息发送数据。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。

网络地址转换 NAT

面试高频指数：★★☆☆☆

NAT（Network Address Translation），即网络地址转换，它是一种把内部私有网络地址翻译成公有网络 IP 地址的技术。该技术不仅能解决 IP 地址不足的问题，而且还能隐藏和保护网络内部主机，从而避免来自外部网络的攻击。

NAT 的实现方式主要有三种：

静态转换：内部私有 IP 地址和公有 IP 地址是一对一的关系，并且不会发生改变。通过静态转换，可以实现外部网络对内部网络特定设备的访问，这种方式原理简单，但当某一共有 IP 地址被占用时，跟这个 IP 绑定的内部主机将无法访问 Internet。

动态转换：采用动态转换的方式时，私有 IP 地址每次转化成的公有 IP 地址是不唯一的。当私有 IP 地址被授权访问 Internet 时会被随机转换成一个合法的公有 IP 地址。当 ISP 通过的合法 IP 地址数量略少于网络内部计算机数量时，可以采用这种方式。

端口多路复用：该方式将外出数据包的源端口进行端口转换，通过端口多路复用的方式，实现内部网络所有主机共享一个合法的外部 IP 地址进行 Internet 访问，从而最大限度地节约 IP 地址资源。同时，该方案可以隐藏内部网络中的主机，从而有效避免来自 Internet 的攻击。

TTL 是什么？有什么作用

面试高频指数：★★☆☆☆

TTL 是指生存时间，简单来说，它表示了数据包在网络中的时间。每经过一个路由器后 TTL 就减一，这样 TTL 最终会减为 0 ，当 TTL 为 0 时，则将数据包丢弃。通过设置 TTL 可以避免这两个路由器之间形成环导致数据包在环路上死转的情况，由于有了 TTL ，当 TTL 为 0 时，数据包就会被抛弃。

#### 运输层协议和网络层协议的区别 面试高频指数：★★★☆☆

网络层协议负责提供主机间的逻辑通信；运输层协议负责提供进程间的逻辑通信。

### 第五部分：数据链路层

####  以太网

```
计算机局域网技术

相关技术：
共享介质，带冲突检测的载波侦听多路访问（CSMA/CD）技术规定了多台计算机共享一个通道的方法。
中继器，因为信号的衰减，根据不同的介质以太网段有距离的限制，中继器可以把电缆中信号放大。
集线器，采用集线器组网的以太网尽管在物理上是星型结构，但在逻辑上仍然是总线型的，半双工的通信方式采用CSMA/CD的冲突检测方法，集线器对于减少数据包冲突的作用很小。
```



#### MAC 地址和 IP 地址分别有什么作用

```
面试高频指数：★★★☆☆

MAC 地址是数据链路层和物理层使用的地址，是写在网卡上的物理地址。MAC 地址用来定义网络设备的位置。

IP 地址是网络层和以上各层使用的地址，是一种逻辑地址。IP 地址用来区别网络上的计算机。

为什么有了 MAC 地址还需要 IP 地址
```

面试高频指数：★★★★☆

如果我们只使用 MAC 地址进行寻址的话，我们需要路由器记住每个 MAC 地址属于哪一个子网，不然每一次路由器收到数据包时都要满世界寻找目的 MAC 地址。而我们知道 MAC 地址的长度为 48 位，也就是说最多总共有 2 的 48 次方个 MAC 地址，这就意味着每个路由器需要 256 T 的内存，这显然是不现实的。

和 MAC 地址不同，IP 地址是和地域相关的，在一个子网中的设备，我们给其分配的 IP 地址前缀都是一样的，这样路由器就能根据 IP 地址的前缀知道这个设备属于哪个子网，剩下的寻址就交给子网内部实现，从而大大减少了路由器所需要的内存。

为什么有了 IP 地址还需要 MAC 地址

面试高频指数：★★★★☆

只有当设备连入网络时，才能根据他进入了哪个子网来为其分配 IP 地址，在设备还没有 IP 地址的时候或者在分配 IP 地址的过程中，我们需要 MAC 地址来区分不同的设备。

私网地址和公网地址之间进行转换：同一个局域网内的两个私网地址，经过转换之后外面看到的一样吗

面试高频指数：★★★☆☆

当采用静态或者动态转换时，由于一个私网 IP 地址对应一个公网地址，因此经过转换之后的公网 IP 地址是不同的；而采用端口复用方式的话，在一个子网中的所有地址都采用一个公网地址，但是使用的端口是不同的。

以太网中的 CSMA/CD 协议

面试高频指数：★★☆☆☆

CSMA/CD 为载波侦听多路访问/冲突检测，是像以太网这种广播网络采用的一种机制，我们知道在以太网中多台主机在同一个信道中进行数据传输，CSMA/CD 很好的解决了共享信道通信中出现的问题，它的工作原理主要包括两个部分：

载波监听：当使用 CSMA/CD 协议时，总线上的各个节点都在监听信道上是否有信号在传输，如果有的话，表明信道处于忙碌状态，继续保持监听，直到信道空闲为止。如果发现信道是空闲的，就立即发送数据。

冲突检测：当两个或两个以上节点同时监听到信道空闲，便开始发送数据，此时就会发生碰撞（数据的传输延迟也可能引发碰撞）。当两个帧发生冲突时，数据帧就会破坏而失去了继续传输的意义。在数据的发送过程中，以太网是一直在监听信道的，当检测到当前信道冲突，就立即停止这次传输，避免造成网络资源浪费，同时向信道发送一个「冲突」信号，确保其它节点也发现该冲突。之后采用一种二进制退避策略让待发送数据的节点随机退避一段时间之后重新。

数据链路层上的三个基本问题

面试高频指数：★☆☆☆☆

封装成帧：将网络层传下来的分组前后分别添加首部和尾部，这样就构成了帧。首部和尾部的一个重要作用是帧定界，也携带了一些必要的控制信息，对于每种数据链路层协议都规定了帧的数据部分的最大长度。

透明传输：帧使用首部和尾部进行定界，如果帧的数据部分含有和首部和尾部相同的内容， 那么帧的开始和结束的位置就会判断错，因此需要在数据部分中出现有歧义的内容前边插入转义字符，如果数据部分出现转义字符，则在该转义字符前再加一个转义字符。在接收端进行处理之后可以还原出原始数据。这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。

差错检测：目前数据链路层广泛使用循环冗余检验（CRC）来检查数据传输过程中是否产生比特差错。

PPP 协议

面试高频指数：★☆☆☆☆

互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP（点对点）协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。点对点协议为点对点连接上传输多协议数据包提供了一个标准方法。该协议设计的目的主要是用来通过拨号或专线方式建立点对点连接发送数据，使其成为各种主机、网桥和路由器之间简单连接的一种解决方案。

PPP 协议具有以下特点：

PPP 协议具有动态分配 IP 地址的能力，其允许在连接时刻协商 IP 地址。

PPP 支持多种网络协议，例如 TCP/IP、NETBEUI 等。

PPP 具有差错检测能力，但不具备纠错能力，所以 PPP 是不可靠传输协议。

无重传的机制，网络开销小，速度快。

PPP 具有身份验证的功能。

为什么 PPP 协议不使用序号和确认机制

面试高频指数：★☆☆☆☆

IETF 在设计因特网体系结构时把其中最复杂的部分放在 TCP 协议中，而网际协议 IP 则相对比较简单，它提供的是不可靠的数据包服务，在这种情况下，数据链路层没有必要提供比 IP 协议更多的功能。若使用能够实现可靠传输的数据链路层协议，则开销就要增大，这在数据链路层出现差错概率不大时是得不偿失的。

即使数据链路层实现了可靠传输，但其也不能保证网络层的传输也是可靠的，当数据帧在路由器中从数据链路层上升到网络层后，仍有可能因为网络层拥塞而被丢弃。

PPP 协议在帧格式中有帧检验序列，对每一个收到的帧，PPP 都会进行差错检测，若发现差错，则丢弃该帧。

### 第六部分：物理层

物理层主要做什么事情

面试高频指数：★★☆☆☆

作为 OSI 参考模型最低的一层，物理层是整个开放系统的基础，该层利用传输介质为通信的两端建立、管理和释放物理连接，实现比特流的透明传输。物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流，其尽可能地屏蔽掉不同种类传输媒体和通信手段的差异，使物理层上面的数据链路层感觉不到这些差异，这样就可以使数据链路层只考虑完成本层的协议和服务，而不必考虑网络的具体传输媒体和通信手段是什么。

主机之间的通信方式

面试高频指数：★★☆☆☆

单工通信：也叫单向通信，发送方和接收方是固定的，消息只能单向传输。例如采集气象数据、家庭电费，网费等数据收集系统，或者打印机等应用主要采用单工通信。

半双工通信：也叫双向交替通信，通信双方都可以发送消息，但同一时刻同一信道只允许单方向发送数据。例如传统的对讲机使用的就是半双工通信。

全双工通信：也叫双向同时通信，全双工通信允许通信双方同时在两个方向是传输，其要求通信双方都具有独立的发送和接收数据的能力。例如平时我们打电话，自己说话的同时也能听到对面的声音。

通道复用技术

面试高频指数：★☆☆☆☆

频分复用（FDM，Frequency Division Multiplexing）

频分复用将传输信道的总带宽按频率划分为若干个子频带或子信道，每个子信道传输一路信号。用户分到一定的频带后，在数据传输的过程中自始至终地占用这个频带。由于每个用户所分到的频带不同，使得传输信道在同一时刻能够支持不同用户进行数据传输，从而实现复用。除了传统意义上的 FDM 外，目前正交频分复用（OFDM）已在高速通信系统中得到广泛应用。

时分复用（TDM，Time Division Multiplexing）

顾名思义，时分复用将信道传输信息的时间划分为若干个时间片，每一个时分复用的用户在每一个 TDM 帧中占用固定时隙进行数据传输。用户所分配到的时隙是固定的，所以时分复用有时也叫做同步时分复用。这种分配方式能够便于调节控制，但是也存在缺点，当某个信道空闲时，其他繁忙的信道无法占用该空闲信道，因此会降低信道利用率。

波分复用（WDM，Wavelength Division Multiplexing）

在光通信领域通常按照波长而不是频率来命名，因为光的频率和波长具有单一对应关系，因此 WDM 本质上也是 FDM，光通信系统中，通常由光来运载信号进行传输，WDM 是在一条光纤上传输多个波长光信号，其将 1 根光纤看做多条「虚拟」光纤，每条「虚拟」光纤工作在不同的波长上，从而极大地提高了光纤的传输容量。

码分复用（CDM，Code Division Multiplexing）

码分复用是靠不同的编码来区分各路原始信号的一种复用方式，不同的用户使用相互正交的码字携带信息。由于码组相互正交，因此接收方能够有效区分不同的用户数据，从而实现每一个用户可以在同样的时间在同样的频带进行数据传输，频谱资源利用率高。其主要和各种多址接入技术相结合从而产生各种接入技术，包括无线和优先接入。

几种常用的宽带接入技术

面试高频指数：★☆☆☆☆

我们一般将速率超过 1 Mbps 的接入称为宽带接入，目前常用的宽带接入技术主要包括：ADSL 和 FTTx + LAN。

ADSL

ADSL 全称为非对称用户数字环路，是铜线宽带接入技术的一种。其非对称体现在用户上行和下行的传输速率不相等，一般上行速率较低，下行速率高。这种接入技术适用于有宽带业务需求的家庭用户或者中小型商务用户等。

FTTx + LAN

其中 FTTx 英文翻译为 Fiber To The X，这里的 X 指任何地方，我们可以理解为光纤可以接入到任何地方，而 LAN 指的是局域网。FTTx + LAN 是一种在接入网全部或部分采用光纤传输介质，构成光纤用户线路，从而实现用户高速上网的接入技术，其中用户速率可达 20 Mbps。这种接入技术投资规模小，网络拓展性强，网络可靠稳定，使得其应用广泛，目前是城市汇总较为普及的一种宽带接入技术。

其它还有 光纤同轴混合网（HFC）、光接入技术（有源和无源光纤系统）和无线接入技术等等。

### 第七部分：计算机网络中的安全

安全攻击有哪些

面试高频指数：★★☆☆☆

网络安全攻击主要分为被动攻击和主动攻击两类：

被动攻击：攻击者窃听和监听数据传输，从而获取到传输的数据信息，被动攻击主要有两种形式：消息内容泄露攻击和流量分析攻击。由于攻击者并没有修改数据，使得这种攻击类型是很难被检测到的。

主动攻击：攻击者修改传输的数据流或者故意添加错误的数据流，例如假冒用户身份从而得到一些权限，进行权限攻击，除此之外，还有重放、改写和拒绝服务等主动攻击的方式。

ARP 攻击

面试高频指数：★★★☆☆

在 ARP 的解析过程中，局域网上的任何一台主机如果接收到一个 ARP 应答报文，并不会去检测这个报文的真实性，而是直接记入自己的 ARP 缓存表中。并且这个 ARP 表是可以被更改的，当表中的某一列长时间不适使用，就会被删除。ARP 攻击就是利用了这一点，攻击者疯狂发送 ARP 报文，其源 MAC 地址为攻击者的 MAC 地址，而源 IP 地址为被攻击者的 IP 地址。通过不断发送这些伪造的 ARP 报文，让网络内部的所有主机和网关的 ARP 表中被攻击者的 IP 地址所对应的 MAC 地址为攻击者的 MAC 地址。这样所有发送给被攻击者的信息都会发送到攻击者的主机上，从而产生 ARP 欺骗。通常可以把 ARP 欺骗分为以下几种：

洪泛攻击

攻击者恶意向局域网中的网关、路由器和交换机等发送大量 ARP 报文，设备的 CPU 忙于处理 ARP 协议，而导致难以响应正常的服务请求。其表现通常为：网络中断或者网速很慢。

欺骗主机

这种攻击方式也叫仿冒网关攻击。攻击者通过 ARP 欺骗使得网络内部被攻击主机发送给网关的信息实际上都发送给了攻击者，主机更新的 ARP 表中对应的 MAC 地址为攻击者的 MAC。当用户主机向网关发送重要信息使，该攻击方式使得用户的数据存在被窃取的风险。

欺骗网关

该攻击方式和欺骗主机的攻击方式类似，不过这种攻击的欺骗对象是局域网的网关，当局域网中的主机向网关发送数据时，网关会把数据发送给攻击者，这样攻击者就会源源不断地获得局域网中用户的信息。该攻击方式同样会造成用户数据外泄。

中间人攻击

攻击者同时欺骗网关和主机，局域网的网关和主机发送的数据最后都会到达攻击者这边。这样，网关和用户的数据就会泄露。

IP 地址冲突

攻击者对局域网中的主机进行扫描，然后根据物理主机的 MAC 地址进行攻击，导致局域网内的主机产生 IP 冲突，使得用户的网络无法正常使用。

对称加密和非对称的区别，非对称加密有哪些

面试高频指数：★★★★☆

加密和解密的过程不同：对称加密和解密过程使用同一个密钥；非对称加密中加密和解密采用公钥和私钥两个密钥，一般使用公钥进行加密，使用私钥进行解密。

加密和解密的速度不同：对称加密和解密速度较快，当数据量比较大时适合使用；非对称加密和解密时间较长，速度相对较慢，适合少量数据传输的场景。

传输的安全性不同：采用对称加密方式进行通信时，收发双方在数据传送前需要协定好密钥，而这个密钥还有可能被第三方窃听到的，一旦密钥泄漏，之后的通信就完全暴漏给攻击者了；非对称加密采用公钥加密和私钥解密的方式，其中私钥是基于不同的算法生成的随机数，公钥可以通过私钥通过一定的算法推导得出，并且私钥到公钥的推导过程是不可逆的，也就是说公钥无法反推导出私钥，即使攻击者窃听到传输的公钥，也无法正确解出数据，所以安全性较高。

常见的非对称加密算法主要有：RSA、Elgamal、背包算法、Rabin、D-H 算法等等。

AES 的过程

面试高频指数：★★☆☆☆

AES（Advanced Encryption Standard）即密码学的高级加密标准，也叫做 Rijndeal 加密法，是为最为常见的一种对称加密算法，和传统的对称加密算法大致的流程类似，在发送端需要采用加密算法对明文进行加密，在接收端需要采用与加密算法相同的算法进行解密，不同的是， AES 采用分组加密的方式，将明文分成一组一组的，每组长度相等，每次加密一组数据，直到加密完整个明文。在 AES 标准中，分组长度固定为 128 位，即每个分组为 16 个字节（每个字节有 8 位）。而密钥的长度可以是 128 位，192 位或者 256 位。并且密钥的长度不同，推荐加密的轮数也不同。

我们以 128 位密钥为例（加密轮次为 10），已知明文首先需要分组，每一组大小为16个字节并形成 4 × 4 的状态矩阵（矩阵中的每一个元素代表一个字节）。类似地，128 位密钥同样用 4 × 4 的字节矩阵表示，矩阵中的每一列称为 1 个 32 位的比特字。通过密钥编排函数该密钥矩阵被扩展成一个由 44 个字组成的序列，该序列的前四个字是原始密钥，用于 AES 的初始密钥加过程，后面 40 个字分为 10 组，每组 4 个字分别用于 10 轮加密运算中的轮密钥加。在每轮加密过程中主要包括四个步骤：

① 字节代换：AES 的字节代换其实是一个简易的查表操作，在 AES 中定义了一个 S-box 和一个逆 S-box，我们可以将其简单地理解为两个映射表，在做字节代换时，状态矩阵中的每一个元素（字节）的高四位作为行值，低四位作为列值，取出 S-box 或者逆 S-box 中对应的行或者列作为输出。

② 行位移：顾名思义，就是对状态矩阵的每一行进行位移操作，其中状态矩阵的第 0 行左移 0 位，第 1 行左移 1 位，以此类推。

③ 列混合：列混合变换是通过矩阵相乘来实现的，经唯一后的状态矩阵与固定的矩阵相乘，从而得到混淆后的状态矩阵。其中矩阵相乘中涉及到的加法等价于两个字节的异或运算，而乘法相对复杂一些，对于状态矩阵中的每一个 8 位二进制数来说，首先将其与 00000010 相乘，其等效为将 8 位二进制数左移一位，若原二进制数的最高位是 1 的话再将左移后的数与 00011011 进行异或运算。

④ 轮密相加：在开始时我们提到，128 位密钥通过密钥编排函数被扩展成 44 个字组成的序列，其中前 4 个字用于加密过程开始时对原始明文矩阵进行异或运算，而后 40 个字中每四个一组在每一轮中与状态矩阵进行异或运算（共计 10 轮）。

上述过程即为 AES 加密算法的主要流程，在我们的例子中，上述过程需要经过 10 轮迭代。而 AES 的解密过程的各个步骤和加密过程是一样的，只是用逆变换取代原来的变换。

RSA 和 AES 算法有什么区别

面试高频指数：★★★☆☆

RSA

采用非对称加密的方式，采用公钥进行加密，私钥解密的形式。其私钥长度一般较长，除此之外，由于需要大数的乘幂求模等运算，其运算速度较慢，不适合大量数据文件加密。

AES

采用对称加密的方式，其密钥长度最长只有 256 个比特，加密和解密速度较快，易于硬件实现。由于是对称加密，通信双方在进行数据传输前需要获知加密密钥。

基于上述两种算法的特点，一般使用 RSA 传输密钥给对方，之后使用 AES 进行加密通信。

DDoS 有哪些，如何防范

面试高频指数：★★★☆☆

DDoS 为分布式拒绝服务攻击，是指处于不同位置的多个攻击者同时向一个或数个目标发动攻击，或者一个攻击者控制了不同位置上的多台机器并利用这些机器对受害者同时实施攻击。和单一的 DoS 攻击相比，DDoS 是借助数百台或者数千台已被入侵并添加了攻击进程的主机一起发起网络攻击。

DDoS 攻击主要有两种形式：流量攻击和资源耗尽攻击。前者主要针对网络带宽，攻击者和已受害主机同时发起大量攻击导致网络带宽被阻塞，从而淹没合法的网络数据包；后者主要针对服务器进行攻击，大量的攻击包会使得服务器资源耗尽或者 CPU 被内核应用程序占满从而无法提供网络服务。

常见的 DDos 攻击主要有：TCP 洪水攻击（SYN Flood）、放射性攻击（DrDos）、CC 攻击（HTTP Flood）等。

针对 DDoS 中的流量攻击，最直接的方法是增加带宽，理论上只要带宽大于攻击流量就可以了，但是这种方法成本非常高。在有充足网络带宽的前提下，我们应尽量提升路由器、网卡、交换机等硬件设施的配置。

针对资源耗尽攻击，我们可以升级主机服务器硬件，在网络带宽得到保证的前提下，使得服务器能有效对抗海量的 SYN 攻击包。我们也可以安装专业的抗 DDoS 防火墙，从而对抗 SYN Flood等流量型攻击。此外，负载均衡，CDN 等技术都能够有效对抗 DDoS 攻击





### 浏览器输入域名，到显示界面的流程

https://nyimac.gitee.io/2020/12/10/URL%E8%AE%BF%E9%97%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%B5%81%E7%A8%8B

#### 1. URL解析

地址解析

其他

缓存检查

<img src="https://nyimapicture.oss-cn-beijing.aliyuncs.com/img/20201208150315.png" alt="img" style="zoom:67%;" />

#### 2. DNS解析

<img src="https://nyimapicture.oss-cn-beijing.aliyuncs.com/img/20201209141644.png" alt="img" style="zoom:67%;" />

查询缓存

​	DNS高速缓存

递归解析

​	. --> .com --> baidu.com --> www.baidu.com

 DNS负载均衡

每个公司可以有百千台服务器，DNS根据机器的负载以及与用户的距离进行分配的

#### 3. TCP连接

<img src="https://nyimapicture.oss-cn-beijing.aliyuncs.com/img/20201209141851.png" alt="img" style="zoom: 67%;" />

TCP提供一种**面向连接的，可靠的字节流**服务，是一种可靠传输。接下来将会讲解TCP的**首部、三次握手与四次挥手**。



7. 浏览器页面渲染过程
   1）浏览器通过HTML parse根据深度遍历的方式把html节点遍历成dom 树
   2）将css解析成CSS DOM树
   3）将dom树和CSS DOM树构造成render树
   4）根据得到的render树 计算所有节点在屏幕中的位置进行布局
   5）遍历render树并调用硬件API绘制所有节点



### HTTP状态码

HTTP状态码都被分成了五类。

‘1’开头，表示服务器收到请求并需要请求继续处理；‘2’开头，表成功响应，即成功处理了请求；‘3’开头，表重定向，也就是引导浏览器跳转到另一个资源页面；‘4’开头，则表示请求出错妨碍了服务器的处理，服务器会返回一个状态码解释到底是什么错误；而‘5’开头，表示服务器错误，但并非请求者的原因。

200 OK 访问正常
206 跟断点续传相关

3XX 重定向：Location
304 缓存有效
307 临时重定向
4XX 客户端问题
401 代表没有权限访问
404 代表访问的资源不存在

5XX 通常服务器内部处理的问题



### CDN

CDN的全称是Content Delivery Network，即内容分发网络。边缘节点服务（ENS） ENS中最主要的技术就是CDN。

我们在浏览网络的时候，我们访问一个页面的时候，会向服务器请求很多网络资源，包括各种图片、声音、影片、文字等信息，网站也可以预先把内容分发至全国各地的加速节点。这样用户就可以就近获取所需内容，避免网络拥堵、地域、运营商等因素带来的访问延迟问题，有效提升下载速度、降低响应时间，提供流畅的用户体验。所以，"内容分发网络"，解决了因分布、带宽、服务器性能带来的访问延迟问题，适用于站点加速、点播、直播等场景。使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度和成功率。

CDN技术消除了不同运营商之间互联的瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问质量。广泛分布的CDN节点加上节点之间的智能冗余机制，可以有效地预防黑客入侵以及降低各种DDoS攻击对网站的影响，同时保证较好的服务质量。

传统网站的请求响应过程类似，一般经历以下步骤：

```
用户在自己的浏览器中输入要访问的网站域名。
浏览器向本地DNS服务器请求对该域名的解析。
本地DNS服务器中如果缓存有这个域名的解析结果，则直接响应用户的解析请求。
本地DNS服务器中如果没有关于这个域名的解析结果的缓存，则以迭代方式向整个DNS系统请求解析，获得应答后将结果反馈给浏览器。
浏览器得到域名解析结果，就是该域名相应的服务设备的IP地址 。
浏览器获取IP地址之后，经过标准的TCP握手流程，建立TCP连接。
浏览器向服务器发起HTTP请求。
服务器将用户请求内容传送给浏览器。
经过标准的TCP挥手流程，断开TCP连接。
```

所以，引入CDN之后，用户访问网站一般经历以下步骤：

```
当用户点击网站页面上的内容URL，先经过本地DNS系统解析，如果本地DNS服务器没有相应域名的缓存，则本地DNS系统会将域名的解析权交给CNAME指向的CDN专用DNS服务器。
CDN的DNS服务器将CDN的**全局负载均衡设备**IP地址返回给用户。
用户向CDN的全局负载均衡设备发起URL访问请求。
CDN全局负载均衡设备根据用户IP地址，以及用户请求的URL，选择一台用户所属区域的**区域负载均衡设备**，并将请求转发到此设备上。
基于以下这些条件的综合分析之后，区域负载均衡设备会选择一个最优的缓存服务器节点，并从缓存服务器节点处得到缓存服务器的IP地址，最终将得到的IP地址返回给全局负载均衡设备：
				根据用户IP地址，判断哪一个边缘节点距用户最近；
				根据用户所请求的URL中携带的内容名称，判断哪一个边缘节点上有用户所需内容；
				查询各个边缘节点当前的负载情况，判断哪一个边缘节点尚有服务能力。
全局负载均衡设备把服务器的IP地址返回给用户。
用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，而区域均衡设备依然将它分配给了用户，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。
```

————————————————
版权声明：本文为CSDN博主「漫话编程」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/weixin_43167418/article/details/98564755



### 攻击类型

DDoS攻击

分布式[拒绝服务攻击](https://baike.baidu.com/item/拒绝服务攻击/421896)(英文意思是Distributed Denial of Service，简称DDoS)是指处于不同位置的多个攻击者同时向一个或数个目标发动攻击，或者一个攻击者控制了位于不同位置的多台机器并利用这些机器对受害者同时实施攻击。由于攻击的发出点是分布在不同地方的，这类攻击称为分布式拒绝服务攻击，其中的攻击者可以有多个。



CSRF攻击

伪造身份攻击，获取别人的cookie





### DNS解析

1. 浏览器DNS解析

   浏览器自身也带有DNS解析

2. 搜索host文件和操作系统缓存

3. 域名解析器（也就是我们平时的DNS服务器）

4. 从根域名解析器开始迭代解析



### DHCP协议

动态主机配置协议，让系统可以连接到网络上的一种协议



### ARP

用于建立IP地址到MAC地址的映射



### RPC

https://blog.csdn.net/daaikuaichuan/article/details/88595202?utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control

![image-20210808085026777](/Users/rb/Library/Application Support/typora-user-images/image-20210808085026777.png)

**RPC是指远程过程调用**，也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，**由于不在一个内存空间，不能直接调用**，需要通过**网络来表达调用的语义和传达调用的数据**。

1. 函数&CallID的映射表

   在RPC中，**所有的函数都必须有自己的一个ID**。这个ID在所有进程中都是唯一确定的。**客户端在做远程过程调用时，必须附上这个ID**。然后我们还需要在客户端和服务端分别维护一个 {函数 <–> Call ID} 的对应表。两者的表不一定需要完全相同，**但相同的函数对应的Call ID必须相同**。

     **【Note】当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。**

2. 序列化和反序列化

   在远程过程调用时，**客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言**（比如服务端用C++，客户端用Java或者Python）。

     **【Note】这时候就需要客户端把参数先转成一个字节流（编码），传给服务端后，再把字节流转成自己能读取的格式（解码）。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。**

3. 网络传输

   远程调用往往用在网络上，客户端和服务端是通过网络连接的。**所有的数据都需要通过网络传输**，因此就需要有一个网络传输层。

     **【Note】网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。**只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。**尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。**

4. RPC既可以同步也可以异步

   同步与异步同步和异步关注的是消息通信机制 (synchronous communication/ asynchronous communication)所谓同步，就是在发出一个调用时，在没有得到结果之前，该调用就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由调用者主动等待这个调用的结果。而异步则是相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用。

   阻塞与非阻塞阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.
   阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到
   结果之后才会返回。非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。

# 数据库

### 事务（InnoDB引擎）

1. 原子性

2. 一致性

   ​	undo log

   ​			存在数据库内部一个特殊段（segment）中，这个段叫undo段（undo segment）

   ​			undo log是逻辑日志，是数据库逻辑的恢复到原始的样子

   ​			undo log 另一个作用是MVCC

   ​			undo log 的产生伴随着redo log,undo log需要持久层的保护

   ​			undo log时逻辑日志（每行记录），redo log是物理日志（记录每页的物理修改操作）

3. 隔离性

   ​	（1） 锁lock

   * 粒度

     表锁

     行锁

   * 类型

     共享锁（S） 行锁，事务读一行的数据

     排他锁 (X)	行锁，事务删除或更新一行的数据

     意向共享锁（IS） 表锁，事务获得一张表中多行共享锁

     意向排他锁（IX） 表锁，事务获得一张表中多行排他锁

     **注意**：X锁与任何锁不兼容

     ​		IX锁与S锁和X锁不兼容

   * 机制

     无锁 

     ​	MVCC，对于自动更新的数据，InnoDB会去读区一个快照数据（undo log）

     加锁

     ​	X锁

     SELECT ... FOR UPDATE

     ​	S锁

     ​	SELECT ... LOCK IN SHARE MODE

   * 算法

     Record Lock
     Gap Lock

     Next-Key Lock

   * 问题

     读取

     ​	脏读：某个事务读取了另一个事务中未提交的数据

     ​	不可重复读：某个事务对同一个数据前后读取的结果不一样

     ​	幻读：某一个事务多一个表前后查询的行数不一样

     更新

     ​	第一类丢失更新：某一个事务的回滚，导致另一个事务更新的数据丢失

     ​	第二类丢失更新：某一个事务的提交，导致另一个事务的数据丢失。

     ​	不可能发生，在一个事务DML时需要先加IX锁，事务2不能执行相应操作。

   * 死锁

     解决：超时回滚innodb_lock_wait_timeout

     ​			死锁监测wait_for graph

   * 锁升级

     InnoDB不存在

     （2） 隔离级别

     ​	READ UNCOMMITTED 

     ​		不解决任何问题

     ​	READ COMMITTED

     ​		采用Record Lock 算法解决脏读

     ​		采用MVCC，读取被锁定行的最新一份的快照数据

     ​	REPEATABLE READ

     ​		默认的隔离级别

     ​		Next-key Lock ，解决脏读，不可重复读、幻读

     ​		MVCC

     ​	SERIALIZABLE

     ​		解决脏读、不可重复读、幻读

4. 持久性

   ​	1)redo log

   ​	当事务提交时，将事务所有日志写入redo log持久化，等待事务commit后才算完成。

   ​	redo log是顺序写的，在数据运动时不需要对该文件进行读取操作

   ​	每次写入redo log后，InnoDB调用一次fsync操作，（立刻更新磁盘）

   ​	redo log通常是物理日志，记录的是物理修改操作

   ​	2)bin log

   ​		redo log是引擎层产生，bin log 是数据库上层产生， 任何引擎对于数据库的修改都会禅师二进制日志文件

   ​		bin log是逻辑日志，存SQL语句，InnoDB引擎的redo log是物理格式日志，寸每个页的修改

   ​		bin log在事务完成后执行一次写入，redo log在事务进行中不停写入，日志不是随事务提交的顺序写入



### PreparedStatement

用PreparedStatement可以避免注入攻击，Spring框架使用的时候，使用了#就是使用了PreparedStatement预编译，不使用？就是避免了字符串拼接而发生注入攻击。



### DQL、DML、DDL、DCL

DQL数据查询语言

```
数据查询语言DQL基本结构是由SELECT子句，FROM子句，WHERE
子句组成的查询块：
SELECT <字段名表>
FROM <表或视图名>
WHERE <查询条件>
```

DML数据操纵语言

```
数据操纵语言DML主要有三种形式：
1) 插入：INSERT
2) 更新：UPDATE
3) 删除：DELETE
```

DDL数据定义语言

```
数据定义语言DDL用来创建数据库中的各种对象-----表、视图、
索引、同义词、聚簇等如：
CREATE TABLE/VIEW/INDEX/SYN/CLUSTER
                  |      |         |         |          |
                 表   视图    索引   同义词    簇

DDL操作是隐性提交的！不能rollback 
```

DCL数据控制语言

```
数据控制语言DCL用来授予或回收访问数据库的某种特权，并控制
数据库操纵事务发生的时间及效果，对数据库实行监视等。如：
1) GRANT：授权。


2) ROLLBACK [WORK] TO [SAVEPOINT]：回退到某一点。
回滚---ROLLBACK
回滚命令使数据库状态回到上次最后提交的状态。其格式为：
SQL>ROLLBACK;


3) COMMIT [WORK]：提交。
```

显示提交、隐式提交、自动提交

```
(1) 显式提交
用COMMIT命令直接完成的提交为显式提交。其格式为：
SQL>COMMIT；


(2) 隐式提交
用SQL命令间接完成的提交为隐式提交。这些命令是：
ALTER，AUDIT，COMMENT，CONNECT，CREATE，DISCONNECT，DROP，
EXIT，GRANT，NOAUDIT，QUIT，REVOKE，RENAME。


(3) 自动提交
若把AUTOCOMMIT设置为ON，则在插入、修改、删除语句执行后，
系统将自动进行提交，这就是自动提交。其格式为：
SQL>SET AUTOCOMMIT ON
```



TCL事务控制语言

```
还有事务控制语句TCL：

SAVEPOINT：保存点

ROLLBACK：回退到某点

COMMIT：提交事务
```



### SQL 中 where和on的区别

数据库在通过连接两张或多张表来返回记录时，都会生成一张中间的临时表，然后再将这张临时表返回给用户。 在使用left jion时，on和where条件的区别如下：

1、on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录。

2、where条件是在临时表生成好后，再对临时表进行过滤的条件。这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉。



### MySQL之Innodb引擎的4大特性

https://blog.csdn.net/weixin_45320660/article/details/115326483

插入缓存、二次写、自适应哈希索引、预读



### Mysql的Innodb引擎中的purge操作

```
innodb会开启一个**后台线程执行清理**工作，具体的规则是将删除版本号小于当前系统版本的行删除，这个过程叫做purge
```



### 数据库视图

```
视图也可以增删改查
视图不存储数据
可以根据数据库表和自由表来创建视图
对视图的操作最终都转化为对数据表的操作
```



### Mysql的底层数据结构

B+树

### [Mysql 索引](url=https://www.cnblogs.com/bypp/p/7755307.html)

索引优化应该是对查询性能优化最有效的手段了。

**本质都是：通过不断地缩小想要获取数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是说，有了这种索引机制，我们可以总是用同一种查找方式来锁定数据。**

**磁盘IO与预读**

考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，**当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内**，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。

# 项目

### 云服务器

```
2核4G，Cent OS8

开放端口，安全组， Sys-default和Sys-webServer，入方向

80端口 前端

90端口 后端

3306 mysql

6379 redis

9876 rocketmq

安装Putty访问服务器 云服务的地址，22端口，通过ssh协议
```

云服务器安装mysql：

```
yum list mysql-server  搜索mysql

yum install -y mysql-server.aarch64 安装mysql

systemctl start mysqld  启动mysql

systemctl status mysqld  查看mysql服务状态
```

更改mysql的密码

```
mysql -uroot -p  第一次进去mysql没有密码，直接回车

alter user root@localhost identified by '123456';

quit;

mysql -uroot -p123456
```

更改mysql的访问权限

```
show databese；//mysql自带的表有information_schema、mysql、performance_schema、sys

use mysql;

update user set host='%' where user='root'  //更改mysql的访问权限，本来只有localhost能访问，现在全部IP都能访问

flush privileges; //刷新

quit；

```

上传mysql文件

```
scp seckill.sql root@ip地址:/root
scp seckill-data.sql root@ip地址:/root
```

创建数据库，导入mysql文件

```
mysql -uroot -p123456
create database seckill;
use seckill;
source /root/seckill.sql;
source /root/seckill-data.sql;
show tables;
quit;
```

### Maven

配置镜像仓库

设置settings.xml

```xml
<mirrors>
	<id> aliyunmaven</id>
  <mirrorof>*</mirrorof>
  <name>阿里云公共仓库</name>
  <url>https://maven.aliyun.com/repository/public</url>
</mirrors>
```

### Spring Boot

![1](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第二课）/1.png)

spring-boot-starter-web 构建项目块，整合了包

spring-boot内嵌tomcat

自动配置不在需要配置.xml文件

application.properties中改server.port=...可以改端口



**IOC 控制反转**

Spring来进行bean的管理，可以降低bean之间的耦合度， 控制对象的生产， 主动装配对象

根据注解扫描对象，实现了对象的可插拔，因此如果需要更换一个对象，操作方便。

@Qualifier（“类名”)根据类名来自动装配bean

如User类不加bean，因为它会产生多个实例

可复用的则使用容器来管理

在controller中,指定访问地址，@RequestMapping（path= ， method= ）

IOC 会管理bean的生命周期和作用域

@PostConstruct

@PreDestory 

@Scope()

singleton

prototype



ApplicationContext 继承于BeanFactory 子接口API

BeanFactory 给Spring内部API ，Bean工厂

ApplicationContext.getBean();通过名字来获取bean，通过类型来获取bean



项目启动的步骤 @SpringBootApplication

1. 加载配置文件  application.properties @SpringBootConfiguration
2. 启动tomcat 
3. 创建Spring 容器
4. 自动扫描bean并将其装配到容器中  @EnableAutoConfiguration @ComponentScan



**AOP 面向切面**

![2](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第二课）/2.png)

### 项目架构

<img src="/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第一课）/项目架构.png" alt="项目架构"  >

### MyBatis

**导包**

```
mybatis-spring-boot-starter

mysql-connector-java

druid-spring-boot-starter
```

**配置**

application.properties 配置mybatis、datasource

```properties
mybatis.mapperLocations=classpath:mappers/*.xml

spring.datasource.driverClassName=com.mysql.cj.jdbc.Driver
spring.datasource.url=jdbc:mysql://ip地址:3306/seckill?characterEconding=utf8&useSSL=false&serverTimeZone=Hongkong
spring.datasource.username=root
spring.datasource.password=123456
spring.datasource.type=com.alibaba.druid.pool.DruidDateSource
##前缀spring.datasource
```

mybatis 插件 

导包：

```xml
<plugin>
  mybatis-generator-maven-plugin  ...
</plugin>
```

配置文件

mybatis-generate-config.xml

mvn mybatis-generator:generate生成

<mapper namespacr="..接口">

@Mapper加在接口上，没有实现类

1、 在mapper.xml中将namespace设置为mapper.Java的全限定名 
2、 将mapper.java接口的方法名和mapper.xml中statement的id保持一致。 
3、 将mapper.java接口的方法输入参数类型和mapper.xml中statement的parameterType保持一致 
4、 将mapper.java接口的方法输出结果类型和mapper.xml中statement的resultType保持一致



**核心内容**

![2](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第三课）/2.png)

SqlSession依赖于SqlSessionFactory创建

从Configuration配置类读取配置信息application.properties，也会加载Mapper.xml中的必要信息

Mapper接口与Mapper.xml关联

Mapper接口的实现类是动态代理生成的，通过MapperProxy是实际执行的代理对象，获取SqlSession进行增删改查

启动服务器就自动配置MyBatisAutoConfiguration自动配置类会自动初始化，创建SqlSessionFactory

MyBaitsAutoConfiguration 调用MapperScannerConfigurer,扫描Mappe接口,  创建实现类

MyBatisAutoConfiguration依赖与唯一的datasource对象，读取全局配置文件中以mybatis开头的配置。会实例化SqlSessionFactory对象到容器中。

MapperProxy是由MapperProxyFactory创建，执行invoke方法

1. SqlSessionFactory是MyBatis的关键对象,它是个单个数据库映射关系经过编译后的内存镜像.SqlSessionFactory对象的实例可以通过SqlSessionFactoryBuilder对象类获得,而SqlSessionFactoryBuilder则可以从XML配置文件或一个预先定制的Configuration的实例构建出SqlSessionFactory的实例.每一个MyBatis的应用程序都以一个SqlSessionFactory对象的实例为核心.同时SqlSessionFactory也是线程安全的,SqlSessionFactory一旦被创建,应该在应用执行期间都存在.在应用运行期间不要重复创建多次,建议使用单例模式.SqlSessionFactory是创建SqlSession的工厂.
   ————————————————
   版权声明：本文为CSDN博主「先说好不能骂我」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
   原文链接：https://blog.csdn.net/u013412772/article/details/73648537
2. SqlSession是MyBatis的关键对象,是执行持久化操作的独享,类似于JDBC中的Connection.它是应用程序与持久层之间执行交互操作的一个单线程对象,也是MyBatis执行持久化操作的关键对象.SqlSession对象完全包含以数据库为背景的所有执行SQL操作的方法,它的底层封装了JDBC连接,可以用SqlSession实例来直接执行被映射的SQL语句.每个线程都应该有它自己的SqlSession实例.SqlSession的实例不能被共享,同时SqlSession也是线程不安全的,绝对不能讲SqlSeesion实例的引用放在一个类的静态字段甚至是实例字段中.也绝不能将SqlSession实例的引用放在任何类型的管理范围中,比如Servlet当中的HttpSession对象中.使用完SqlSeesion之后关闭Session很重要,应该确保使用finally块来关闭它.

```
(1)、定义一个Configuration对象，其中包含数据源、事务、mapper文件资源以及影响数据库行为属性设置settings

(2)、通过配置对象，则可以创建一个SqlSessionFactoryBuilder对象

(3)、通过 SqlSessionFactoryBuilder 获得SqlSessionFactory 的实例。

(4)、SqlSessionFactory 的实例可以获得操作数据的SqlSession实例，通过这个实例对数据库进行操作
```

###  连接池

```
druid 连接池

1）DataSourceAutoConfiguration  是一个配置类，在springboot项目启动的时候，进行自动配置。在全局的配置文件中写spring.datasource....开头就可以被DataSourceProperties类读取

2）DruidDataSourceAutoConfigure 是实际使用的，配置类，在DataSourceAutoConfiguration前进行配置。在全局配置文件中以spring.datasource.druid开头的配置就可以被DruidDateSourceProperties类读取，如果容器中没有一个datasource的bean对象则配置类会创建一个DataSource的bean对象

3）datasource是被SqlSessionFactory依赖的
```

### 用户登录和注册

**公共代码**

```
common 包

BusinessException 定义好异常的格式，自己定义的异常RuntimeException 可以不处理异常直接throw，会在controller层处理异常

ErrorCode接口定义了错误代码

ResponseModel 返回json格式统一化 {status:0,{id:1,title:"",....}}

Toolbox 工具箱，md5方法进行加密，format 将日期进行格式化

Controller层统一处理异常，@ControllerAdvice   当Controller层中出现任何异常会调用这个类，异常处理的方法加@ExceptionHandler @ResponseBody，处理的方法handleException将异常信息code、message传入一个map对象中，用json格式传递

spring.profiles.active="" 选择不同的配置文件

logback 日志  路径

前端用轻量级的bootstrap、jQuery框架
```

**注册登录**

```
表user_info 用户表

User实体类
数据校验通过hibernate-validator，导入包
@NotNull
@NotBlank  不能为null也不能为空
@Min(value=   ,message= )

ObjectValidator校验类 @Component 
validate方法

UserMapper接口  @Mapper  持久层处理的方法

UserMapper.xml  sql处理

UserService接口
UserServiceImpl 实现类@Service

@Transactional 事务处理
```

### Nginx

```
当一台服务器无法支持大量的用户访问时，将用户分摊到两个或多个服务器上的方法叫负载均衡。
Nginx有4个模块，core、handlers、filters、load-balancers

负载均衡模块load-balancers
过滤操作的filters模块

配置了负载均衡模块，则前一步应该先访问的是Nginx负载均衡服务器的ip，将请求发送到这个ip上。Nginx会根据设定的配置分配算法和规则，选择一台后端真实的web服务器，与之建立TCP连接，转发请求。

Nginx支持RR轮转法和 ip_hash法
前者会从头到尾一个个轮询所有Web服务器，而后者则对源IP使用hash函数确定应该转发到哪个Web服务器上，也能保证同一个IP的请求能发送到同一个Web服务器上实现会话粘连。、
其他分配算法包括 fair、url_hash

然后web服务器处理请求，将响应返回给负载均衡服务器
Nginx负载均衡服务器将响应交给filters链处理，然后返回给浏览器

Filter功能是处理前一步的结果
```

### 状态管理

```
第一版本用session存储用户

用拦截器来检查用户的登录状态，LoginCheckIntercepter implement HandlerInterceptor
preHandler  返回false就不会执行handler（controller），由于这个方法默认返回的是boolean，没有办法返回responsemodel，所以手写response，使用fastjson的JsonObject 
还需要自己写一个配置类@Configuration 实现WebMvcConfigurer接口，使用addInterceptors来注册interceptor
InterceptorRegistry registery.addInterceptor("...").addPathPatterns("....")


前端也需要显示用户的登录状态，通过user.js

postHandler
afterCompletion
```

### 跨域问题

#### localhost和127.0.0.1 

```
localhost是一个域名，具体对应哪个IP地址只需要在host中配置，默认是127.0.0.1.

本机IP是与网卡绑定的，用于外部设备的访问。

127.0.0.1是本机用于监听的，外部设备不可访问。

localhost:8080 访问 127.0.0.1;8080属于跨域— 因为浏览器不能确定localhost具体是否是指127.0.0.1 虽然默认如此，但是可以轻易改变。

localhost与127.0.0.1的概念和工作原理不同。

localhost：也叫local ，本地服务器
127.0.0.1：本机地址(本机服务器)

一个是“本地”，一个是“本机”。

localhot：是不经网卡传输的，它不受网络防火墙和网卡相关的的限制。
127.0.0.1：是通过网卡传输的，它依赖网卡，并受到网络防火墙和网卡相关的限制。

localhost能访问但127.0.0.1不可以访问的问题，究其原因，很可能是localhost访问时，系统带的本机当前用户的权限去访问，而用ip的时候，等于本机是通过网络再去访问本机，可能涉及到网络用户的权限。

另外一般设置程序时本地服务用localhost是最好的，localhost不会解析成IP，也不会占用网卡、网络资源。
```

#### 项目中的跨域

```
127.0.0.1:5500
5500端口是我们的vscode服务器liveserver的端口(静态)，服务又请求了8080端口tomcat（动态）
```

#### 跨域的解决方法

1. 通过代理服务器 Nginx

   ![1](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第四课）/1.png)

2. 前端  只能是get请求，欺骗服务器

   

   ![2](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第四课）/2.png)

3. 后端进行@CrossOrigin

   前端要设置允许带cookies

   在ResponseHeaders中会有Access-Control-Allow-Origin:    http://127.0.0.1:5500

### Cookies && Session

让服务器可以识别用户（用户状态），用户第一次访问，服务器会判断要创建cookie  

将cookie 给用户保存，可能有敏感信息会修改不安全， 容量有限2k、存储形式单一，只能是字符串。

![3](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第四课）/3.png)

一个session有一个cookie JSESSIONID，session是tomcat创建好的，session是依赖于cookie，session存在于内存中，更加安全、存储类型不限制，session默认30分钟

![4](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第四课）/4.png)

Nginx做负载均衡，redis存储session，但是在多客户端使用时不适用，因为session依赖于cookie，如果客户端不是浏览器就不行，使用token就可以避免这个问题，token是广义的session

![5](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第四课）/5.png)

### 单点登陆

sso单点登陆

子系统之间的登录

根域名相同时，单点登陆好解决，跨域不能传cookie，但是因为根域名相同，可以设置cookie的范围允许传cookie

![6](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第四课）/6.png)

域名完全不同时 ，服务器之间的通信（验证token）用web service，全局token和局部token，只需要登陆一次。当全局token失效会通知局部token进行销毁。![屏幕快照 2021-08-07 上午9.12.59](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第四课）/屏幕快照 2021-08-07 上午9.12.59.png)

### 索引

需要自己再整理！！！！！！！！

1. 索引分类：**普通索引**、**唯一索引**（主键索引）、全文索引、空间索引

2. 存储方式：**B-Tree**、Hash（innodb支持B-Tree，数据存储有序，B+树）

3. 依赖的列数：单列索引、组合索引

4. 数据分布：**聚簇索引**（不用回表）、**二级索引**（辅助索引，返回id再去聚簇索引中查找）

5. 回表情况：**覆盖索引**（不用回表）

   当一个索引覆盖了需要查询的字段的值时就是覆盖索引

   聚簇索引中包含了所有的数据，所以它是一个覆盖索引。不对，只有select和where中出现的列被索引覆盖的情况才是覆盖索引，using index

   title 构建了索引

   select *

   from item 

   where title=... and ;

6. 最左前缀

   ```mysql
   	table T , index(a,b,c)
   	
   	-- 全值匹配
   	select * from T where a='' and b='' and c='' ;-- Y
   		select * from T where b='' and a='' and c=''; -- Y
   		
   	-- 匹配左前缀
   	Select * from T where a='';  -- Y
   	Select * from T where b='';  -- N
   	
   	
   	-- 匹配列前缀
   select * from T where a like 'x%'; -- Y
   select * from T where a like '%x'; -- N
   select * from T where b like 'x%'; -- N
   
   
   -- 匹配范围值
   select * from T where a between ' ' and ' '; -- Y
   select * from T where b between ' ' and ' '; -- N
   
   -- 全值匹配 + 范围匹配
   select * from T where a=' ' and b between ' ' and ' ';  -- Y
   select * from T where b=' ' and c between ' ' and ' ';  -- N
   select * from T where a between ' ' and ' ' and b=' ';  -- N
   
   ```

   索引解决查询慢的问题

   explain 查看索引是否生效  explain select * from item; 返回执行计划  可以看type 和 rows等检查语句的效率，用explain select 1 from item

### 慢查询日志

```
show variable like 'slow_query';

show variable like 'long_query';

set global show_query_log='ON';

set global long_query_time=1;

quit；


如果sql查询超过指定时间则被记录在日志中

tail /var/lib/mysql/nowcoder_slow.log

慢的原因可能是没有加索引，或者没有执行索引（没有最左前缀匹配）、子查询
explain 
```

### 下单时扣减库存来解决超卖问题

```
order_info(订单表)

id(20位，前8位年月日后12位是流水)	user_id	item_id	promotion_id	order_price	order_amount	order_total	order_time

id这样设计可以方便数据表的拆分，将历史订单的数据移出
```

```
serial_number表里面的order_serial是用来记录订单最大序号的
SerialNumberMapper   ...for update  增加了一个行锁、排他锁，避免其他线程会更改，避免订单号重复
```

```
ItemMappper   

ItemStockMapper   依据主键来增删改查，decreaseStock

OrderMapper

```

```
ItemServiceImpl:

decreaseStock 

IncreaseStock	

OrderServiceImpl:

createOrder
```

```
前端  item.html+item.js
```

整个项目是没有付款步骤的

### 事务

mysql使用了MVCC机制，既保证了并发性又保证了事务执行的效率。

看脑图

Spring中实现事务就通过@Transitional，隔离级别默认就是Repeatable Read， 事务嵌套时设置属性 propagation=Propagation.Required 如果外部有事务则使用外部的事务，如果外部没有事务则自己创建一个事务，设置属性propagation=Propagation.Requires_new则不管外部是否有事务都是自己创建一个新的事务

Spring框架底层实现Transactional是通过AOP



### 部署&测试

Nginx可以做web服务器和反向代理

tomcat是可以通过代码打包jar，自带一个tomcat

压测商品详情+下单页面

![1](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第六课）/1.png)



指定配置文件spring.profiles.active=dev参数可以在云服务器启动的时候指定

反向代理和Tomcat之间走本地路径127.0.0.1，数据库也是本地网络127.0.0.1:3306

mvn clean package -Dmaven.test.skip-true

scp ....jar root@ip:/root

Tomcat是8080端口

```
云服务器需要安装jdk 
yum list java*

yum install -y java-1.8.0-openjdk.aarch64

java version
```

```
上传启动脚本
startup.sh

配置权限
chomd -R 777 startup.sh

启动
sh startup.sh

会在nohup.out打印日志
tail nohup.out

启动
nginx -c /etc/nginx/nginx.conf

将静态页面zip传递到   /usr/share/nginx/html目录下

unzip seckill-site

要配置前端代码，AJAX需要配置访问云服务器的90端口
```

```
安装Nginx，配置web服务+反向代理
yum list Nginx*
yum install -y  nginx.aarch64
```

```
JMeter测试工具安装，jmeter.properties里设置sampleresult.default.encoding=UTF-8


查看服务器的状态：
top -h    主要看load average、%Cpu（s）
压测商品详情页面
吞吐量在300左右的请求/
下单操作压测需要先登录，可以先获得cookie，模拟一个用户
```

```
配置Nginx,监听80和90端口
cd /etc/nginx
vim nginx.conf

server{
				listen 80;
				location / {
										alias  /usr/share/nginx/html/seckill-site/;
										index seckill.html;
				}
}

upstream myserver{
				server	127.0.0.1:8080 max_fails=3	fail_timeout=30s;
}

server{
				listen 90;
				server name _;
				location / {
										proxy_pass http://myserver;
				}
}

nginx -s reload
```

```
单节点部署
分布式部署
通过Nginx进行负载均衡（Nginx可以做热备份），tomcat集群，mysql可以读写分离（mysql一般不做集群，因为需要分布式事务，复杂），增加两级缓存（Gauva cache、redis，guava cache是直接跑在tomcat上的），消息队列异步消息处理提高处理性能。
```



![2](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第六课）/2.png)

```
总结：中间件提高性能，通过两级缓存提高了查询的并发性能，通过缓存和rocketMQ一步消息提高了下单功能的持久化操作响应的能力，通过tomcat集群配置、分布式部署提高性能。

redis  理论上的QPS 十万/s
```

### MySQL 主从分离

```
主服务器主要进行数据的写入、从服务器主要是数据的读取

MySQL主服务器以事务为单位存储bin log（二进制日志），Mysql从服务器主要是起到一个对主服务器进行备份的作用，Mysql的从服务器则从bin log中进行读取日志文件

Mysql 既需要读取主服务器中的bin log，又需要运行外部的数据读取，因此是多线程，主要有两个线程，一个IO线程、一个是SQL线程。因此IO线程按照一定的频率从Mysql主服务器中的bin log中读取，将其写入自己的relay log（中继日志中），而SQL线程则从relay log中读取数据。从服务器还会进行快照备份，快照的主要用于恢复主服务器。
```



![3](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第六课）/3.png)



### Mysql 外部分布式事务

可以跨数据库（例如跨行转账），核心是两阶段提交，资源管理器就是数据库或者rocketMQ，事务管理器是协调者，但事务不能百分百保证，应用层进行保证处理。

![4](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第六课）/4.png)



### Mysql内部分布式事务

MySQL 主服务器的bin log和redo log需要保证事务一致性，需要保证同步。也是需要两阶段提交，创建一个InnoDB prepare，当InnoDB 写入redo log失败则可以通过bin log进行分布。

![5](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第六课）/5.png)



### Redis

```
安装redis
yum list redis*
yum install redis.arrch64

配置redis
vim /etc/redis.conf
:set nu
#bind 127.0.0.1 允许外网访问
daemonize yes  支持后台运行
requirepass ..（密码）  设置密码

redis-server  /etc/redis.conf 指定配置文件启动redis
redis-cli -a 密码  进入客户端

redis默认自带16个库（0～15）
select 9 就是进入到第9个库
select 0 进入第0个库

key * 查询所有的key，在生产环境中key*会查询上百万的key，因此会阻塞服务器，因此在生产环境不使用

set [key] [value]
get [key]
del [key]
exist [key]
incr [key]
decr [key]
set [key] [value] ex(px) [time]  设置存储指定时间的数据ex表示秒，ps表示毫秒
ttl [key] 查询到期时间
flushdb 删库跑路
quit 退出

redis.cn 中文网站

```



```xml
在项目中引入redis

<dependency>
  					<groupId>org.springframework.boot</groupId>
  					<artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```



```
在项目中配置redis
spring.redis.database=0
spring.redis.host= 主机
spring.redis.port=6379
spring.redis.password=
```

```
Springboot中的自动配置类 redisAutoConfiguration会调用RedisProperties类，然后RedisProperties就会从配置文件中读取以spring.redis开头的配置信息，Springboot支持两种redis客户端的配置（Lettuce、Jedis），对外访问的接口RedisTemplate。redisConnectionFactory。可以自己配置redisTemplate对象

自定义了redisSerializer（redis的序列化器）：
FastJsonSerializer implement RedisSerializer  主要是调用了FastJson的API对对象数据进行序列化和反序列化

```

```
redis事务
redisTemplate.execute（new SessionCallback(){

				public Object execute(RedisOperations operations) throws DataAccessException{
				
								Operations.multi(); //开启事务
								Operations.exec();	//提交事务
				}
}）;
```

```
使用redis

@Autowired
RedisTemplate redisTemplate；


redisTemplate.opsForValue().set("", );

```

```
redis做用户状态管理
返回token给浏览器，浏览器有Local storage 、 Session Storage
浏览器返回时在url上拼接token
当然token可能被截获，然后伪造身份攻击服务器（CSRF攻击），但是这需要后期服务器的安全检测，例如异地重登录、可疑设备检测等等的策略。

不使用Session为了满足不同的客户端登录，token更通用。
```

redis IO多路复用，可以用单线程并发处理，使用一个IO多路复用程序监听socket的状态，引入套接字队列来有序处理socket对象，使用文件事件分排器来读取套接字队列



![1](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第七课）/1.png)



Redis远程缓存+Guava本地缓存

Guava是运行在tomcat中本地缓存，二级缓存

```
<dependency>
						<groupId>com.google.guava</groupId>
  					<artifactId>guava</artifactId>
  					<version>27.0.1-jre</version>
</dependency>
```

用两级缓存优化商品的查询 findItemByCache，在创建订单时调用

用redis缓存用户的状态，用户数量大不适合本地缓存





**Redis持久化**

dbfilename dump.rdb

dir /var/lib/redis

RDB持久化，快照，二进制文件，使用了操作系统的写时复制技术

其实副本+剩余的页就是父进程所需要使用的，后续不使用的页可以回收 

<img src="/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第八课）/1.png" alt="1" style="zoom:150%;" />

AOF持久化，独立日志，记录命令。

AOF重写：AOF会有很多冗余命令，减少文件体积

![2](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第八课）/2.png)





### 分布式缓存

缓存淘汰策略

缓存与数据库同步

![3](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第八课）/3.png)

![4](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第八课）/4.png)

分布式缓存的常见问题









![削峰限流方案](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十课）/削峰限流方案.png)

![ROCKETMQ事务型消息](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十课）/ROCKETMQ事务型消息.png)



### 削峰限流



![1](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十一课）/1.png)



![2](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十一课）/2.png)



![3](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十一课）/3.png)

![4](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十一课）/4.png)

![5](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十一课）/5.png)



![6](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十一课）/6.png)



![7](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十一课）/7.png)



![8](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十一课）/8.png)

![9](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十一课）/9.png)

![10](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第十一课）/10.png)

# Spring

### 粗糙的Spring对象构建过程

加载配置文件，解析，封装成BeanDefinition对象，实例化，完整对象，使用。

获取ApplicationContext对象，调用getBean方法，得到对象，根据名字找、根据类型找。

Container中有Map结构，存储bean。

### 具体的过程

Application Context 是BeanFactory 的子接口

BeanFactory是访问Spring Bean Container的入口

xml文件、properties文件、yaml文件、注解、json抽象出一个借口【BeanDefinitionReader】，这些不同子类实现不同，最后得到BeanDefinition（bean的定义信息） 对象。（BeanDefinition通过new或者反射实例化对象---复杂过程！）BeanDefinition并不会对占位符替换。BeanFactoryPostProcessor可以进行替换。  

### 反射的过程

1. 获取class对象

   Class.forName();

   类名.class

   对象.getClass();

2. Constructor ctor=Clazz.getDeclareConstructor();

   Object obj = ctor.newInstance();

### 配置文件

在.xml文件中加入使用外置的配置文件的时候，需要使用：

```xml
<context:property-placeholder location="classpath:...."</context:property-placeholder>
<bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource">
  <property name="username" value="${jdbc.username}"></property>
  <property name="passward" value="${jdbc.passward}"></property>
  <property name="url" value="${jdbc.url}"></property>
  <property name="driverClassName" value="${jdbc.driverClassName}"></property>
</bean>
```

但是配置文件在获取BeanDefinition对象的时候，相应的占位符还未被替换，需要通过BeanFactoryPostProcessor对象调用PlaceholderConfigurerSupport进行替换，

PostProcessor（接口） 后置处理器/ 增强器，有两个BeanFactoryPostProcessor（接口）和BeanPostProcessor（接口）

<img src="/Users/rb/Desktop/找工作的资料/我的整理笔记/图片 4.png" alt="图片 4"  />

# Spring MVC



### SpringMVC和Struct2的区别

```
1、Struts2是类级别的拦截， 一个类对应一个request上下文，SpringMVC是方法级别的拦截，一个方法对应一个request上下文，而方法同时又跟一个url对应,所以说从架构本身上SpringMVC就容易实现restful url,而struts2的架构实现起来要费劲，因为Struts2中Action的一个方法可以对应一个url，而其类属性却被所有方法共享，这也就无法用注解或其他方式标识其所属方法了。

2、由上边原因，SpringMVC的方法之间基本上独立的，独享request response数据，请求数据通过参数获取，处理结果通过ModelMap交回给框架，方法之间不共享变量，而Struts2搞的就比较乱，虽然方法之间也是独立的，但其所有Action变量是共享的，这不会影响程序运行，却给我们编码读程序时带来麻烦，每次来了请求就创建一个Action，一个Action对象对应一个request上下文。

3、由于Struts2需要针对每个request进行封装，把request，session等servlet生命周期的变量封装成一个一个Map，供给每个Action使用，并保证线程安全，所以在原则上，是比较耗费内存的。

4、 拦截器实现机制上，Struts2有以自己的interceptor机制，SpringMVC用的是独立的AOP方式，这样导致Struts2的配置文件量还是比SpringMVC大。

5、SpringMVC的入口是servlet，而Struts2是filter。
```

### 过滤器、监听器、拦截器

```
1）过滤器（Filter）：所谓过滤器顾名思义是用来过滤的，Java的过滤器能够为我们提供系统级别的过滤，也就是说，能过滤所有的web请求，这一点，是拦截器无法做到的。在Java Web中，你传入的request,response提前过滤掉一些信息，或者提前设置一些参数，然后再传入servlet或者struts的action进行业务逻辑，比如过滤掉非法url（不是login.do的地址请求，如果用户没有登陆都过滤掉）,或者在传入servlet或者struts的action前统一设置字符集，或者去除掉一些非法字符。filter 流程是线性的，url传来之后，检查之后，可保持原来的流程继续向下执行，被下一个filter, servlet接收。

（2）监听器（Listener）：Java的监听器，也是系统级别的监听。监听器随web应用的启动而启动。Java的监听器在c/s模式里面经常用到，它会对特定的事件产生产生一个处理。监听在很多模式下用到，比如说观察者模式，就是一个使用监听器来实现的，在比如统计网站的在线人数。又比如struts2可以用监听来启动。Servlet监听器用于监听一些重要事件的发生，监听器对象可以在事情发生前、发生后可以做一些必要的处理。

（3）拦截器（Interceptor）：java里的拦截器提供的是非系统级别的拦截，也就是说，就覆盖面来说，拦截器不如过滤器强大，但是更有针对性。Java中的拦截器是基于Java反射机制实现的，更准确的划分，应该是基于JDK实现的动态代理。它依赖于具体的接口，在运行期间动态生成字节码。拦截器是动态拦截Action调用的对象，它提供了一种机制可以使开发者在一个Action执行的前后执行一段代码，也可以在一个Action执行前阻止其执行，同时也提供了一种可以提取Action中可重用部分代码的方式。在AOP中，拦截器用于在某个方法或者字段被访问之前，进行拦截然后再之前或者之后加入某些操作。java的拦截器主要是用在插件上，扩展件上比如 Hibernate Spring Struts2等，有点类似面向切片的技术，在用之前先要在配置文件即xml，文件里声明一段的那个东西。
```

![1](/Users/rb/Desktop/找工作的资料/春招集训营/随堂资料（第三课）/1.png)

DispatcherServlet，满足http协议，已经自动给tomcat, 源码中有doDispatch方法中调用getHandler获取HandlerMapping根据request请求得到的HandlerExecutionChain,通过getHandlerAdapter获取HandlerAdapter，然后调用HandlerAdapter的handle方法返回ModelAndView，然后processDispatcherResult处理ModelAndView, 调用ViewResolver的render渲染到模版引擎，返回view。

mv==null, 直接返回

interceptor方法通过返回的handler

HandlerMapping 扫描注解

HandlerExecutionChain  

拦截器



**dispatcherservlet**

 接收请求，并配发请求，对请求回应，降低了组建了之间的耦合性

**HandlerMapping**

根据用户的请求映射对应的Handler和HandlerInterceptor，根据URL找到URI，根据URI找到处理器和拦截器

**HandlerAdapter**

按照规则执行handler， 如果handler有对应的handerAdapter则会调用handler之前调用handlerinterceptor的prehandler方法，对handler进行拦截

**HandlerInterceptor**

prehandler会提取http请求中的数据，填充到handler中

**Handler**

就是controller，是业务代码的核心

### 实际原理

DispatcherServlet: 前置控制器，

HandlerMapping

HandlerExcutionChain

HandlerAdapter 自动数据类型转换

Handler

ModelAndView

ViewResolver

### Restful 风格URL

localhost:8080/index/1/tom 

###  映射Cookie

JSESSIONID

### 使用POJO绑定参数

Spring MVC 会根据请求参数名和POJO属性名进行匹配，自动为对象填充属性值，支持属性及联。

中文乱码通过filter即可





### 2. 同源策略

所谓同源是指"协议+域名+端口"三者相同，即便两个不同的域名指向同一个 ip 地址，也非同源。同源策略/SOP（Same origin policy）是一种约定，由 Netscape 公司 1995 年引入浏览器，它是浏览器最核心也最基本的安全功能，现在所有支持 JavaScript 的浏览器都会使用这个策略。如果缺少了同源策略，浏览器很容易受到 XSS、 CSFR 等攻击。

跨站脚本攻击（XSS），是最普遍的Web应用安全漏洞。这类漏洞能够使得攻击者嵌入恶意脚本代码到正常用户会访问到的页面中，当正常用户访问该页面时，则可导致嵌入的恶意脚本代码的执行，从而达到恶意攻击用户的目的。

CSRF跨站点请求伪造(Cross—Site Request Forgery)，跟XSS攻击一样，存在巨大的危害性，你可以这样来理解：
    攻击者盗用了你的身份，以你的名义发送恶意请求，对服务器来说这个请求是完全合法的，但是却完成了攻击者所期望的一个操作，比如以你的名义发送邮件、发消息，盗取你的账号，添加系统管理员，甚至于购买商品、虚拟货币转账等。



# Redis

### 数据类型

```
String 
hash
list
set
zset
```

### redis 单线程

redis的网络IO、数据读写都是单线程的，其他的功能例如：持久化、异步删除、集群数据同步则依赖于其他线程。

redis大多数的操作都是在内存中完成，而且redis支持IO多路复用，可以并发处理大量客户端的请求。



### redis的持久化机制

```
RDB持久化
					默认
					快照的形成持久化到硬盘中
					通过BGSAVE命令手动/自动触发
AOF持久化
					以独立日志方式，记录每次写入的日志
					实时性好，在保证性能的前提下，最多丢失1s的数据
					比RDB文件体积大，可以通过重写机制压缩AOF文件的体积
RDB-AOF混合持久化
					从redis4.0开始支持，基于AOF实现
					在AOF重写时，先执行BGSAVE命令生成RDB文件，再将新处				理的文件加到AOF的尾部。
```



### 打开方式

1. 进入到redis目录
2. bin/redis-server ect/redis.conf
3. bin/redis-cli

### Nosql

```
在我们日常的开发中最常用的就是关系型数据库，在一般的系统中不存在高并发的需求，使用关系型数据库不存在问题。涉及大数据量的需求时，例如商品的抢购时，页面的访问量一下子增加，单一使用数据库来保存数据由于需要大量的读写操作就会造成数据库系统的瘫痪，最终可能会发生宕机。

因此为了克服这个问题，会采取NoSQL技术，这是一种基于内存的数据库，且提供一定的持久化功能。redis就是NoSQL技术的一种。
```



### 缓存穿透、缓存击穿、缓存雪崩的概念

```
缓存穿透：key对应的数据不存在，则每次针对key的请求在缓存中都不能命中，因此需要请求数据库，从而压垮数据库，如用一个不存在的用户id获取用户的数据，无论缓存和数据库中都不存在，则黑客可以利用这个漏洞进行攻击压垮数据库。　　缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。

缓存击穿：key对应的数据存在，但是在redis中过期，此时大量的并发请求就会从后端加载，并存入缓存中，这种大量的请求则可能会把数据库压垮。某一个key在某些时间点被超高并发的访问，是“热点”数据，可能会存在缓存击穿的问题。缓存击穿是由于原有缓存失效(过期)，新缓存未到期间。所有请求都去查询数据库，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃

缓存雪崩：缓存服务器重启或者大量缓存集中在一个时间段失效，则会给后端系统带来很大压力。与缓存击穿的区别在于这里针对很多key缓存。
```



### 解决方法

```
1. 缓存穿透的解决方法 
		布隆过滤器，将所有可能存在的数据进过哈希算法存储到bitmap对应的位置中，一定不存在的数据则会被bitmap拦截，从而避免了底层存储的查询压力。例外，也可以粗暴的将不存在的数据空结果保存在缓存中，这样再次请求时就可以在缓存中命中，不过一般都将这个数据过期时间设置较短。
2. 缓存击穿的解决方法
		一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间key是锁着的，这是过来1000个请求999个都在阻塞的。同样会导致用户等待超时，这是个治标不治本的方法。
		还有一个解决办法解决方案是：给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。　缓存标记：记录缓存数据是否过期，如果过期会触发通知另外的线程在后台去更新实际key的缓存。		缓存数据：它的过期时间比缓存标记的时间延长1倍，例：标记缓存时间30分钟，数据缓存设置为60分钟。 这样，当缓存标记key过期后，实际缓存还能把旧数据返回给调用端，直到另外的线程在后台更新完成后，才会返回新缓存。
3. 缓存雪崩的解决方法
		大多数系统设计者考虑用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
		
		“二级缓存”的解决方法。

　　
```

### 缓存预热

```
　　缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样避免，用户请求的时候，再去加载相关的数据。

　　解决思路：

　　　　1，直接写个缓存刷新页面，上线时手工操作下。

　　　　2，数据量不大，可以在WEB系统启动的时候加载。

　　　　3，定时刷新缓存，
```

### 缓存更新

```
　　缓存淘汰的策略有两种：

　　　　(1) 定时去清理过期的缓存。

　　　　(2)当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。 

　　两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂，具体用哪种方案，大家可以根据自己的应用场景来权衡。1. 预估失效时间 2. 版本号（必须单调递增，时间戳是最好的选择）3. 提供手动清理缓存的接口。
```



# Linux

### linux 中的kernel space和user space

kernel space 内核空间，是linux内核的运行空间，可以调用任意命令，调用系统的一切资源

user space 用户空间，是用户程序的运行空间，只能简单的运算，不能直接调用系统资源，必须通过系统接口

<img src="http://www.ruanyifeng.com/blogimg/asset/2016/bg2016120201-2.png" alt="img" style="zoom:200%;" />

Linux允许一个进程创建新进程，整个Linux进程是一个进程树结构，树根是系统自动构建的，即在内核态下执行的0号进程是所有进程的祖先，0号进程创建1号进程，1号进程负责内核的部分初始化工作以及系统配置，创建高速缓存和虚拟主存管理的内核线程。然后1号进程就会调用execve()运行可执行程序init，然后演化为用户态1号进程，即init进程。

fork()允许用户态下创建新的进程，fork的子进程复制父进程的资源，包括内存的内容task_struct内容，新旧进程使用同一代码段,复制数据段和堆栈段，这里的复制采用了注明的copy_on_write技术，即一旦子进程开始运行，则新旧进程的地址空间已经分开，两者运行独立。

在 Linux 内核中,供用户创建进程的系统调用fork()函数的响应函数是 sys_fork()、sys_clone()、sys_vfork()。这三个函数都是通过调用内核函数 do_fork() 来实现的。根据调用时所使用的 clone_flags 参数不同，do_fork() 函数完成的工作也各异。



### Linux进程调度状态转化

https://segmentfault.com/a/1190000021140927

Task_Running(R) 可运行状态

Task_interruptible（S）可中断的休眠

Task_uninterruptible(D) 不可中断休眠

Task_stop（T）停止状态

Task_traced(t) 跟踪状态

Exit_zombie(Z) 僵尸状态

Exit_Dead(X) 死亡状态

<img src="/Users/rb/Library/Application Support/typora-user-images/image-20210807211819371.png" alt="image-20210807211819371" style="zoom:50%;" />

# 设计模式

https://zhuanlan.zhihu.com/p/263565558 待整理



### 单例模式

保证一个类只有一个实例，并提供一个全局访问点



### 工厂模式

静态工厂模式、抽象工厂



### 开发者模式





### 观察者模式







# 工具类

Apache库StringUtils.contains

Apache的`commons-lang3`提供许多开箱即用的功能，`StringUtils`就提供了许多与字符串相关的功能，

# 待整理的面试题



八股文： 

\1. static修饰类，方法，变量有什么作用，final呢？ 

\2. ==和equals区别 

\3. Object类的hashcode方法的作用 

\4. hashmap的哈希冲突，rehash 

\5. GC Roots节点都有啥 

\6. G1收集器的收集[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)

\7. redo log 和undo log的用处，binlog的用处；从服务器主动拉binlog，还是主服务器推binlog 

\8. InnoDB为什么要用B+树做索引 

[算法题](https://www.nowcoder.com/jump/super-jump/word?word=算法题)： 

给一个升序数组，部分掉换，例：[4, 5, 6, 7, 0, 1, 2]，给一个target：0，找到位置（力扣原题，题号忘了） 

反问：本来想问两道[算法题](https://www.nowcoder.com/jump/super-jump/word?word=算法题)，前面聊多了，所以就一道，问的比较简单，会让后面面试官着重考察[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)（孩子哭了



1. 怼实习[项目](https://www.nowcoder.com/jump/super-jump/word?word=项目)和学校[项目](https://www.nowcoder.com/jump/super-jump/word?word=项目)
2. Spring的ioc和aop说一说
3. 如果让你实现一个ioc，你要怎么做？
4. aop实现原理，以及jdk动态代理会遇到的问题
5. 那cglib就没有什么问题了吗？
6. cookie和session区别
7. session存不下怎么办？
8. 键入一个url网址的过程
9. tcp连接的三次握手，没有第三次行不行?
10. tpc和udp的区别，以及他们适用的范围（应用层哪些用的tcp，哪些用的udp）
11. 说一说java并发（volatile，synchronized）
12. synchronized的效率如何？（锁升级）
13. 了解过其他并发包吗？（vector, copyOnWrite, ConcurrentHashMap, AQS的锁，reentrantLock）
14. 自己写代码如何避免死锁？
15. 了解哪些[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法),都讲一讲？
16. 快排最坏复杂度？归并呢？
17. HTTPS加密过程
18. 为什么一开始要用非对称加密，直接用对称加密不行吗？了解过公钥加密和私钥加密的应用范围吗？
19. 自己如何使用udp实现可靠的数据传输？
20. 八个硬币，有一个最轻，其他一样重，用天平最少几次能选出最轻那个
21. **写题**：1，2，3，4。。。。。n 中选k个数，输出所有选择的可能性。

二面

1. tcp的滑动窗口说一下
2. 发送窗口会变成0吗？
3. linux了解哪些命令？
4. grpc用的什么序列化（protobuf）
5. protobuf怎么编码的？
6. 修改了protobuf的字段，应该先上线服务提供方，还是服务调用方？？
7. [redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)如何实现分布式锁？（使用set五个参数那个命令）
8. [redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)如何保证原子性？（[redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)是单线程执行的，单个命令就是原子执行的）
9. [redis](https://www.nowcoder.com/jump/super-jump/word?word=redis)的数据结构了解哪些？说了跳表，然后跟面试官聊了五分钟的跳表。
10. MySql的隔离级别和产生的问题
11. MySql的索引说一下？
12. B树使用场景？
13. 给一个表，id,a,b,c (a,b)是联合索引 select * from db where a > x and b == y;能否使用上索引？那查找过程呢？a走不走索引？b走不走？
14. update set c == x,会加什么锁？，那update set id == x呢？
15. **写题**：[二叉树](https://www.nowcoder.com/jump/super-jump/word?word=二叉树)的右视图
16. **口述思路**：一个无序数组，找到一个数，左边都比他小，右边都比他大

三面

1. 介绍实习[项目](https://www.nowcoder.com/jump/super-jump/word?word=项目)
2. 聊RPC，protobuf序列化方式
3. 介绍一下服务治理
4. java代码编译加载执行的过程
5. 类加载过程讲一讲
6. 如何去找到入口去执行第一段代码
7. linux系统的虚拟地址空间讲一讲
8. 进程内存空间怎么分布的？（linux和jvm中）
9. 除了堆和栈还有哪些区域？
10. 什么是堆外内存？
11. 悲观锁和乐观锁以及现实场景
12. mysql怎么体现乐观锁？
13. Mysql 中某索引列 已经 存在 5，9记录，第一个事务Insert 6，第二个事务 select for update where col > 4? （问：第二个事务是否会被block？如果没有for update会不会被阻塞？那如果第二个事务insert 7会不会加锁？）
14. 注册的用户密码应该怎么存储？
15. md5和加密[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)有啥区别？
16. 讲一讲非对称和对称加密的概念
17. 非对称加密的公钥加密私钥解密和私钥加密公钥解密使用场景？
18. jvm垃圾回收和收集器的概念（讲了引用计数，可达性分析，回收[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)，cms收集器）
19. 为什么年轻代用复制，老年代用标记整理？
20. 如何对mysql查询进行优化？
21. explain了解哪些参数？
22. **写题**：[二叉树](https://www.nowcoder.com/jump/super-jump/word?word=二叉树)中找出满足节点和为某一给定值k的所有路径（路径是指的根节点到叶子结点）
23. 闲聊阶段





1、[项目]()中的手机发送验证码功能怎么实现的，用了那个平台的API（这块没看，纠结了半天，没说好） 

2、List、Set、Map的区别 

3、HashMap底层实现原理 

 4、HashMap的遍历方式（7种，大概说了4,5种） 

  5、线程创建方式 

  6、线程状态 

  7、线程池类型 

  8、线程锁有哪些（感觉没回答到点上） 

  9、Mybatis #{}和的区别，{}的区别，的区别，{}在SQL语句中什么情况下用（没回答好） 

  10、Redis数据类型 

  11、Redis缓存穿透

1.自我结束
2.什么时候开始学习前端的
3.从你的项目中拿一个印象深刻的说一说
4.线程和进程的区别?线程之间是怎么通信的?
5.CDN 的原理?有什么用处?
6.解释什么是正向代理和反向代理? 为什么要分正向和反向?
7.网关的作用是什么
8.解释关系型数据库和非关系型数据库?
9.讲一下redis的特点
10.什么是闭包?应用场景有哪些?
11.react会吗? node.jsl了解吗? 不了解 只会vue
12.vue的源码有看吗?有 ...
13.说一下vuex
14.vue2 和vue3有哪些不同
15.TS了解多少?......说一下泛型.......
16.webpack有用吗?讲一下打包的流程原理?
17.webpack打包优化,页面渲染优化分别说一下
18.10分钟手撕代码 对数组的处理 将数组扁平化,数组去重,数组排序结合起来的一道题



作者：Starting。。
链接：https://www.nowcoder.com/discuss/689110?type=post&order=time&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack
来源：牛客网



[大华]()提前批[面经]()： 

  一面： 


​    1.自我介绍 
​    2.[项目]()分工 [项目]()介绍 
​    3.[项目]()是否使用多线程 
   4.Redis 缓存雪崩 及其拯救措施 
   5.spring代理模式 

​      
   6.HashMap底层实现架构 
   7.设计模式 （工厂模式、单例模式）使用场景 
   8.java内存模型以及JVM内存模型 
   9.消息队列（定义、作用、功能） 

​    10.反问 

  二面: 

​    1，自我介绍 

​    2.[项目]()相关技术栈，以及实现那部分的功能，其中面临的主要问题有哪些？如何介绍？ 
   3.谈谈你对Java面向对象的理解（继承、封装、多态），会给你一个模拟 场景，如何去设计？ 设计一些类的优缺点，是否违反了什么原则？ 

​    4.Redis 的优缺点 内存淘汰机制？ 
   5.如何设计一个缓存？ 

​    6.反问 

  HR面： 

​    1.自我介绍 
​    2.介绍一下[项目]()和研究方向? 
   3.聊一下你的技术栈，以及通过何种方式来学习新的技术? 
   4.如何完成应届生到职员的身份转化? 
   5.是否有投递其他公司?进度如何？ 
   6.是否有了解过公司?谈谈你对公司的认识? 
​    7.谈谈你的[职业规划]()? 
   8.你对工作地有什么要求吗？ 
   9.如何看待加班? 
   10.咨询个人情况，是否可以实习? 
   11.期望薪资? 

​    12.反问





ArrayList  && LinkedList

如何做扣减库存，做Guava Cache、redis的同步

G1垃圾回收算法、JVM

设计模式

